<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog Posts - Sam Stelfox&#39;s Thoughts &amp; Notes</title>
    <link>https://stelfox.net/blog/</link>
    <description>Recent content in Blog Posts - Sam Stelfox&#39;s Thoughts &amp; Notes</description>
    <language>en-US</language>
    <managingEditor>Sam Stelfox</managingEditor>
    <webMaster>Sam Stelfox</webMaster><atom:link href="https://stelfox.net/blog/atom.xml" rel="self" type="application/rss+xml" /><item>
      <title>Fixing Hung Nginx Workers</title>
      <link>https://stelfox.net/blog/2019/10/fixing-hung-nginx-workers/</link>
      <pubDate>Fri, 25 Oct 2019 11:26:31 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2019/10/fixing-hung-nginx-workers/</guid>
      <description>While cleaning up some tech debt, a curious issue cropped up. Nginx was running in an alpine container as a front end load balancer. It had a dynamic config that got periodically updated by a sidecar, and had filebeat shipping logs out to a central collector but otherwise was just a very simple Nginx config.
Every now and then the container would crash, it would automatically recover fast enough no alarms were lost and the clients would just resend their requests.</description>
    </item><item>
      <title>Fixing Dark Input Boxes in Firefox</title>
      <link>https://stelfox.net/blog/2019/04/fixing-dark-input-boxes-in-firefox/</link>
      <pubDate>Sat, 13 Apr 2019 11:53:22 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2019/04/fixing-dark-input-boxes-in-firefox/</guid>
      <description>I recently began trying out Cinnamon as my desktop environment and I&#39;ve been thoroughly enjoying it. The only issue I was having was occasionally a page&#39;s form input fields would have a dark background while still having dark text making it impossible to read, and very difficult to write.
It wasn&#39;t happening everywhere, and I couldn&#39;t track down what about a website would cause the issue. Most prominently for me was when this showed up in AWS&#39;s interface.</description>
    </item><item>
      <title>Merging Overlapping Subnets</title>
      <link>https://stelfox.net/blog/2019/03/merging-overlapping-subnets/</link>
      <pubDate>Wed, 27 Mar 2019 19:11:30 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2019/03/merging-overlapping-subnets/</guid>
      <description>Once upon a time there was a single AWS account. In this AWS account was several regions but a single VPC. To make sure expansions into other regions was possible this VPC chose to use the largest private subnet which just so happened to also be the default (10.0.0.0/8).
Another AWS account enter the picture and while they were single they came to the same conclusion and followed the best practices and defaults to their heart&#39;s content.</description>
    </item><item>
      <title>Reflashing Cisco Catalyst With XMODEM</title>
      <link>https://stelfox.net/blog/2019/03/reflashing-cisco-catalyst-with-xmodem/</link>
      <pubDate>Sun, 24 Mar 2019 23:26:30 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2019/03/reflashing-cisco-catalyst-with-xmodem/</guid>
      <description>One of the Cisco Catalyst 3750 I had to work on recently had it&#39;s flash completely wiped. When this happens you can only flash the filesystem using the XMODEM serial console. This is a fairly well documented process on Windows. On Linux most of the documented ways involve switching between multiple utilities and can be tricky. I wanted to documented how I did this and possibly help other in the same situation.</description>
    </item><item>
      <title>AWS Elastic IP Details</title>
      <link>https://stelfox.net/blog/2019/03/aws-elastic-ip-details/</link>
      <pubDate>Sun, 17 Mar 2019 16:26:30 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2019/03/aws-elastic-ip-details/</guid>
      <description>Sometimes it becomes important to understand how your cloud provider implements certain networking details. While working through an issue in AWS I needed to understand how they handle public IP addressing. While this issue for me was specific to an Elastic IP all of their public addresses are handled this way and may bite you even without them. The problems specifically crop up when a hosted piece of software does NAT traversal detection and changes it&#39;s behavior based on the result.</description>
    </item><item>
      <title>Fighting IPSec on AWS</title>
      <link>https://stelfox.net/blog/2019/03/fighting-ipsec-on-aws/</link>
      <pubDate>Thu, 14 Mar 2019 21:26:30 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2019/03/fighting-ipsec-on-aws/</guid>
      <description>IPSec is a well known and well understood protocol that is pretty easy to get setup and going&amp;hellip; Most of the time. While setting up an IPSec tunnel to an AWS host I came across a new and unique experience that didn&#39;t seem to have an easily searchable solution.
I had two CentOS 7 EC2 instances, each set up with their own Elastic IP in a default VPC. I installed and configured libreswan with the following config:</description>
    </item><item>
      <title>Hosting Your Own Private Git Repo</title>
      <link>https://stelfox.net/blog/2018/12/hosting-your-own-private-git-repo/</link>
      <pubDate>Fri, 21 Dec 2018 18:53:30 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/12/hosting-your-own-private-git-repo/</guid>
      <description>Git was built and developed with the intention of being a distributed reversion control system. Most people now use it with one or another central repository even when working on large teams which is perfectly fine if that model works for you and your team.
It can be useful to quickly work with others on private repositories without requiring them to get on your platform of choice, or for sensitive repositories keep the repository entirely under your control.</description>
    </item><item>
      <title>Performance Impact of OpenVPN Port Sharing</title>
      <link>https://stelfox.net/blog/2018/11/performance-impact-of-openvpn-port-sharing/</link>
      <pubDate>Sun, 04 Nov 2018 15:09:02 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/11/performance-impact-of-openvpn-port-sharing/</guid>
      <description>I recently had cause to use OpenVPN on the standard HTTPS port to protect my traffic. This was done as a compromise with administrators who didn&#39;t want to change their egress filtering, but wanted to allow me to continue doing my normal work.
I already run several webservers, including this one, and didn&#39;t want to give up exclusive access to the precious TCP port 443. The recommended way to deal with this is to make use of the port-share option built into OpenVPN.</description>
    </item><item>
      <title>Run Your Own DNS-over-TLS Server</title>
      <link>https://stelfox.net/blog/2018/11/run-your-own-dns-over-tls-server/</link>
      <pubDate>Fri, 02 Nov 2018 15:09:02 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/11/run-your-own-dns-over-tls-server/</guid>
      <description>DNS-over-TLS is a relatively new privacy enhancing protocol that encrypts all of your DNS requests to a trusted server. In an age when airports, and coffee shops are outsourcing &amp;lsquo;free wifi&amp;rsquo; to corporate entities that are likely harvesting as much data as they can this is a nice addition. I largely use VPNs when connected to these access points which provides at least as good protection as DNS-over-TLS which has caused me to largely overlook this development.</description>
    </item><item>
      <title>Weird CloudFlare Behavior</title>
      <link>https://stelfox.net/blog/2018/10/weird-cloudflare-behavior/</link>
      <pubDate>Sun, 21 Oct 2018 22:36:09 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/10/weird-cloudflare-behavior/</guid>
      <description>While working on a replacement webserver, I encountered some odd behavior which took a bit to track down to CloudFlare. This isn&#39;t a bug or an issue with CloudFlare, it was just unexpected.
The server was configured to respond to www.example.tld as well as example.tld, to both encrypted and unencrypted connections. Any requests to the www. domain get redirected to https://example.tld. The config was roughly:
server { listen 80; listen [::]:80; listen 443 ssl http2; listen [::]:443 ssl http2; server_name www.</description>
    </item><item>
      <title>It&#39;s Never the Firewall</title>
      <link>https://stelfox.net/blog/2018/10/its-never-the-firewall/</link>
      <pubDate>Sun, 14 Oct 2018 13:36:09 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/10/its-never-the-firewall/</guid>
      <description>This last Thursday I had the privilege of giving a talk at our local Linux User Group about diagnosing firewall issues on Linux entitled &amp;ldquo;It&#39;s Never the Firewall: Diagnosing Linux Firewall Issues&amp;rdquo;. I really enjoyed giving the talk, however, I left a few questions unanswered. While I may do a more extensive post on everything that I went through in the talk (I have been lax on writing content for this blog), this post is more to answer the outstanding questions and of course to make my slides available.</description>
    </item><item>
      <title>SPF and Google Site Verification in Route 53</title>
      <link>https://stelfox.net/blog/2018/06/spf-and-google-site-verification-in-route-53/</link>
      <pubDate>Thu, 14 Jun 2018 11:36:09 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/06/spf-and-google-site-verification-in-route-53/</guid>
      <description>Route53 doesn&#39;t allow multiple definitions of the same name/type pair of DNS entries which is quite a headache. This is the first time I&#39;ve had a conflict of a TXT record in Route53 at the base, specifically both Google&#39;s site verification, and SPF records both want to live at the root of the domain. The site verification record needs to stay around as Google periodically re-verifies the domain.
To get this to work you need to quote both the Google verification string and the SPF record, but you also have to ensure that there is a newline in the field.</description>
    </item><item>
      <title>Timelapse of a Linux Desktop</title>
      <link>https://stelfox.net/blog/2018/06/timelapse-of-a-linux-desktop/</link>
      <pubDate>Fri, 08 Jun 2018 16:37:39 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/06/timelapse-of-a-linux-desktop/</guid>
      <description>I have the privilege of working full remote. To stay connected with our other remote workers and the main office we keep a live video conference going all the time. It&#39;s pretty convenient and definitely allows me to continue to feel connected with the company.
During one of our stand ups, a coworker mentioned that they&#39;d like to see how things looked over time. I have three 1440p monitors and largely leave the video conference on my right most window, which makes recording (an audio free) timelapse pretty easy with FFmpeg.</description>
    </item><item>
      <title>Parsing HTTP Responses in Ruby</title>
      <link>https://stelfox.net/blog/2018/05/parsing-http-responses-in-ruby/</link>
      <pubDate>Wed, 23 May 2018 07:53:19 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/05/parsing-http-responses-in-ruby/</guid>
      <description>Normally handling HTTP responses in Ruby is rather straight forward. There is a native library in Ruby that handles HTTP requests which parses the responses into a neat data structure that you can then operate on. What if you want to work on stored HTTP responses outside of a connection though? This was the situation I found myself in and thanks to a series of unusual decisions in the Ruby core library I found myself left out in the cold.</description>
    </item><item>
      <title>Quick and Silent Gigabit Packet Interception</title>
      <link>https://stelfox.net/blog/2018/05/quick-and-silent-gigabit-packet-interception/</link>
      <pubDate>Sun, 13 May 2018 00:55:09 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/05/quick-and-silent-gigabit-packet-interception/</guid>
      <description>I regularly find myself inspecting traffic on Linux systems. Usually I&#39;m already on the client or server when doing this (such as when diagnosing weird low level app behavior, or unknown, or unusual traffic). It has been a while since I&#39;ve needed to silently be the wire between two black boxes.
While verifying link level information about bypassing my Google Fiber Network Box I needed to be that wire again. Before I connected any wires to anything I needed to be sure I wouldn&#39;t accidentally leak traffic as I wasn&#39;t sure what would impact the link.</description>
    </item><item>
      <title>Converting OpenLDAP Schemas to LDIF</title>
      <link>https://stelfox.net/blog/2018/03/converting-openldap-schemas-to-ldif/</link>
      <pubDate>Sat, 24 Mar 2018 20:20:22 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/03/converting-openldap-schemas-to-ldif/</guid>
      <description>I&#39;ve been writing software to work against an OpenLDAP instance, with a highly customized schema. The operators of the existing system only had the schema files and searching around found several elaborate ways to convert the files which I tried with mixed success. After doing the research to figure this out, it became clear I could probably have used slapcat and have dumped the active schema directly to LDIF.
As a sample of how I converted these, I&#39;ll use the rfc2307bis.</description>
    </item><item>
      <title>Including LDIF Files in OpenLDAP</title>
      <link>https://stelfox.net/blog/2018/03/including-ldif-files-in-openldap/</link>
      <pubDate>Sat, 24 Mar 2018 20:20:22 -0600</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2018/03/including-ldif-files-in-openldap/</guid>
      <description>While setting up and OpenLDAP server I found my distribution shipped with a couple of schema files, but no equivalent LDIF files. I found ways to convert the file using slapcat and slaptest and the files were valid on their own.
I was specifically trying to bootstrap an OpenLDAP server, with it&#39;s schema, from scratch for a CI/CD system to test against. To accomplish this I was making use of the include directive in a configuration LDIF file and saw some very odd behavior.</description>
    </item><item>
      <title>Cross-Compiling Gentoo for Xilinx Boards</title>
      <link>https://stelfox.net/blog/2017/12/cross-compiling-gentoo-for-xilinx-boards/</link>
      <pubDate>Mon, 18 Dec 2017 17:49:22 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/12/cross-compiling-gentoo-for-xilinx-boards/</guid>
      <description>Note: If you&#39;ve come here looking to build a root filesystem for 32 bit ARM devices I suspect everything but the build tuple will be the same. The issues that need to be worked around largely packaging and profile issues that should all be the same.
I got a hold of a Zynq 7100 development board, and while I&#39;ve played with some embedded ARM microcontrollers such as the STM32F3 series and more basic RISC style microcontrollers like Atmel&#39;s SAMD10 and Atmega lines, I&#39;ve never played with FPGA development before so I considered this an interesting learning opportunity.</description>
    </item><item>
      <title>Converting CPIO Files to Tarballs</title>
      <link>https://stelfox.net/blog/2017/12/converting-cpio-files-to-tarballs/</link>
      <pubDate>Mon, 04 Dec 2017 22:46:56 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/12/converting-cpio-files-to-tarballs/</guid>
      <description>I needed to convert a directory full of CPIO files to tar balls. This quick script did the trick for me but didn&#39;t preserve the user / group. Running it as root will preserve the ownership information but that wasn&#39;t important for my immediate use case.
#!/bin/bash SRC_DIR=$(pwd) for i in *.cpio; do CPIO_TMP_DIR=&amp;quot;$(mktemp -d /tmp/cpioconv.XXXX)&amp;quot; (cd ${CPIO_TMP_DIR} &amp;amp;&amp;amp; cpio -idm &amp;lt; &amp;quot;${SRC_DIR}/${i}&amp;quot; &amp;amp;&amp;amp; tar -cf ${SRC_DIR}/${i%%.cpio}.tar .) rm -rf ${CPIO_TMP_DIR} done </description>
    </item><item>
      <title>Unusable Secret Key</title>
      <link>https://stelfox.net/blog/2017/12/unusable-secret-key/</link>
      <pubDate>Mon, 04 Dec 2017 11:38:01 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/12/unusable-secret-key/</guid>
      <description>I use a Yubikey NEO to store subkeys used for signing and authentication. I started experiencing a weird issue with it. It coincided with me rebuilding my system so diagnosing it ended up being harder than normal. The behavior I experienced allowed me to use the key to authenticate (SSH&#39;ing worked fine) but any attempt to sign new data resulted in an &amp;lsquo;Unusuable secret key&amp;rsquo; error. For git this resulted in the following message:</description>
    </item><item>
      <title>XFCE Failed to Connect to Socket</title>
      <link>https://stelfox.net/blog/2017/11/xfce-failed-to-connect-to-socket/</link>
      <pubDate>Mon, 27 Nov 2017 17:23:09 +0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/11/xfce-failed-to-connect-to-socket/</guid>
      <description>While trying to build up a minimal Gentoo graphical environment I kept running into an error every time I logged into XFCE from lightdm (I didn&#39;t try starting up XFCE any other way). There are tons of blog posts that relate to systemd, ubuntu, or crouton but none related to Gentoo.
The first error message that pops up is:
Unable to contact settings server Failed to connect to socket /tmp/dbus-xxxxxxxxx: Connection refused Once you click through there was a second error message, but I believe it was due to the previous error and not actually an issue:</description>
    </item><item>
      <title>Unable to Enter LUKS Passphrase</title>
      <link>https://stelfox.net/blog/2017/11/unable-to-enter-luks-passphrase/</link>
      <pubDate>Sun, 26 Nov 2017 21:49:51 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/11/unable-to-enter-luks-passphrase/</guid>
      <description>While setting up a gentoo install with a full disk encryption, I continuously got to a point where the passphrase would show up on boot but I was unable to enter the passphrase. The behavior of the keyboard was also odd, it would toggle it&#39;s numlock light every couple of button presses.
Once again this was an issue that was hard to search for, and most other people asking it seemed to only get snarky non-answers which seem so prevalent in forums.</description>
    </item><item>
      <title>Downgrading Glibc in Gentoo</title>
      <link>https://stelfox.net/blog/2017/11/downgrading-glibc-in-gentoo/</link>
      <pubDate>Wed, 15 Nov 2017 12:27:45 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/11/downgrading-glibc-in-gentoo/</guid>
      <description>While refining some automated setup scripts at some point I upgraded to a testing/unstable version of glibc. When I attempted to get the box back on to the stable version I hit a solid protection mechanism built into the portage scripts that prevents downgrading glibc. Attempts will give you the following error message:
 * Sanity check to keep you from breaking your system: * Downgrading glibc is not supported and a sure way to destruction * ERROR: sys-libs/glibc-2.</description>
    </item><item>
      <title>File in Wrong Format</title>
      <link>https://stelfox.net/blog/2017/11/file-in-wrong-format/</link>
      <pubDate>Mon, 13 Nov 2017 13:44:00 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/11/file-in-wrong-format/</guid>
      <description>I have been recently attempting to cross compile a custom Gentoo profile targetting a Xilinx board as I found their distribution to be unmanageable (PetaLinux as hacked together sub-distro of Yocto). I had several issues with the default profile (embedded) conflicting with other critical packages. I&#39;ll do a detailed post later on for building that entire root filesystem.
I came across one issue which didn&#39;t seem to have a well-documented solution.</description>
    </item><item>
      <title>Gentoo Fstab Failure</title>
      <link>https://stelfox.net/blog/2017/11/gentoo-fstab-failure/</link>
      <pubDate>Wed, 01 Nov 2017 11:12:34 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/11/gentoo-fstab-failure/</guid>
      <description>I use Gentoo with OpenRC quite a bit both for my personal servers and as a compilation test bed for new software since I can control the dependency versions very tightly. I have a set of scripts I&#39;ve been using for quite some time that handle setting up a hardened, fairly minimal install.
I recently encountered a weird issue with them that resulted in an esoteric error that prevented my host from fully booting and leaving the root filesystem read-only.</description>
    </item><item>
      <title>Investigating LVM From Dracut</title>
      <link>https://stelfox.net/blog/2017/10/investigating-lvm-from-dracut/</link>
      <pubDate>Tue, 24 Oct 2017 11:45:07 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/10/investigating-lvm-from-dracut/</guid>
      <description>In my my last post, I covered finding logical volumes that were missing from LVM from within a live CD (which is effectively a whole standard environment). Working with dracut is quite a bit more limited.
Turns out that the commands I&#39;m normally used to for operating and inspecting LVM volumes can all be accessed as a second parameter to the lvm tool like so:
$ lvm vgscan $ lvm pvscan $ lvm lvscan For my particular issue, it led me to notice that block device of my root filesystem was missing due to a missing kernel driver&amp;hellip;</description>
    </item><item>
      <title>Visible Yet Missing Logical Volumes</title>
      <link>https://stelfox.net/blog/2017/10/visible-yet-missing-logical-volumes/</link>
      <pubDate>Tue, 24 Oct 2017 10:58:12 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/10/visible-yet-missing-logical-volumes/</guid>
      <description>While working on an automated install script for an embedded board, I hit an issue with the logical volumes never showing up in /dev/mapper, and in turn unable to be mounted. This left me in the dracut emergency shell (after about three minutes), with little to go on beyond the following error:
[187.508531] dracut Warning: Could not boot. [187.510560] dracut Warning: /dev/disk/by-uuid/5681-902D does not exist [187.512534] dracut Warning: /dev/mapper/system-root does not exit [187.</description>
    </item><item>
      <title>Vultr Deny All Firewall</title>
      <link>https://stelfox.net/blog/2017/10/vultr-deny-all-firewall/</link>
      <pubDate>Fri, 20 Oct 2017 17:18:36 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/10/vultr-deny-all-firewall/</guid>
      <description>While setting up new instances on Vultr for testing, I wanted to initially ensure that no traffic beyond my own could touch the instances. After adding a matching rule for SSH to my IPv4 address, a default rule shows up that drops any unspecified traffic. Switching to the IPv6 I wanted to add a drop all rule (as I wouldn&#39;t be using IPv6 until the system was up).
The interface only allows accept rules to be created and additionally you&#39;ll be greeted with this message while trying to figure out what to do:</description>
    </item><item>
      <title>Security Principles</title>
      <link>https://stelfox.net/blog/2017/10/security-principles/</link>
      <pubDate>Thu, 19 Oct 2017 05:19:12 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/10/security-principles/</guid>
      <description>While reviewing current security hardening practices put out by several organizations and attempting to filter the good recommendations from the outdated legislated requirements, I came across one of the best descriptions of basic security principles. You can find it in the NIST Guide to General Server Security (published in 2008).
I&#39;ve replicated section 2.4 from the linked document (I have removed the footnotes, but it is otherwise unchanged) in its entirety here for safe keeping and to hopefully help expose this to more people.</description>
    </item><item>
      <title>Linux Audit Rule Paths</title>
      <link>https://stelfox.net/blog/2017/10/linux-audit-rule-paths/</link>
      <pubDate>Mon, 16 Oct 2017 23:20:20 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/10/linux-audit-rule-paths/</guid>
      <description>I encountered a little bit of confusion while rewriting my auditd rules which some Googling did not help me solve.
When monitoring a file or directory there are two forms the rules can take. They are effectively equivalent in their functionality. The simpler form is the following format:
-w /etc/shadow -p wa -w /boot -p wa -w /etc/dont_readme -p r These three rules are all behaving slightly differently. The first will audit any writes or attribute changes to the shadow file.</description>
    </item><item>
      <title>Vulnerable Smart Cards</title>
      <link>https://stelfox.net/blog/2017/10/vulnerable-smart-cards/</link>
      <pubDate>Mon, 16 Oct 2017 12:25:58 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/10/vulnerable-smart-cards/</guid>
      <description>In addition to the WiFi vulnerability a much more limited vulnerability was announced around private GPG keys that were generated using Infineon&#39;s RSA Library version v1.02.013.
The vulnerability lies in shortcuts taken to speed up the key generation using the library. The performance increase makes the private key vulnerable to factorization attacks using an extension to Coppersmith&#39;s attack.
It has been confirmed that YubiKey 4s are effected as are many nations national ID cards.</description>
    </item><item>
      <title>A KRACK In the Defenses</title>
      <link>https://stelfox.net/blog/2017/10/a-krack-in-the-defenses/</link>
      <pubDate>Mon, 16 Oct 2017 08:23:43 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/10/a-krack-in-the-defenses/</guid>
      <description>An advisory from US CERT has been circulating for the last week about a protocol level flaw in WPA &amp;amp; WPA2. The advisory itself was:
 US-CERT has become aware of several key management vulnerabilities in the 4-way handshake of the Wi-Fi Protected Access II (WPA2) security protocol. The impact of exploiting these vulnerabilities includes decryption, packet replay, TCP connection hijacking, HTTP content injection, and others. Note that as protocol-level issues, most or all correct implementations of the standard will be affected.</description>
    </item><item>
      <title>The Case of an Empty Executable</title>
      <link>https://stelfox.net/blog/2017/10/the-case-of-an-empty-executable/</link>
      <pubDate>Thu, 12 Oct 2017 23:09:01 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2017/10/the-case-of-an-empty-executable/</guid>
      <description>I recently came across a short article written about a decade ago. It was a curious thing already as it was hosted in a user&#39;s home directory off a web server with the standard &amp;lsquo;~&amp;rsquo; showing up in the URL. The important part that caught my eye was this:
 The &amp;ldquo;true&amp;rdquo; program does nothing; it merely exits with a zero exit status. This can be done with an empty file that&#39;s marked executable, and that&#39;s what it was in the earliest unix system libraries.</description>
    </item><item>
      <title>Hash Cash</title>
      <link>https://stelfox.net/blog/2016/09/hash-cash/</link>
      <pubDate>Wed, 14 Sep 2016 01:36:59 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2016/09/hash-cash/</guid>
      <description>This is an interesting proof of work concept. The first example I have found of this in the wild is to prevent abuse for anonymous account registration on an IRC network.
I reviewed it&#39;s source and found that it requests a seed, and payload from a backend PHP script. It assumes that a target collision will happen within 1,000,000 iterations.
This is broken up into 10 iterations. A pool of four WebWorkers are spawned.</description>
    </item><item>
      <title>Better Practices With Sudo</title>
      <link>https://stelfox.net/blog/2016/02/better-practices-with-sudo/</link>
      <pubDate>Fri, 26 Feb 2016 17:45:22 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2016/02/better-practices-with-sudo/</guid>
      <description>&lt;p&gt;I work with a lot of different linux machines from embedded devices, to cloud
servers and open stack hosts. For many of them I&#39;m either the sole
administrator or one of three or less with administrative access. Where there
are multiple administrative users, we all are generally working as backups to
each other. We use sudo whenever we need to execute a task with privileges on
any of these machines with no direct root login permitted remotely.&lt;/p&gt;
&lt;p&gt;I must confess I have established two habits over time that are against best
practices with regard to sudo; Using it to execute a root shell only, and not
restricting which commands can be run with sudo.&lt;/p&gt;</description>
    </item><item>
      <title>Sharing Context Between Dependent Rake Tasks</title>
      <link>https://stelfox.net/blog/2016/02/sharing-context-between-dependent-rake-tasks/</link>
      <pubDate>Thu, 18 Feb 2016 15:46:12 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2016/02/sharing-context-between-dependent-rake-tasks/</guid>
      <description>I use Rakefiles quite a bit like traditional Makefiles, in that I specify immediate dependencies for an individual task and Rake will execute all of them. If a file or directory is the dependency and it exists, the task that creates it will be skipped. A contrived Rakefile example might look like:
file &amp;#39;sample&amp;#39; do |t| puts &amp;#39;Creating sample directory&amp;#39; Dir.mkdir(t.name) end file &amp;#39;sample/population.txt&amp;#39; =&amp;gt; [&amp;#39;sample&amp;#39;] do |t| puts &amp;#39;Creating sample population file.</description>
    </item><item>
      <title>Ruby Code Quality Metrics</title>
      <link>https://stelfox.net/blog/2015/04/ruby-code-quality-metrics/</link>
      <pubDate>Wed, 22 Apr 2015 16:47:10 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2015/04/ruby-code-quality-metrics/</guid>
      <description>I like getting unopinionated feedback on the quality of the code I write. Sometimes I can get this from other developers but they tend to get annoyed being asked after every commit whether they consider it an improvement.
There are a few utilities for Ruby codebases such as flay, flog, and rubocop as well as hosted services such as Code Climate that can help you identify chunks of code that can use some work.</description>
    </item><item>
      <title>Creating an Empty Git Branch</title>
      <link>https://stelfox.net/blog/2015/04/creating-an-empty-git-branch/</link>
      <pubDate>Mon, 13 Apr 2015 20:47:40 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2015/04/creating-an-empty-git-branch/</guid>
      <description>Every now and then I find myself wanting to create a new empty branch in an existing repository. It&#39;s useful for things such as GitHub Pages so you&#39;re able to keep your content source in the master branch while only keeping the output in the gh-pages branch. I&#39;ve also used it for testing a complete rewrite of a code base without the overhead of creating a new repo and copying access permissions.</description>
    </item><item>
      <title>Unbuffered Pipe Filters</title>
      <link>https://stelfox.net/blog/2015/02/unbuffered-pipe-filters/</link>
      <pubDate>Mon, 23 Feb 2015 12:49:13 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2015/02/unbuffered-pipe-filters/</guid>
      <description>I need to filter a live log stream for only relevant events and quickly hit an issue that I wasn&#39;t expecting. The grep in my pipe chain was waiting until it received all the output from the prior command before it began to attempt to filter it.
Reading through the grep man page I came across the --line-buffered flag which provides exactly what I needed. I wasn&#39;t using the tail command but it serves really well in this situation to demonstrate the use:</description>
    </item><item>
      <title>Dependency Prelink Issues</title>
      <link>https://stelfox.net/blog/2014/08/dependency-prelink-issues/</link>
      <pubDate>Tue, 12 Aug 2014 16:16:14 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/08/dependency-prelink-issues/</guid>
      <description>While running an aide check on one of my servers after updating it, I started seeing a large number of very concerning warning messages:
/usr/sbin/prelink: /bin/mailx: at least one of file&#39;s dependencies has changed since prelinking Error on exit of prelink child process /usr/sbin/prelink: /bin/rpm: at least one of file&#39;s dependencies has changed since prelinking Error on exit of prelink child process /usr/sbin/prelink: /sbin/readahead: at least one of file&#39;s dependencies has changed since prelinking Error on exit of prelink child process /usr/sbin/prelink: /lib64/libkrb5.</description>
    </item><item>
      <title>Fast Hex to Decimal in Bash</title>
      <link>https://stelfox.net/blog/2014/08/fast-hex-to-decimal-in-bash/</link>
      <pubDate>Fri, 01 Aug 2014 19:50:24 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/08/fast-hex-to-decimal-in-bash/</guid>
      <description>I needed too turn some hexadecimal values into decimal in a bash script and found a real easy way too do it. The following is a very short bash script demonstrating how too turn the hexadecimal string &amp;ldquo;deadbeefcafe&amp;rdquo; into it&#39;s equivalent decimal value of &amp;ldquo;244837814094590&amp;rdquo;.
#!/bin/bash  INPUT=&amp;#34;deadbeefcafe&amp;#34; OUTPUT=$((0x${INPUT})) echo $OUTPUT </description>
    </item><item>
      <title>SPF &amp; DKIM Records in Route 53</title>
      <link>https://stelfox.net/blog/2014/07/spf-and-dkim-records-in-route-53/</link>
      <pubDate>Wed, 30 Jul 2014 10:46:13 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/07/spf-and-dkim-records-in-route-53/</guid>
      <description>I&#39;m going to do a more detailed post on emailing from Amazon&#39;s infrastructure soon, but in the meantime I wanted to quickly throw out solutions too a couple of problems I encountered. These are all specific too Amazon&#39;s Route 53, and most are user error (myself).
SPF Invalid Characters or Format After generating my SPF record, I jumped into Route 53, created a new record pasted in my record, attempted to save and received the following message:</description>
    </item><item>
      <title>Unregistering From WhisperPush After Flashing a New ROM</title>
      <link>https://stelfox.net/blog/2014/07/unregistering-from-whisperpush-after-flashing-a-new-rom/</link>
      <pubDate>Tue, 22 Jul 2014 21:54:59 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/07/unregistering-from-whisperpush-after-flashing-a-new-rom/</guid>
      <description>I&#39;ve been playing around with my Nexus 5 lately. It was quickly rooted and I began playing with various ROMs that had been pre-built for the Nexus 5. My first stop was the CyanogenMod. Since I&#39;d last used CyanogenMod they added a built-in framework that provides transparent text message encryption called WhisperPush.
WhisperPush is an implementation of Moxie Marlinspike&#39;s highly respected TextSecure and I was very excited at the possibility of using it.</description>
    </item><item>
      <title>Using OpenWRT&#39;s Dnsmasq as a TFTP Server</title>
      <link>https://stelfox.net/blog/2014/07/using-openwrts-dnsmasq-as-a-tftp-server/</link>
      <pubDate>Tue, 01 Jul 2014 21:26:45 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/07/using-openwrts-dnsmasq-as-a-tftp-server/</guid>
      <description>I recently reflashed my primary router to a newer version of OpenWRT and attempted to follow my own directions written in an earlier blog post to add PXE booting to my local network using the dnsmasq service built in. After following my advice I found that the dnsmasq service wasn&#39;t starting.
Looking into the logread output I finally saw that this was due too a permission issue. Combining this with the output of ps too identify the user that dnsmasq was running on I was able to both modify my instructions and use OpenWRT&#39;s own configuration system to perform the configuration instead of modifying the dnsmasq configuration.</description>
    </item><item>
      <title>Fixing Erratic BMC Controller on PowerEdge C6100</title>
      <link>https://stelfox.net/blog/2014/06/fixing-erratic-bmc-controller-on-poweredge-c6100/</link>
      <pubDate>Mon, 30 Jun 2014 21:43:02 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/06/fixing-erratic-bmc-controller-on-poweredge-c6100/</guid>
      <description>I randomly started experiencing an issue with one blade in one of my PowerEdge C6100 blades. It wouldn&#39;t obey all commands issued too it via IPMI or through the BMC&#39;s web interface. Additionally the blade would randomly power on when off, and the front light would consistently blink as if a hardware fault was detected.
This has been bothering me for a while, but it was my spare blade and wasn&#39;t affecting my lab in anyway so I&#39;ve ignored it.</description>
    </item><item>
      <title>AWS Reserved Instance Pricing</title>
      <link>https://stelfox.net/blog/2014/06/aws-reserved-instance-pricing/</link>
      <pubDate>Fri, 06 Jun 2014 13:28:11 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/06/aws-reserved-instance-pricing/</guid>
      <description>The current large project I&#39;m working on is going to be hosted on AWS and I was requested to do a cost estimate. Looking into it, it quickly became clear that reserved instances could potentially save quite a bit of cash but there was a catch (isn&#39;t there always?).
There is an upfront cost for reserving the instance and in exchange you get a reduced hourly rate. After running the numbers one thing wasn&#39;t clear too me, is the upfront cost credit towards running machines or a fee you never see again?</description>
    </item><item>
      <title>Modifying the Hosts File in a Docker Container</title>
      <link>https://stelfox.net/blog/2014/06/modifying-the-hosts-file-in-a-docker-container/</link>
      <pubDate>Tue, 03 Jun 2014 11:43:59 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/06/modifying-the-hosts-file-in-a-docker-container/</guid>
      <description>Before I describe the issue that I encountered, let me be very clear. This hack is potentially dangerous and should absolutely only be done in development environments. This won&#39;t affect your host system, only the docker container so the most damage you&#39;ll do is prevent hostname and possibly user/group lookups within the container itself.
Alright with that out of the way, I was actively working on a codebase that uses subdomains as part of the identifier.</description>
    </item><item>
      <title>Extracting Content From Markdown</title>
      <link>https://stelfox.net/blog/2014/05/extracting-content-from-markdown/</link>
      <pubDate>Fri, 30 May 2014 18:34:29 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/05/extracting-content-from-markdown/</guid>
      <description>Recently I&#39;ve been playing around with building a pure javascript full text search engine for static content sites like this one. One of the challenges with doing this has been working around the Markdown markup embedded in the written content.
Most of the markdown syntax can be stripped out simply by removing all non-alphanumeric characters from the document and move on. This doesn&#39;t solve one of the bigger challenges I&#39;ve experienced&amp;hellip; Code blocks.</description>
    </item><item>
      <title>PG::Error: ERROR: Type &#39;Hstore&#39; Does Not Exist</title>
      <link>https://stelfox.net/blog/2014/05/pg-error-error-type-hstore-does-not-exist/</link>
      <pubDate>Wed, 28 May 2014 18:00:55 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/05/pg-error-error-type-hstore-does-not-exist/</guid>
      <description>I&#39;ve been using the PostgreSQL&#39;s hstore extension in a Rails application lately and kept encountering the error that is this post&#39;s namesake. It would specifically happen when a database had been dropped, recreated and I freshly ran the migrations.
It seems that while Rails 4 supports the HStore datatype, it doesn&#39;t enable the extension itself. I&#39;ve found two ways too solve this issue in wildly different ways.
First Solution: Enable HStore by Default This is the common solution that is recommended too solve this issue.</description>
    </item><item>
      <title>Chain Loading Kernels</title>
      <link>https://stelfox.net/blog/2014/05/chain-loading-kernels/</link>
      <pubDate>Fri, 23 May 2014 11:39:16 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/05/chain-loading-kernels/</guid>
      <description>I&#39;ve found several places where I needed to be able to update my kernels but for one reason or another can&#39;t update the kernel that gets booted initially. A couple of these situations were:
 Running Custom or Updated Kernels on DigitalOcean (this is one of their biggest failings IMHO) Allowing updating of kernels on embedded linux devices that require their kernel flashed into NVRAM. Running an embedded system that used an active/backup partition scheme for updating.</description>
    </item><item>
      <title>Calculating RSA Key Fingerprints in Ruby</title>
      <link>https://stelfox.net/blog/2014/04/calculating-rsa-key-fingerprints-in-ruby/</link>
      <pubDate>Mon, 21 Apr 2014 18:37:04 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/04/calculating-rsa-key-fingerprints-in-ruby/</guid>
      <description>I regularly find myself working on projects that involve the manipulation and storage of RSA keys. In the past I&#39;ve never had to worry about identification or presentation of these keys. Normally I&#39;ve only got one too three pairs at most that I&#39;m manipulating (server, certificate authority, client).
I&#39;ve not found myself working on a project that involves presenting the certificates to users for selection and comparison. The obvious way too do this is take a page out of other developer&#39;s books and present the key&#39;s fingerprint.</description>
    </item><item>
      <title>Disabling Gnome&#39;s Keyring in Fedora 19</title>
      <link>https://stelfox.net/blog/2014/04/disabling-gnomes-keyring-in-fedora-19/</link>
      <pubDate>Mon, 14 Apr 2014 10:19:23 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/04/disabling-gnomes-keyring-in-fedora-19/</guid>
      <description>An update too Fedora a while ago started causing some unexpected behavior with my dotfiles. Specifically the way I was handling my SSH agent. My SSH keys when added to my agent automatically expire after a couple of hours.
After the update, when that expiration came I started receiving errors in my shell that looked similar to the following (Since I fixed it I am not able to get the exact working again):</description>
    </item><item>
      <title>One-Liner SSL Certificate Generation</title>
      <link>https://stelfox.net/blog/2014/03/one-liner-ssl-certificate-generation/</link>
      <pubDate>Fri, 28 Mar 2014 14:52:51 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/03/one-liner-ssl-certificate-generation/</guid>
      <description>I regularly find myself in need of generating a quick SSL key and certificate pair. I&#39;ve been using a one-liner for a while to generate these certificates. No annoying user prompts just a quick fast certificate pair.
echo -e &amp;#34;XX\n\n \n \n\n$(hostname)\n\n&amp;#34; | openssl req -new -x509 -newkey \  rsa:2048 -keyout service.key -nodes -days 90 -out service.crt &amp;amp;&amp;gt; /dev/null The cert uses the hostname of whatever machine you generated it on.</description>
    </item><item>
      <title>Preventing Tmux Lockups</title>
      <link>https://stelfox.net/blog/2014/03/preventing-tmux-lockups/</link>
      <pubDate>Fri, 28 Mar 2014 12:56:12 -0400</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/03/preventing-tmux-lockups/</guid>
      <description>Anyone that has used SSH, Tmux or Screen for a while will have inevitably dumped excessive output to their terminal. Depending on the size of the output you may have experienced the dreaded lockup. That horrible realization seconds after you hit the command where signals just stop working and you just have to sit there and wait for your terminal to catch up.
There is a piece of remote connection software called Mosh that I&#39;ve been told handles this pretty well, but I don&#39;t yet trust its security model and it doesn&#39;t prevent the same thing from happening locally.</description>
    </item><item>
      <title>Finding Ruby Subclasses</title>
      <link>https://stelfox.net/blog/2014/02/finding-ruby-subclasses/</link>
      <pubDate>Thu, 20 Feb 2014 07:48:24 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/02/finding-ruby-subclasses/</guid>
      <description>While working through a problem I found it would be immensely useful to be able to enumerate all of the current subclasses of a particular class. After thinking about this for a while I settled on a good old friend of mine, ObjectSpace.
For those not familiar with the ObjectSpace module, it is a means to inspect and access the items being tracked by Ruby&#39;s garbage collector. This means it has a hook into every living object, and more dangerously, every near-death object.</description>
    </item><item>
      <title>Creating Crypt Style SHA512 Passwords With Ruby</title>
      <link>https://stelfox.net/blog/2014/02/creating-crypt-style-sha512-passwords-with-ruby/</link>
      <pubDate>Mon, 17 Feb 2014 15:28:27 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/02/creating-crypt-style-sha512-passwords-with-ruby/</guid>
      <description>I needed to generate crypt-style SHA512 passwords in ruby for an /etc/shadow file. After a bunch of Googling and messing around with the OpenSSL library I finally found a very simple built-in way to handle this.
require &amp;#39;securerandom&amp;#39; &amp;#39;password&amp;#39;.crypt(&amp;#39;$6$&amp;#39; + SecureRandom.random_number(36 ** 8).to_s(36)) You&#39;ll get a string that looks like:
$6$4dksjo1b$Lt194Dwy7r/7WbM8MezYZysmGcxjaiisgTrTBbHkyBZFXeqQTG0J5hep4wLM/AmYxlGNLRy0OWATLDZCqjwCk. If you don&#39;t want to use the SecureRandom module you can replace the random call with simply rand(36 ** 8) though this isn&#39;t recommended.</description>
    </item><item>
      <title>Setting Linux System Timezone</title>
      <link>https://stelfox.net/blog/2014/02/setting-linux-system-timezone/</link>
      <pubDate>Sat, 01 Feb 2014 13:50:46 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/02/setting-linux-system-timezone/</guid>
      <description>I change the timezone on the linux systems so rarely that I almost always have to look it up. I&#39;m writing it up here for my own personal reference. With any luck it&#39;ll also help others.
The system timezone is controlled by the /etc/localtime file and is generally symlinked to locale files stored in /usr/share/zoneinfo. Generally I like to keep my systems on UTC as I my machines are in several timezones and it makes all the logs have consistent times.</description>
    </item><item>
      <title>Starting Puppet Master on Fedora 19</title>
      <link>https://stelfox.net/blog/2014/01/starting-puppetmaster-on-fedora-19/</link>
      <pubDate>Sat, 18 Jan 2014 22:47:37 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2014/01/starting-puppetmaster-on-fedora-19/</guid>
      <description>I was trying to get puppet running out of the box on Fedora 19 and found a bug exists in their systemd service file. After installing puppet and puppet-server, whenever I tried to start the server with the following command:
systemctl start puppetmaster.service It would hang for a long time and the following error message would show up in the log:
Jan 19 03:42:18 puppet-01 puppet-master[1166]: Starting Puppet master version 3.</description>
    </item><item>
      <title>Playing With the Linux Bluetooth Stack</title>
      <link>https://stelfox.net/blog/2013/12/playing-with-the-linux-bluetooth-stack/</link>
      <pubDate>Tue, 24 Dec 2013 14:53:27 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/playing-with-the-linux-bluetooth-stack/</guid>
      <description>List all available bluetooth interfaces:
hciconfig -a If you get an error like the following:
Operation not possible due to RF-kill You&#39;ll need to unblock access to the resource using rfkill. You can unblock all blocked devices like so:
rfkill unblock all Before doing any iBeacon stuff you should disable scanning:
hciconfig hci0 noscan hcitool -i hci0 cmd 0x08 0x0008 1E 02 01 1A 1A FF 4C 00 02 15 [ 92 77 83 0A B2 EB 49 0F A1 DD 7F E3 8C 49 2E DE ] [ 00 00 ] [ 00 00 ] C5 00 hcitool -i hci0 leadv LE set advertise enable on hci1 returned status 12 </description>
    </item><item>
      <title>Updating BMC on Dell PowerEdge C6100</title>
      <link>https://stelfox.net/blog/2013/12/updating-bmc-on-dell-poweredge-c6100/</link>
      <pubDate>Mon, 16 Dec 2013 21:26:13 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/updating-bmc-on-dell-poweredge-c6100/</guid>
      <description>I just received my Dell PowerEdge C6100 and found it&#39;s software quite a bit outdated. After searching around quite a bit I found the resources lacking for explaining how to perform these updates. So in this post I&#39;m going to quickly cover updating the BMC firmware on each blade.
The system I received had four different versions of the BMC software installed, additionally Two were branded as MegaRAC and the others branded as Dell.</description>
    </item><item>
      <title>Updating the BIOS on Dell PowerEdge C6100</title>
      <link>https://stelfox.net/blog/2013/12/updating-the-bios-on-dell-poweredge-c6100/</link>
      <pubDate>Mon, 16 Dec 2013 09:39:02 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/updating-the-bios-on-dell-poweredge-c6100/</guid>
      <description>The BIOS was quite a bit more complicated and there was a few options that I had available to try, all of which require either Windows or DOS environments. I don&#39;t have any legal copies of Windows to put on my server and didn&#39;t want to go through all that effort`
It really needs to be done within a DOS environment. I downloaded the file PEC6100BIOS017000.exe from Dell&#39;s support website (locally hosted copy) as well as the 2.</description>
    </item><item>
      <title>Using Dnsmasq as a Standalone TFTP Server</title>
      <link>https://stelfox.net/blog/2013/12/using-dnsmasq-as-a-standalone-tftp-server/</link>
      <pubDate>Thu, 12 Dec 2013 18:29:46 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/using-dnsmasq-as-a-standalone-tftp-server/</guid>
      <description>If you&#39;ve come across this blog post with the intention of setting up TFTP on an modern version of OpenWRT I have a more recent blog post detailing how too configure your system.
I found myself in need of a TFTP server but wanted to avoid having all of the xinet.d packages and services on my system (even if they were disabled). While looking for alternatives I found out that dnsmasq has a built-in read-only TFTP server.</description>
    </item><item>
      <title>Configuring PXE Booting on OpenWRT</title>
      <link>https://stelfox.net/blog/2013/12/configuring-pxe-booting-on-openwrt/</link>
      <pubDate>Wed, 11 Dec 2013 08:40:44 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/configuring-pxe-booting-on-openwrt/</guid>
      <description>I needed to support PXE booting on my home network. I use OpenWRT as my main router and DHCP server and it took me a bit of searching how to configure the BOOTP next server to redirect local clients to my Arch TFTP/NFS server for booting, so I&#39;m placing the configuration here to help others who might be looking to do the same thing.
It&#39;s worth noting that this isn&#39;t a guide on setting up PXE booting completely on an OpenWRT, you&#39;ll need another system that is running a configured TFTP server.</description>
    </item><item>
      <title>Running Emails Through Ruby</title>
      <link>https://stelfox.net/blog/2013/12/running-emails-through-ruby/</link>
      <pubDate>Sun, 08 Dec 2013 09:32:05 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/running-emails-through-ruby/</guid>
      <description>Following up on my earlier post where I covered how to backup your Gmail account using fetchmail and procmail; I wanted to cover how I was additionally processing received mail through ruby.
This was part of a larger project where I was doing statistical analysis on my email while evaluating various data stores. To get the emails into the various data stores, I used the ruby script to parse, process and store the emails as they came in.</description>
    </item><item>
      <title>Access GET Parameters With Coffeescript</title>
      <link>https://stelfox.net/blog/2013/12/access-get-parameters-with-coffeescript/</link>
      <pubDate>Sat, 07 Dec 2013 18:20:58 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/access-get-parameters-with-coffeescript/</guid>
      <description>I&#39;ve been working on a pure javascript based search engine for this static website and needed to access a get parameter within the URL.
I found a few solutions online but they usually made use of jQuery or weren&#39;t in coffeescript. A few others would only extract an individual named parameter at a time. The following will return all of them in Javascript&#39;s equivalent of a hash (or dictionary if you prefer) in the form of an object.</description>
    </item><item>
      <title>Downloading Google Mail and Calendar Data</title>
      <link>https://stelfox.net/blog/2013/12/downloading-google-mail-and-calendar-data/</link>
      <pubDate>Thu, 05 Dec 2013 11:04:18 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/downloading-google-mail-and-calendar-data/</guid>
      <description>I recently posted a guide on backing up your Gmail with fetchmail. This unfortunately doesn&#39;t include your calendar data. It seems like backing up was a hot enough topic that the Google Gmail team are releasing an official backup method. It&#39;s not completely in the wild yet but I definitely look forward to poking around in it.
Now if only Google let you download everything they know about you as well&amp;hellip; Would definitely make for an interesting read.</description>
    </item><item>
      <title>Taking Back the Sky</title>
      <link>https://stelfox.net/blog/2013/12/taking-back-the-sky/</link>
      <pubDate>Wed, 04 Dec 2013 13:18:15 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/12/taking-back-the-sky/</guid>
      <description>During my daily review of various new sources I came across one particular article that was both concerning and very amusing. Drones have been getting more and more popular, and more accessible. They&#39;ve been getting used by the military, law enforcement, recently Amazon (though they&#39;ve abandoned that for now), you can even purchase one for your iPhone at airports.
The security of these systems hasn&#39;t been thoroughly tested publicly, though there is at least one report of a military drone being stolen already.</description>
    </item><item>
      <title>Fail Fast in Bash Scripts</title>
      <link>https://stelfox.net/blog/2013/11/fail-fast-in-bash-scripts/</link>
      <pubDate>Tue, 26 Nov 2013 15:19:40 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/11/fail-fast-in-bash-scripts/</guid>
      <description>I found myself writing another bash script that should exit should any of the few commands within it fail to run. As I began writing some error handling after each command, and isolating the sections into bash functions I figured there had to be a better way. After a little Googling and a trip through the bash man pages sure enough:
#!/bin/bash  function error_handler() { echo &amp;#34;Error occurred in script at line: ${1}.</description>
    </item><item>
      <title>Using VIM as Your Password Manager</title>
      <link>https://stelfox.net/blog/2013/11/using-vim-as-your-password-manager/</link>
      <pubDate>Mon, 25 Nov 2013 15:10:46 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/11/using-vim-as-your-password-manager/</guid>
      <description>There are all kinds of password managers out there. Everything from web services that are quite solid and respectable, to native desktop apps.
A lot of these are simply too heavy for me, involve installing software on a computer to access in addition to sharing the file around, or required you to remember multiple account details before you could get access to any individual password.
Due too the various complexities and lack of matching use cases a couple years ago I set out to develop my own open-source version of PassPack.</description>
    </item><item>
      <title>Backing up Gmail with fetchmail</title>
      <link>https://stelfox.net/blog/2013/11/backing-up-gmail-with-fetchmail/</link>
      <pubDate>Tue, 19 Nov 2013 09:55:40 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2013/11/backing-up-gmail-with-fetchmail/</guid>
      <description>This morning I found myself in need of a large set of emails to test a particular set of code. Ideally these emails would be broken out into easily digestible pieces, and it was strictly for my own personal testing so I wasn&#39;t concerned with using my own live data for this test (There will probably be another post on this project later on).
Having used fetchmail with good results in the past I decided it was a good idea to take this opportunity to also backup my Gmail account into the common Maildir format (which essentially breaks out emails into individual files meeting my requirements).</description>
    </item><item>
      <title>Ruby&#39;s Option Parser - a More Complete Example</title>
      <link>https://stelfox.net/blog/2012/12/rubys-option-parser-a-more-complete-example/</link>
      <pubDate>Sun, 02 Dec 2012 22:59:00 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2012/12/rubys-option-parser-a-more-complete-example/</guid>
      <description>Recently while writing a Ruby program I needed to parse some command line options. Helpfully Ruby provides a module named OptionParser to make this easy. I found a few parts of the documentation ambiguous and a few others down right confusing.
The catch I hit was the required field. In my mind the definition of a required argument is something that needs to be passed on the command line to continue.</description>
    </item><item>
      <title>Keep Your Gems Updated</title>
      <link>https://stelfox.net/blog/2012/11/keep-your-gems-updated/</link>
      <pubDate>Tue, 27 Nov 2012 14:17:00 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2012/11/keep-your-gems-updated/</guid>
      <description>I recently went back through my backups recently and found quite a few old abandoned projects. Looking back on the code I see some things I&#39;m impressed with, but the majority of the code I wouldn&#39;t write today. That&#39;s not to say the code is bad, or doesn&#39;t function. It did exactly what I wanted to accomplish at the time, just not necessarily in the most efficient way.
This archive of old code made me start wondering how much old code I&#39;m using in the projects that I&#39;m currently writing.</description>
    </item><item>
      <title>Auditing Heroku SSH Keys</title>
      <link>https://stelfox.net/blog/2012/11/auditing-heroku-ssh-keys/</link>
      <pubDate>Mon, 26 Nov 2012 10:18:00 -0500</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2012/11/auditing-heroku-ssh-keys/</guid>
      <description>A good friend of mine recently left the organization I work for and the task of resetting our passwords and auditing credentials fell on me. Since we use Heroku for our development platform I needed to not only reset the credentials for the web portion (which conveniently also handles resetting the API key) but also revoke any SSH keys he may have added to access it.
Sadly Heroku does not seem to provide any web interface that I could find for examining what keys were associated with the account.</description>
    </item><item>
      <title>CarrierWave, S3 and Filenames</title>
      <link>https://stelfox.net/blog/2012/08/carrierwave-s3-and-filenames/</link>
      <pubDate>Thu, 09 Aug 2012 20:00:57 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2012/08/carrierwave-s3-and-filenames/</guid>
      <description>This is going to be a real quick post. I&#39;m using the &amp;ldquo;carrier_wave&amp;rdquo; gem with &amp;ldquo;fog&amp;rdquo; for one of my projects and found that when a file is stored on S3 the &amp;ldquo;identifier&amp;rdquo;, and &amp;ldquo;filename&amp;rdquo; methods return nil. I got around this issue in two separate ways neither of which I&#39;m particularly happy about.
Outside of the uploader, you can use the File utility and the URL of the object to get the base filename like so:</description>
    </item><item>
      <title>Security Through Obesity</title>
      <link>https://stelfox.net/blog/2012/08/security-through-obesity/</link>
      <pubDate>Wed, 08 Aug 2012 15:06:56 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2012/08/security-through-obesity/</guid>
      <description>Jeremy Spilman recently proposed changes to how user&#39;s hashes are stored in website&#39;s and companies databases. This post was originally going to look at some of the issues involved in the scheme he envisioned, however, he rather quickly posted a followup article with a well thought out solution that countered all of the issues that other people and myself were able to come up with. I&#39;d strongly recommend reading both if you haven&#39;t done so.</description>
    </item><item>
      <title>Adding a Table Prefix to DataMapper Tables</title>
      <link>https://stelfox.net/blog/2012/08/adding-a-table-prefix-to-datamapper-tables/</link>
      <pubDate>Tue, 07 Aug 2012 14:09:33 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2012/08/adding-a-table-prefix-to-datamapper-tables/</guid>
      <description>So I recently encountered a situation where I needed to define a prefix on the tables used by the &amp;ldquo;data_mapper&amp;rdquo; gem. When I went searching I found quite a bit of information about similar projects in Python, and PHP named DataMapper but nothing about the ruby &amp;ldquo;data_mapper&amp;rdquo;. The search continued eventually ending in my reading through the source of the data_mapper gem only to find that there was no feature for simply defining a prefix.</description>
    </item><item>
      <title>Thoughts on IPv6 Security and Mitigation</title>
      <link>https://stelfox.net/blog/2012/07/thoughts-on-ipv6-security-and-mitigation/</link>
      <pubDate>Sun, 22 Jul 2012 03:07:42 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2012/07/thoughts-on-ipv6-security-and-mitigation/</guid>
      <description>I setup IPv6 on my home network with an OpenWRT router and Hurricane Electric and now I suddenly have an opinion on the state of IPv6 security. This is something that I&#39;ve been meaning to do for some time and have been mulling over in the back of my mind. I&#39;ll go over the details from start to finish of setting up hurricane electric on the router in another post as the information to do so is very scattered and disjointed.</description>
    </item><item>
      <title>Ruby&#39;s XMLRPC::Client and SSL</title>
      <link>https://stelfox.net/blog/2012/02/rubys-xmlrpcclient-and-ssl/</link>
      <pubDate>Tue, 14 Feb 2012 18:08:51 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2012/02/rubys-xmlrpcclient-and-ssl/</guid>
      <description>For the past few days I&#39;ve been working on a Ruby project that needed to interact with a remote XMLRPC API. This isn&#39;t particularly unusual but it was the first time from within a Ruby application. Luckily enough Ruby has a built in XMLRPC client that handles a lot of the messy bits.
The XMLRPC::Client class itself seems fairly simple. There are only a handful of methods, five of which are for opening a new connection in a few different ways, and at least two ways to open each type of connection.</description>
    </item><item>
      <title>Exploration of an ACN Iris 3000</title>
      <link>https://stelfox.net/blog/2011/05/exploration-of-a-acn-iris-3000/</link>
      <pubDate>Sun, 01 May 2011 15:48:08 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2011/05/exploration-of-a-acn-iris-3000/</guid>
      <description>So I found a dirt cheap video SIP phone (ACN Iris 3000) at a local HAM fest. After looking around I found the vendor has locked in the phone with their specific service with an iron grip and had gone out of business. I guess I should expect that kind of anti-competitive behavior from a business that Donald Trump has a vested interest in.
I&#39;ve come across one post on a forum that seems to have been crawled and copied out every where.</description>
    </item><item>
      <title>Linux N Issues &amp; KDE Multi-Monitor Woes</title>
      <link>https://stelfox.net/blog/2011/02/linux-n-issues-kde-multi-monitor-woes/</link>
      <pubDate>Fri, 25 Feb 2011 14:37:39 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2011/02/linux-n-issues-kde-multi-monitor-woes/</guid>
      <description>So I recently did a fresh install of Fedora 14 with KDE installed (not the KDE spin mind you) on my ThinkPad. I&#39;m pleasantly surprised with hows it&#39;s working everything seems to be working out the box very stably. I used it without issue for a solid month and a half without a single issue.
Earlier this week I started having issues with my wireless card on some networks, but not at all of them.</description>
    </item><item>
      <title>The Home Network and NAT as a Security Layer</title>
      <link>https://stelfox.net/blog/2011/02/the-home-network-and-nat-as-a-security-layer/</link>
      <pubDate>Thu, 17 Feb 2011 18:15:02 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2011/02/the-home-network-and-nat-as-a-security-layer/</guid>
      <description>One of the hot-topics for IPv6 (which I have been thinking about a lot lately) is NAT. I normally wouldn&#39;t go into detail about specifics that are obvious to people in my field but for the sake of this post I will. NAT or Network Address Translation, is a way for a large number of computers to share a single public IP address.
The router that is handling the NAT will keep track of connections coming in and out of it and re-write the destination IP to an internal address to keep the traffic flowing.</description>
    </item><item>
      <title>Image Crawler Meets rm -f *</title>
      <link>https://stelfox.net/blog/2009/11/image-crawler-meets-rm-f/</link>
      <pubDate>Wed, 04 Nov 2009 21:36:45 +0000</pubDate>
      <author>Sam Stelfox</author>
      <guid>https://stelfox.net/blog/2009/11/image-crawler-meets-rm-f/</guid>
      <description>I wrote a simple web crawler that archived any images it found from a site with a large number of backgrounds. I wanted to have rolling backgrounds that almost never repeated.
I let my crawler go and stopped it after a 24 hour period. I ran ls on the directory the images were being saved in to see the results and my ssh session locked up&amp;hellip; Or so I thought. I hit Ctrl-C and nothing happened&amp;hellip; So I closed my window and opened a new one.</description>
    </item></channel>
</rss>
