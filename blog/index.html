<!DOCTYPE html>
<html lang='en_US'>
  <head>
    <title>Blog - Stelfox Athen&#xe6;um</title>

    <meta http-equiv='content-type' content='text/html; charset=utf-8' />
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1' />
    
    

    <link rel="alternate" type="application/atom+xml" title="Stelfox Athen&#xe6;um Feed" href="/atom.xml" />
    <link rel="canonical" href="https://stelfox.net" />
    <link rel="author" href="https://plus.google.com/+SamStelfox31337/"/>

    <meta property="og:locale" content="en_US" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Blog" />
    <meta property="og:url" content="https://stelfox.net/blog/" />
    <meta property="og:site_name" content="Stelfox Athen&#xe6;um" />
    <meta property="article:publisher" content="https://www.facebook.com/sstelfox" />
    <meta property="og:image" content="https://stelfox.net/static/avatar-01.jpg" />

    <meta name="go-import" content="stelfox.net git https://io.stelfox.net/" />

    <link rel='stylesheet' href="//fonts.googleapis.com/css?family=Open+Sans:300,400italic,400,600,700|Alegreya+SC:700" />
    <link rel="stylesheet" href="https://stelfox.net/css/3HrCRVwL3Gos2V4HzXAw/Om/nxs=.css" />

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
       (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
       m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
       })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-32188490-1', 'stelfox.net');
      ga('require', 'displayfeatures');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <header class='masthead'>
      <div class='masthead-inner'>
        <h1><a href='/' title='Home'>Sam Stelfox</a></h1>
        <p class='lead'>Thoughts from a systems hacker and developer.</p>
        <nav>
          <ul>
            <li><a href="/about/" title="About">About</a></li>
            <li><a href="/blog/" title="Blog">Blog</a></li>
            <li><a href="/knowledge_base/" title="Knowledge Base">Knowledge Base</a></li>
            <li><form action="/search/" method="get"><input type="search" name="q" placeholder="Search" /></form></li>
          </ul>
        </nav>
        <footer class='colophon'>
          <p>&copy; 2014, All rights reserved.</p>
        </footer>
      </div>
    </header>
    <div class='content container'>
      
  <div class='post'>
    <h1><a href="/blog/2015/04/ruby-code-quality-metrics/">Ruby Code Quality Metrics</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on April 22, 2015</time> by Sam Stelfox</aside>
    <article>
      <p>I like getting unopionated feedback on the quality of the code I write.
Sometimes I can get this from other developers but they tend to get annoyed
being asked after every commit whether they consider it an approvement.</p>

<p>There are a few utilities for Ruby codebases such as <a href="https://github.com/seattlerb/flay">flay</a>, <a href="https://github.com/seattlerb/flog">flog</a>, and
<a href="https://github.com/bbatsov/rubocop">rubocop</a> as well as hosted services such as <a href="https://codeclimate.com/">Code Climate</a> that can help
you identify chunks of code that can use some work.</p>

<p>While not directly connected to the quality of the code, I also make use of
<a href="http://yardoc.org/">yard</a> and <a href="https://github.com/colszowka/simplecov">simplecov</a> to assess documentation and test coverage of the
codebases I work on.</p>

<p>Using the tools means very little without some reference or understanding
doesn&#39;t get you very far. For a while I&#39;ve been using flog and only comparing
the numbers against other codebases I control. I finally googled around and
found a <a href="http://jakescruggs.blogspot.com/2008/08/whats-good-flog-score.html">blog post</a> by a developer named Jake Scruggs from a while ago
(2008).</p>

<p>The blog post includes a rough table for assessing scores on individual methods
reported from the flog utility. From what I can tell the ranges are still
pretty accurate. I&#39;ve tweaked the descriptions a bit to fit my mental
understanding a bit but the table is here:</p>

<table><thead>
<tr>
<th>Method Score</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td>0   - 10</td>
<td>Awesome</td>
</tr>
<tr>
<td>10  - 20</td>
<td>Decent</td>
</tr>
<tr>
<td>20  - 40</td>
<td>Might need refactoring</td>
</tr>
<tr>
<td>40  - 60</td>
<td>Should probably review</td>
</tr>
<tr>
<td>60  - 100</td>
<td>Danger</td>
</tr>
<tr>
<td>100 - 200</td>
<td>Raise the alarm</td>
</tr>
<tr>
<td>200+</td>
<td>Seriously what are you doing!?</td>
</tr>
</tbody></table>

<p>I wanted to extend this with a second table providing a scale for the overall
method average with a more aggressive scale (an individual couple of methods
can be justifiably complex but the overall code base shouldn&#39;t be riddled with
them) but had a hard time working it out.</p>

<p>I&#39;ve seen some awesome code bases with a score of 6.4 on average, some bad
larger ones with 7.8. Even some mediocre ones around a score of 10.6.</p>

<p>I guess I&#39;ll have to think more on it...</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2015/04/creating-an-empty-git-branch/">Creating an Empty Git Branch</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on April 13, 2015</time> by Sam Stelfox</aside>
    <article>
      <p>Every now and then I find myself wanting to create a new empty branch in an
existing repository. It&#39;s useful for things such as [Github Pages][1] so you&#39;re
able to keep your content source in the master branch while only keeping the
output in the gh-pages branch. I&#39;ve also used it for testing a complete rewrite
of a code base without the overhead of creating a new repo and copying access
permissions.</p>

<p>This is a pretty straight forward trick to do. You create the brach by
indicating you want the new branch to be an orphan by passing the &#39;--orphan&#39;
flag like so:</p>
<div class="CodeRay">
  <div class="code"><pre>git checkout --orphan NEW_BRANCH_NAME
</pre></div>
</div>

<p>This leaves all the files in place but effectively uncommitted like you just
initialized a new repository. Add and commit any files you&#39;d like to keep then
delete the rest, everything will still be preserved in the original branches.</p>

<p>With that done you should be able to easily switch just using a normal
&#39;checkout&#39; between your normal branches and this new tree.</p>

<p>[1]:</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2015/02/unbuffered-pipe-filters/">Unbuffered Pipe Filters</a></h1>
    <aside class="post-date">Published <time datetime=''>during lunch on February 23, 2015</time> by Sam Stelfox</aside>
    <article>
      <p>I need to filter a live logstream for only relevant events and quickly hit an
issue that I wasn&#39;t expecting. The <code>grep</code> in my pipe chain was waiting until it
received all the output from the prior command before it began to attempt to
filter it.</p>

<p>Reading through the grep man page I came across the <code>--line-buffered</code> flag
which provides exactly what I needed. I wasn&#39;t using the <code>tail</code> command but it
serves really well in this situation to demonstrate the use:</p>
<div class="CodeRay">
  <div class="code"><pre>tail -f /var/log/maillog | grep --line-buffered -i error
</pre></div>
</div>

<p>Hope this saves someone a headache in the future!</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/08/dependency-prelink-issues/">Dependency Prelink Issues</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on August 12, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>While running an aide check on one of my servers after updating it, I started
seeing a large number of very concerning warning messages:</p>
<div class="CodeRay">
  <div class="code"><pre>/usr/sbin/prelink: /bin/mailx: at least one of file's dependencies has changed since prelinking
Error on exit of prelink child process
/usr/sbin/prelink: /bin/rpm: at least one of file's dependencies has changed since prelinking
Error on exit of prelink child process
/usr/sbin/prelink: /sbin/readahead: at least one of file's dependencies has changed since prelinking
Error on exit of prelink child process
/usr/sbin/prelink: /lib64/libkrb5.so.3.3: at least one of file's dependencies has changed since prelinking
Error on exit of prelink child process
/usr/sbin/prelink: /lib64/libgssapi_krb5.so.2.2: at least one of file's dependencies has changed since prelinking
</pre></div>
</div>

<p>The list went on with maybe a total of forty packages and libraries. My initial
reaction was &#39;Did I get hacked?&#39;. Before running the updates I ran an aide
verification check which returned no issues and the files that were now
displaying the issue were in the packages that got updated.</p>

<p>What was the next worse scenario? The packages had been tampered with and I
just installed malicious files. This didn&#39;t seem likely as the packages are all
signed with GPG and an aide check would have caught tampering with my trust
database, the gpg binary, or the aide binary. Still a key could have been
comprimised.</p>

<p>After some Googling I came across people with similar issues, (including one
annoyingly paywalled RedHat article on the issue). Several people simply ended
the conversation on the assumption the user with the issue had been hacked.
Finally I <a href="http://lists.centos.org/pipermail/centos/2007-December/049222.html">came across one helpful individual</a> with the fix. The binaries
just need to have their prelink cache updated again. This can be accomplished
with the following command on CentOS 6.5 (probably the same on others).</p>
<div class="CodeRay">
  <div class="code"><pre>/usr/sbin/prelink -av -mR
</pre></div>
</div>

<p><em>Update:</em> Ultimately I decided to follow <a href="/knowledge_base/linux/hardening/">my own advice</a> (search for
prelink) and just simply disabled prelinking too prevent it from interferring
with aide checks and causing other weird issues. The memory trade-off isn&#39;t
valuable enough for me.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/08/fast-hex-to-decimal-in-bash/">Fast Hex to Decimal in Bash</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on August 1, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I needed too turn some hexidecimal values into decimal in a bash script and
found a real easy way too do it. The following is a very short bash script
demostrating how too turn the hexidecimal string &quot;deadbeefcafe&quot; into it&#39;s
equivalent decimal value of &quot;244837814094590&quot;.</p>
<div class="CodeRay">
  <div class="code"><pre>#!/bin/bash

INPUT=&quot;deadbeefcafe&quot;
OUTPUT=$((0x${INPUT}))

echo $OUTPUT
</pre></div>
</div>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/07/spf-and-dkim-records-in-route-53/">SPF & DKIM Records in Route 53</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on July 30, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I&#39;m going to do a more detailed post on emailing from Amazon&#39;s infrastructure
soon, but in the meantime I wanted to quickly throw out solutions too a couple
of problems I encountered. These are all specific too Amazon&#39;s Route 53, and
most are user error (myself).</p>

<h2>SPF Invalid Characters or Format</h2>

<p>After generating my SPF record, I jumped into Route 53, created a new record
pasted in my record, attempted to save and received the following message:</p>

<blockquote>
<p>The record set could not be saved because:</p>

<ul>
<li>The Value field contains invalid characters or is in an invalid format.</li>
</ul>
</blockquote>

<p>I was using the SPF record type at a time (see the next section) and assumed
that I had messed up the format of my record in some way. I banged my head
against the wall and through RFCs thoroughly before I found the solution...</p>

<p>Solution: Wrap your SPF records in quotation characters.</p>

<h2>No SPF Record Found / Validation Failure</h2>

<p>Since I have my DMARC policy in place (I&#39;ll cover this in my email follow up),
I receive daily domain reports from Google whenever something fails validation
about my domain. After switching to Route 53 for DNS the <code>authresult</code> component
started showing up as fail for SPF.</p>

<p>Testing around a few online SPF validators indicated that none of them were
able to see my new SPF record, and there had been plenty of time for it too
propagate.</p>

<p>The SPF resource record type (RRTYPE 99) is available in Route 53 even though
<a href="https://tools.ietf.org/html/rfc6686#section-3.1">the record type has been deprecated</a>. Not being familiar with this
particular decision, I assumed I should be using it <em>instead</em> of the TXT record
I&#39;ve used for every other domain, and it would be handled correctly or more
intelligently.</p>

<p>Solution: Either switch the SPF record too a TXT record. or my preference
duplicate it into a TXT record so you have both.</p>

<h2>Invalid DKIM record</h2>

<p>This one had me scratching my head for a while. This was my first time
deploying DKIM on a domain that I was not running a Bind name server for.
OpenDKIM is nice enough too generate a Bind record for you which works
perfectly. It&#39;s output looks like the following:</p>
<div class="CodeRay">
  <div class="code"><pre>default._domainkey.example.tld.   IN      TXT     ( &quot;v=DKIM1; k=rsa; t=y; s=email; &quot;
          &quot;p=MIHfMA0GCSqGSIb3DQEBAQUAA4HNADCByQKBwQC2Cwpa/+Xhfkzn0QnyQoxRwoJPb+s51dIt9UtFLMlMFuYa/k3GBwZ7UWeyAaQJ3RibSzKV/YwgFuMrzyISrLNSuL2k1bQlQQG8nl23Mu9Mowcb+mV2/3G7roshK6kOLNA0IV2SBl8/0UoNZR/x7c1lzVtVqdj0vW1SsJzgGfbt4LGRvCPyjdg+SLpYtOd/Li4Y1pvHgSRKQRrklpKeJo&quot;
          &quot;nJQ4+lXWqzYtuX9xdNH46ck2HUl56Ob4cy3/gYCJBWrAsCAwEAAQ==&quot; )  ; ----- DKIM key default for example.tld
</pre></div>
</div>

<p>Copying and pasting everything between the parens in the value field and
pasting them into Route 53 works flawlessly. The catch? This won&#39;t be treated
as a single record, but three individual responses. None of which are complete
and valid DKIM records.</p>

<p>This happens because Route 53&#39;s value field treats newlines as separate
records.</p>

<p>Solution: Turn it into one long string so it isn&#39;t covering multiple lines
right? Not quite...</p>

<h2>TXTRDATATooLong</h2>

<p>Combining the DKIM key into one string like so:</p>
<div class="CodeRay">
  <div class="code"><pre>&quot;v=DKIM1; k=rsa; t=y; s=email; p=MIHfMA0GCSqGSIb3DQEBAQUAA4HNADCByQKBwQC2Cwpa/+Xhfkzn0QnyQoxRwoJPb+s51dIt9UtFLMlMFuYa/k3GBwZ7UWeyAaQJ3RibSzKV/YwgFuMrzyISrLNSuL2k1bQlQQG8nl23Mu9Mowcb+mV2/3G7roshK6kOLNA0IV2SBl8/0UoNZR/x7c1lzVtVqdj0vW1SsJzgGfbt4LGRvCPyjdg+SLpYtOd/Li4Y1pvHgSRKQRrklpKeJonJQ4+lXWqzYtuX9xdNH46ck2HUl56Ob4cy3/gYCJBWrAsCAwEAAQ==&quot;
</pre></div>
</div>

<p>And attempting to save results in the following error message:</p>

<blockquote>
<p>Invalid Resource Record: FATAL problem: TXTRDATATooLong encountered at ...<snip></p>
</blockquote>

<p>Now we&#39;re left in a tricky spot. After some research the reason behind this is
clear, and makes sense. Though it is another poor usability bug in the way
Amazon&#39;s Route 53 behaves. Individual DNS UDP packets are limited too 255
characters for their response.</p>

<p>Too properly deliver records longer than that DNS servers are supposed to break
up the response into chunks. Properly implemented clients combine these chunks
together (with no spaces, newlines or other characters added). What this means
is that the record can be broken up transparently behind the scenes anywhere in
the message and the client will put it back together correctly.</p>

<p>The Route 53 entry form won&#39;t handle this for you though, and in hindsight it
looks like Bind might not do it for you though I suspected that was more for
readability of zone files rather than a technical limitation (and I haven&#39;t
tested whether Bind is intelligent enough too handle just a long string).</p>

<p>Solution: Take the original output of Bind between the parens and just remove
the newline characters, leave the quotation marks and spaces between the
sections like the following sample and you&#39;ll be golden:</p>
<div class="CodeRay">
  <div class="code"><pre>&quot;v=DKIM1; k=rsa; t=y; s=email; &quot; &quot;p=MIHfMA0GCSqGSIb3DQEBAQUAA4HNADCByQKBwQC2Cwpa/+Xhfkzn0QnyQoxRwoJPb+s51dIt9UtFLMlMFuYa/k3GBwZ7UWeyAaQJ3RibSzKV/YwgFuMrzyISrLNSuL2k1bQlQQG8nl23Mu9Mowcb+mV2/3G7roshK6kOLNA0IV2SBl8/0UoNZR/x7c1lzVtVqdj0vW1SsJzgGfbt4LGRvCPyjdg+SLpYtOd/Li4Y1pvHgSRKQRrklpKeJo&quot; &quot;nJQ4+lXWqzYtuX9xdNH46ck2HUl56Ob4cy3/gYCJBWrAsCAwEAAQ==&quot;
</pre></div>
</div>

<p>Hope this helps someone else!</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/07/unregistering-from-whisperpush-after-flashing-a-new-rom/">Unregistering From WhisperPush After Flashing a New ROM</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on July 22, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I&#39;ve been playing around with my Nexus 5 lately. It was quickly rooted and I
began playing with various ROMs that had been pre-built for the Nexus 5. My
first stop was the <a href="http://www.cyanogenmod.org/">CyanogenMod</a>. Since I&#39;d last used CyanogenMod they added
a built-in framework that provides <a href="https://whispersystems.org/blog/cyanogen-integration/">transparent text</a> <a href="http://www.cyanogenmod.org/blog/whisperpush-secure-messaging-integration">message
encryption</a> called WhisperPush.</p>

<p>WhisperPush is an implementation of <a href="http://thoughtcrime.org/">Moxie Marlinspike&#39;s</a> highly respected
TextSecure and I was very excited at the possibility of using it. I immediately
signed up for the service.</p>

<p>After a day of use I found CyanogenMod far too unstable too use on my primary
device. It locked up multiple times the first day and mobile data simply
wouldn&#39;t work all day. I promptly formatted and flashed my phone, I haven&#39;t
settled on a new ROM but that&#39;s not what this post is about.</p>

<p>It occurred to me after flashing the phone I was still subscribed to
WhisperPush. If anyone that texts me was signed up as well. I&#39;d never receive
even an encrypted blob, it would just silently fail.</p>

<p>Searching around I found there is very little information on it, and no
official way to unregister, especially after you&#39;ve wiped your device and no
longer have your credentials. Ultimately I found a fairly easy solution, just
re-register and perform the backdoor steps too de-register.</p>

<p>I wiped my phone again and installed a new copy of the CyanogenMod nightly.
Booted it up and re-enabled WhisperPush. It didn&#39;t even note that my number was
registered in the past.</p>

<p>I found the solution somewhere in the CyanogenMod forums (though I lost the
link, and I&#39;m now too lazy to go find it again). You can unregister by
performing the following steps:</p>

<ol>
<li>Connect your computer with ADB too the phone and pair the computer with the
phone.</li>
<li>Enable developer options by opening the system settings, choosing &#39;About
phone&#39; and clicking on the &#39;Build number&#39; about 7 times (it will start
counting down).</li>
<li>Open up the developer options found in the root of the system settings menu
and enable root access for &#39;Apps and ADB&#39;.</li>
<li>On the computer use <code>adb shell</code> to get a shell on the device.</li>
<li>Switch to root using the <code>su</code> command.</li>
<li><p>Run the following command too view the WhisperPush internal settings:</p>
<div class="CodeRay">
  <div class="code"><pre>cat /data/user/0/org.whispersystems.whisperpush/shared_prefs/org.whispersystems.whisperpush_preferences.xml`
</pre></div>
</div></li>
<li><p>Note down the value for <code>pref_registered_number</code> (this should be your phone
number with a preceeding &#39;+&#39;) and <code>pre_push_password</code>.</p></li>
<li><p>Exit the shell.</p></li>
</ol>

<p>Finally too unregister we need too make a DELETE request against the
WhisperPush API. The classic HTTP swiss army knife <code>curl</code> is going to help us
on this front. Run the following command on any linux computer with curl
installed, replacing the registered number and registered password with the
value you recorded earlier.</p>
<div class="CodeRay">
  <div class="code"><pre>curl -v -k -X DELETE --basic --user ${pref_registered_number}:${pre_push_password} https://whisperpush.cyanogenmod.org/v1/accounts/gcm
</pre></div>
</div>

<p>Be sure too include the &#39;+&#39; in your pref_registered_number. You should end up
with a status code of 204. The output will look something like the following
(credentials removed).</p>
<div class="CodeRay">
  <div class="code"><pre>* About to connect() to whisperpush.cyanogenmod.org port 443 (#0)
*   Trying 54.201.5.27...
* Connected to whisperpush.cyanogenmod.org (54.201.5.27) port 443 (#0)
* Initializing NSS with certpath: sql:/etc/pki/nssdb
* skipping SSL peer certificate verification
* SSL connection using TLS_DHE_RSA_WITH_AES_128_CBC_SHA
* Server certificate:
*   subject: OU=Operations,O=&quot;Cyanogen, Inc.&quot;,E=ops@cyngn.com,C=US,ST=Washington,L=Seattle,CN=whisperpush.cyanogenmod.org
*   start date: Nov 26 05:39:18 2013 GMT
*   expire date: Nov 24 05:39:18 2023 GMT
*   common name: whisperpush.cyanogenmod.org
*   issuer: E=ops@cyngn.com,CN=Authority,OU=Operations,O=&quot;Cyanogen, Inc.&quot;,L=Seattle,ST=Washington,C=US
* Server auth using Basic with user '${pref_registered_number}'
&gt; DELETE /v1/accounts/gcm HTTP/1.1
&gt; Authorization: Basic ${encoded credentials}
&gt; User-Agent: curl/7.29.0
&gt; Host: whisperpush.cyanogenmod.org
&gt; Accept: */*
&gt; 
&lt; HTTP/1.1 204 No Content
&lt; Server: nginx/1.1.19
&lt; Date: Wed, 23 Jul 2014 01:45:25 GMT
&lt; Connection: keep-alive
&lt; 
* Connection #0 to host whisperpush.cyanogenmod.org left intact
</pre></div>
</div>

<p>I don&#39;t have any way too check that I&#39;m unregistered but it seems too have
worked. Here is hoping this helps some else out in the future.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/07/using-openwrts-dnsmasq-as-a-tftp-server/">Using OpenWRT's Dnsmasq as a TFTP Server</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on July 1, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I recently reflashed my primary router to a newer version of OpenWRT and
attempted to follow <a href="/blog/2013/12/using-dnsmasq-as-a-standalone-tftp-server/">my own directions</a> written in an earlier blog post to
add PXE booting to my local network using the dnsmasq service built in. After
following my advice I found that the dnsmasq service wasn&#39;t starting.</p>

<p>Looking into the <code>logread</code> output I finally saw that this was due too a
permission issue. Combining this with the output of <code>ps</code> too identify the user
that dnsmasq was running on I was able to both modify my instructions and use
OpenWRT&#39;s own config system to perform the configuration instead of modifying
the dnsmasq configuration.</p>

<p>First was solving the permissions issue. I created a dedicated directory at
<code>/var/tftp</code> and changed the ownership to &#39;nobody&#39; and &#39;nogroup&#39; and mode too
&#39;0755&#39;.</p>

<p>Previously I used <code>/var/lib/tftp</code>, however, the default permissions on the
<code>/var/lib</code> directory is too restrictive and I didn&#39;t want to reduce the rest of
that directories security posture simply too allow directory traversal.</p>

<p>Next up was getting the TFTP portion of dnsmasq configured and running. Open up
<code>/etc/config/dhcp</code> and under the &#39;dnsmasq&#39; section add the following lines (or
if these lines already exist adjust the values to match).</p>
<div class="CodeRay">
  <div class="code"><pre>  option enable_tftp '1'
  option tftp_root '/var/tftp'
  option dhcp_boot 'pxelinux.0'
</pre></div>
</div>

<p>Run <code>uci commit dhcp</code> too commit the changes and finally <code>/etc/init.d/dnsmasq
restart</code> To apply the changes. You&#39;ll want too put the &#39;pxelinux.0&#39; and
associated configuration files into the <code>/var/tftp</code> directory too complete the
PXE booting configuration.</p>

<p>I&#39;ll probably write a blog post covering my PXE setup and configuration if I
don&#39;t get distracted by other projects.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/06/fixing-erratic-bmc-controller-on-poweredge-c6100/">Fixing Erratic BMC Controller on PowerEdge C6100</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on June 30, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I randomly started experiencing an issue with one blade in one of my PowerEdge
C6100 blades. It wouldn&#39;t obey all commands issued too it via IPMI or through
the BMC&#39;s web interface. Additionally the blade would randomly power on when
off, and the front light would consistently blink as if a hardware fault was
detected.</p>

<p>This has been bothering me for a while, but it was my spare blade and wasn&#39;t
affecting my lab in anyway so I&#39;ve ignored it. I finally needed it for a
project and looked into what may be causing the issue.</p>

<p>A <a href="http://forums.servethehome.com/index.php?threads/dell-c6100-anyone-brick-a-board-yet.1448/">thread</a> on the Serve the Home forums lead to me too a solution, even
though my symptoms didn&#39;t quite match up with what I was experiencing.</p>

<p>I downloaded the <a href="http://ftp.dell.com/Manuals/all-products/esuprt_ser_stor_net/esuprt_cloud_products/poweredge-c6100_Owner%27s%20Manual_en-us.pdf">PowerEdge C6100 Owner&#39;s Manual</a> for the jumper
information, and found it too be redudant. The board itself has each of the
jumpers clearly labeled.</p>

<p>After pulling the affected chassis out of the server I connected the pins for
the CMOS reset, CMOS password reset, and system reset for about 15 seconds. I
pulled the jumpers, reinstalled the blade and it&#39;s happy once again. Problem
solved.</p>

<p><em>Update:</em> After performing a few commands via the web interface the issue
returned. I&#39;m still looking for a solution too the problem.</p>

<p><em>Update 2:</em> I&#39;m now suspecting that the issue may be related too me not
updating the FSB, which is responsible for handling power management of
individual nodes as well as reporting temperature and command response from the
BMC.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/06/aws-reserved-instance-pricing/">AWS Reserved Instance Pricing</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on June 6, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>The current large project I&#39;m working on is going to be hosted on AWS and I was
requested to do a cost estimate. Looking into it, it quickly became clear that
reserved instances could potentially save quite a bit of cash but there was a
catch (isn&#39;t there alway).</p>

<p>There is an upfront cost for reserving the instance and in exchange you get a
reduced hourly rate. After running the numbers one thing wasn&#39;t clear too me,
is the upfront cost credit towards running machines or a fee you never see
again?</p>

<p>I immediately assumed the latter based on the numbers for one simple reason. If
you use the &#39;Light Reserved Instance&#39; with a 1 year reservation, have your
machine running 24/7 the whole year it will cost your <em>more</em> than running the
same instance as &#39;on demand&#39;. This was true for their m1.small, m3.medium, and
m3.large which was the only ones I ran the numbers for.</p>

<p>I searched the internet and wasn&#39;t able to find a solid answer to the question
until I asked Amazon&#39;s customer service directly.</p>

<p>Ultimately there probably is a price point where 1 year light reserved
instances make sense, and if you&#39;re looking too run 24/7 for the whole year
you&#39;ll want to do a heavy anyway for the most savings but it still surprised
me.</p>

<p>I&#39;ll probably do a project later using <a href="http://d3js.org/">d3.js</a> to get some direct hours run
vs total cost for various instances. It&#39;ll probably be a fun project.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/06/modifying-the-hosts-file-in-a-docker-container/">Modifying the Hosts File in a Docker Container</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on June 3, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>Before I describe the issue that I encountered, let me be very clear. This hack
is <em>potentially dangerous and should absolutely only be done in development
environments</em>. This won&#39;t affect your host system, only the docker container so
the most damage you&#39;ll do is prevent hostname and possibly user/group lookups
within the container itself.</p>

<p>Alright with that out of the way, I was actively working on a codebase that
uses subdomains as part of the identifier. Rather than setup a full DNS server,
point my local system at it and load in the domains I wanted to simply modify
the /etc/hosts file inside the environment.</p>

<p>Docker mounts an /etc/hosts file inside it&#39;s containers, read-only, and the
container&#39;s &#39;root&#39; user has had it&#39;s mount permissions revoked so it&#39;s not able
to be modified. Other users have encountered this issue, and a <a href="https://stackoverflow.com/questions/19414543/how-can-i-make-etc-hosts-writable-by-root-in-a-docker-container">novel
workaround was put forward</a>. The solution however makes use of perl, and is
specific too ubuntu base systems.</p>

<p>I&#39;ll explain the solution after showing a more general way to accomplish the
same thing. Different linux systems will store their libraries in different
directory structures. CentOS is different from Fedora, which is different from
Ubuntu and Debian. All of them name their libraries, in this case we&#39;re looking
for &#39;libnss_files.so.2&#39;.</p>

<p>You can find where your copy of this library lives with the following command.
This should be run inside the docker container that you want to modify the
/etc/hosts file in.</p>
<div class="CodeRay">
  <div class="code"><pre>find / -name libnss_files.so.2 -print 2&gt; /dev/null
</pre></div>
</div>

<p>Pay attention to the path, multiple files may show up and you want the one that
matches your system&#39;s running kernel (generally x86_64 systems will have their
libraries in a lib64 directory).</p>

<p>Once you&#39;ve found this add the following lines to your Dockerfile. Make sure
you modify the path in the copy in the first line to the path of your copy of
the library. Once done you&#39;ll use the /var/hosts file to modify your hosts file
instead.</p>
<div class="CodeRay">
  <div class="code"><pre>RUN mkdir -p /override_lib &amp;&amp; cp /etc/hosts /var/ &amp;&amp; cp /usr/lib64/libnss_files.so.2 /override_lib
RUN sed -ie 's:/etc/hosts:/var/hosts:g' /override_lib/libnss_files.so.2
ENV LD_LIBRARY_PATH /override_lib
</pre></div>
</div>

<p>So what is this actually doing? On linux systems, name configurations such as
DNS, username, and group lookups are generally handled by the &#39;nss&#39; or name
service switch configuration tools including the hosts file. The library that
we&#39;re copying and modifying is a very specific to reading from files on the
system and includes the default paths to these files.</p>

<p>Generally you have to be very careful when you&#39;re manipulating strings within
compiled libraries. The length of the string is encoded along with it, so at a
minimum it&#39;s important that the string is <em>the same length or less</em>. You can
get away with less but it requires additionally writing an end of string
character as well.</p>

<p>Too make this hack simple, we&#39;re simply replacing the &#39;etc&#39; with &#39;var&#39;, both
systems directories that regular users generally should have read access but
not write access too.</p>

<p>Finally we need to tell all programs that need to perform lookups using
hostnames in the hosts file to make use of our modified library instead of the
system one. Linux will look for shared libraries at runtime in any paths set in
in the LD_LIBRARY_PATH (colon delimited just like PATH) and this doesn&#39;t
require any privileges too set.</p>

<p>And the result? An editable hosts file, with no extra services. I can&#39;t stress
enough though, there could be bad ramifications from modifying libraries this
way. This is definitely not a &#39;production ready&#39; hack.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/05/extracting-content-from-markdown/">Extracting Content From Markdown</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on May 30, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>Recently I&#39;ve been playing around with building a pure javascript full text
search engine for static content sites like this one. One of the challenges
with doing this has been working around the Markdown markup embedded in the
written content.</p>

<p>Most of the markdown syntax can be stripped out simply by removing all
non-alphanumeric characters from the document and move on. This doesn&#39;t solve
one of the bigger challenges I&#39;ve experienced... code blocks. Code blocks have
plenty of regular english-ish words and can easily skew keyword detection
within it.</p>

<p>I didn&#39;t want to write my own Markdown parser, so I started with the one
already in use by this site&#39;s renderer (<a href="https://github.com/vmg/redcarpet">redcarpet</a>). Another Github user,
<a href="https://github.com/toupeira">Markus Koller or toupeira on Github</a> provided <a href="https://github.com/vmg/redcarpet/issues/79">the basis</a> for the code
that became the redcarpet &quot;StripDown&quot; formatter, which was designed to
essentially render a Markdown document without the markup.</p>

<p>It does almost exactly what I want, except it still outputs raw code inside the
content. The following code sample includes a modified version that excludes
any code blocks. My content is also formatted inside the markdown documents to
never be longer than 80 lines, this also turns individual paragraphs and list
items into individual lines for paragraph detection.</p>
<div class="CodeRay">
  <div class="code"><pre>require <span class="string"><span class="delimiter">'</span><span class="content">redcarpet</span><span class="delimiter">'</span></span>
require <span class="string"><span class="delimiter">'</span><span class="content">redcarpet/render_strip</span><span class="delimiter">'</span></span>

<span class="keyword">class</span> <span class="class">ContentRenderer</span> &lt; <span class="constant">Redcarpet</span>::<span class="constant">Render</span>::<span class="constant">StripDown</span>
  <span class="keyword">def</span> <span class="function">block_code</span>(*args)
    <span class="predefined-constant">nil</span>
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="function">list_item</span>(content, list_type)
    content.gsub(<span class="string"><span class="delimiter">&quot;</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content"> </span><span class="delimiter">&quot;</span></span>) + <span class="string"><span class="delimiter">&quot;</span><span class="char">\n</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="function">paragraph</span>(text)
    text.gsub(<span class="string"><span class="delimiter">&quot;</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content"> </span><span class="delimiter">&quot;</span></span>) + <span class="string"><span class="delimiter">&quot;</span><span class="char">\n</span><span class="char">\n</span><span class="delimiter">&quot;</span></span>
  <span class="keyword">end</span>
<span class="keyword">end</span>

markdown = <span class="constant">Redcarpet</span>::<span class="constant">Markdown</span>.new(<span class="constant">ContentRenderer</span>, <span class="key">fenced_code_blocks</span>: <span class="predefined-constant">true</span>)
puts markdown.render(<span class="constant">File</span>.read(<span class="string"><span class="delimiter">'</span><span class="content">sample_markdown_article.md</span><span class="delimiter">'</span></span>))
</pre></div>
</div>

<p>The above code will print out just the content of the markdown formatted file
&#39;sample_markdown_article.md&#39;.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/05/pg-error-error-type-hstore-does-not-exist/">PG::Error: ERROR: Type 'Hstore' Does Not Exist</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on May 28, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I&#39;ve been using the PostgreSQL&#39;s hstore extension in a Rails application lately
and kept encountering the error that is this post&#39;s namesake. It would
specifically happen when a database had been dropped, recreated and I freshly
ran the migrations.</p>

<p>It seems that while Rails 4 supports the HStore datatype, it doesn&#39;t enable the
extension itself. I&#39;ve found two ways too solve this issue in wildly different
ways.</p>

<h2>First Solution: Enable HStore by Default</h2>

<p>This is the common solution that is recommended too solve this issue. It
enables the HStore extension by default on all newly created databases. Too
understand this you need to know a bit about PostgreSQL&#39;s behavior.</p>

<p>When a new database is created, PostgreSQL creates a copy of a special
pre-existing database named &#39;template1&#39; by default. Anything done too this
database will be reflected in all new databases, including enabling extensions.</p>

<p>Too enable the HStore extension on the <code>template1</code> database you can execute the
following command (generally as the postgres user or with your authentication
of choice).</p>
<div class="CodeRay">
  <div class="code"><pre>psql -d template1 -c 'CREATE EXTENSION hstore;'
</pre></div>
</div>

<h2>Second Solution: Rails Migration</h2>

<p>The above solution doesn&#39;t sit well with me. While it&#39;s uncommon for any
individual PostgreSQL server to be shared among different applications with
different databases, the possibility is there. Perhaps the application will get
de-commisioned and the DBA will simply drop the associated database and roles
instead of setting up a new one.</p>

<p>Disconnecting the requirements of the application from the application itself
always seems to lead too trouble.</p>

<p>Rails already has a mechanism too handle modifications too the database
overtime, migrations. They&#39;re solid, well tested, and encapsulate not only how
to get the database to a particular state but also how to return it back to
it&#39;s prior state (generally).</p>

<p>We can also do this without using raw SQL which now also seems a bit... off to
me. The following is a sample Rails migration that will both enable and disable
the extension:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="keyword">class</span> <span class="class">ManageHstore</span> &lt; <span class="constant">ActiveRecord</span>::<span class="constant">Migration</span>
  <span class="keyword">def</span> <span class="function">change</span>
    reversible <span class="keyword">do</span> |op|
      op.up { enable_extension <span class="string"><span class="delimiter">'</span><span class="content">hstore</span><span class="delimiter">'</span></span> }
      op.down { disable_extension <span class="string"><span class="delimiter">'</span><span class="content">hstore</span><span class="delimiter">'</span></span> }
    <span class="keyword">end</span>
  <span class="keyword">end</span>
<span class="keyword">end</span>
</pre></div>
</div>

<p>Now the biggest problem with this migration is that too use it, you need too
plan ahead of time too use the extension or not worry about freshly running all
the migrations (generally because you dropped and created the database). This
migration needs to be named so it alphabetically comes before any migration in
your application that makes use of the HStore datatype.</p>

<p>ActiveRecord uses timestamps at the beginning of the migration names to handle
this alphabetic sorting, and such you&#39;ll want to fake this in before you used
the HStore datatype.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/05/chain-loading-kernels/">Chain Loading Kernels</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on May 23, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I&#39;ve found several places where I needed to be able to update my kernels but
for one reason or another can&#39;t update the kernel that gets booted initially. A
couple of these situations were:</p>

<ul>
<li>Running Custom or Updated Kernels on DigitalOcean (this is one of their
biggest failings IMHO)</li>
<li>Allowing updating of kernels on embedded linux devices that require their
kernel flashed into NVRAM.</li>
<li>Running an embedded system that used an active/backup partition scheme for
updating.</li>
</ul>

<p>In all cases the process was pretty much the same, though there were some
custom changes to the preliminary init system depending on what I needed to get
done, especially with the last one which I may cover in a different article.</p>

<p>In all cases these were done on a RedHat based distribution like CentOS,
Scientific Linux, RHEL, or even Fedora. For those users of Debian based systems
you&#39;ll need to adjust the scripts too your system though I can&#39;t imagine
anything other than the package names changing.</p>

<p>This assumes you already have the kernel and initramfs you want to boot
installed on your local filesystem at <code>/boot/vmlinuz-custom</code> and
<code>/boot/initramfs.img</code>.</p>

<p>A quick background on how this works, when the linux kernel is compiled an init
program is configured to be the first thing triggered, by default and in most
situations this will be the executable <code>/sbin/init</code>. This init process is then
responsible for starting the rest of the daemons and processes that make up the
systems we regularly interact with.</p>

<p>There are tools that allow you too effectively execute another kernel to run in
place of the kernel that is already running. There are some catches though as
the new kernel won&#39;t always re-initialize all devices (since they&#39;ve already
been initialized) and that can lead too some weird behaviors with processes
that already have hooks on those devices.</p>

<p>Too prevent any issues you need to load the new kernel as early in the boot
process as possible. Doing this in the init program is pretty much as early as
you can get and makes for a pretty stable system (I&#39;ve yet to experience any
issues with machines running this way).</p>

<p>There are several different init systems and they all behave a little
differently, as far as I know only systemd supports a means of automatically
executing a different kernel but I am personally not a systemd fan and it would
be too late in the boot process already for me too trust the chain load. You
can reliably chain load kernels regardless of what your normal init system is
though very easily and that&#39;s what I&#39;m going to cover here.</p>

<p>You&#39;ll need to have the kexec tools installed on your system. This is pretty
straight-forward:</p>
<div class="CodeRay">
  <div class="code"><pre>yum install kexec-tools -y
</pre></div>
</div>

<p>Next we&#39;re going to shift the standard init process off to the side, someplace
still accessible so we can call it later (this will need to be done as root).</p>
<div class="CodeRay">
  <div class="code"><pre>mv /sbin/init /sbin/init.original
</pre></div>
</div>

<p>Now we need to create our own init script that will handle detecting if it&#39;s
the new or old kernel, replacing the kernel if it is indeed an old one, and
starting up the normal init process if it&#39;s the new kernel.</p>

<p>Now there is a very important catch here, whatever process starts up first is
given PID 1 which is very important in kernel land. Whatever process is PID 1
will inherit all zombie processes on the system and will need to handle them.
Since our shell script is the first thing started up it will get PID 1 for both
the old and new kernel and getting the process handling code correct is not a
trivial issue.</p>

<p>What we really need is to hand over PID 1 to the init process so it can do it&#39;s
job normally as if the shell script never existed. There is a native function
to do exactly this in these shell scripts: <code>exec</code>.</p>

<p>Our simple shell script to do the chain load looks like this:</p>
<div class="CodeRay">
  <div class="code"><pre>#!/bin/bash

# Detect if this is the old kernel (not booted with the otherwise meaningless
# 'kexeced' parameter.
if [ $(grep -q ' kexeced$' /proc/cmdline) ]; then
  kexec --load /boot/vmlinuz-custom --initrd=/boot/initramfs.img \
    --reuse-cmdline --append=' kexeced'
  kexec --exec
fi

# If we made it this far we're running on the new kernel, trigger the original
# init binary with all the options passed too this as well as having it take
# over this process's PID.
exec /sbin/init.original &quot;$@&quot;
</pre></div>
</div>

<p>After rebooting you should be in your new kernel which you can verify with
<code>uname -a</code> and also by examining the <code>/proc/cmdline</code> file for the existence of
the &#39;kexeced&#39; flag.</p>

<p>If you modify the script above, be very careful as any execution error will
cause your system to die and recovery will only be possible by mounting the
filesystem on another linux system and fixing it.</p>

<p>In a future article I&#39;ll cover how to use this trick to build an active /
backup system allowing you to fall back to a known good system when booting
fails which is incredibly useful for embedded devices in the field that need
updates but are not easy to get too or replace when an update bricks the
system.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/04/calculating-rsa-key-fingerprints-in-ruby/">Calculating RSA Key Fingerprints in Ruby</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on April 21, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I regularily find myself working on projects that involve the manipulation and
storage of RSA keys. In the past I&#39;ve never had to worry about identification
or presentation of these keys. Normally I&#39;ve only got one too three pairs at
most that I&#39;m manipulating (server, certificate authority, client).</p>

<p>I&#39;ve not found myself working on a project that involves presenting the
certificates to users for selection and comparison. The obvious way too do this
is take a page out of other developer&#39;s books and present the key&#39;s
fingerprint.</p>

<p>For those unfamiliar with key fingerprints, they are a condensed way to compare
differing RSA with a high probability that if the fingerprints match, so do the
keys. These are generally based on a cryptographic digest function such as SHA1
and MD5, and you&#39;ll see them most commonly when connecting to a new SSH host
and will look like the following:.</p>
<div class="CodeRay">
  <div class="code"><pre>The authenticity of host 'some.fakedomain.tld (127.0.0.1)' can't be established.
RSA key fingerprint is 0c:6c:dd:32:b5:59:40:1d:ac:05:24:4f:04:bc:e0:f3.
Are you sure you want to continue connecting (yes/no)?
</pre></div>
</div>

<p>The string of 32 hex characters presented there can be compared with another
known value to make sure you&#39;re connecting to the correct SSH server and will
always be the same length regardless of the bit-strength of the keys used.
Without the fingerprint, users would have to compare 256 hex characters for a
1024 bit key, which is a very low security key.</p>

<p>You can calculate the SSH fingerprint for your SSH key or a SSH host key using
the <code>ssh-keygen</code> command like so:</p>
<div class="CodeRay">
  <div class="code"><pre>ssh-keygen -lf ~/.ssh/id_rsa
ssh-keygen -lf /etc/ssh/ssh_host_key.pub
</pre></div>
</div>

<p>It will work when the path is either a private RSA key or a public key
formatted for SSH authorizied key files.</p>

<p>X509 certificates also use a key fingerprint to help identify a certificate&#39;s
signing authority. What I rapidly learned through this investigation was that
they are calculated slightly differently from SSH fingerprints even if they&#39;re
in the same format.</p>

<p>I couldn&#39;t find any good Ruby code that calculated either, and the alternatives
were some dense C++. Luckily SSH fingerprints are pretty documented in
<a href="http://www.ietf.org/rfc/rfc4253.txt">RFC4253</a> and <a href="http://www.ietf.org/rfc/rfc4716.txt">RFC4716</a>. Fingerprints on RSA keys for use with OpenSSL
are less clear, and there is a different method for calculating the
fingerprints of certificates.</p>

<p>Slowly working through the undocumented bits of Ruby&#39;s OpenSSL wrapper, the
RFCs and a couple of C++ implementations I finally got a set of working
implementations that calculate the following fingerprints in Ruby:</p>

<ul>
<li>MD5 &amp; SHA1 fingerprints for RSA SSH keys</li>
<li>Fingerprints of RSA keys for use with x509 certificates</li>
<li>Fingerprints of x509 certificates</li>
</ul>

<p>The easiest being a regular x509 certificate:</p>
<div class="CodeRay">
  <div class="code"><pre>require <span class="string"><span class="delimiter">'</span><span class="content">openssl</span><span class="delimiter">'</span></span>

path_to_cert = <span class="string"><span class="delimiter">'</span><span class="content">/tmp/sample.crt</span><span class="delimiter">'</span></span>
cert = <span class="constant">OpenSSL</span>::<span class="constant">X509</span>::<span class="constant">Certificate</span>.new(<span class="constant">File</span>.read(path_to_cert))
puts <span class="constant">OpenSSL</span>::<span class="constant">Digest</span>::<span class="constant">SHA1</span>.hexdigest(cert.to_der).scan(<span class="regexp"><span class="delimiter">/</span><span class="content">..</span><span class="delimiter">/</span></span>).join(<span class="string"><span class="delimiter">'</span><span class="content">:</span><span class="delimiter">'</span></span>)
</pre></div>
</div>

<p>You can compare the output of the above code with OpenSSL&#39;s implementation with
the following command:</p>
<div class="CodeRay">
  <div class="code"><pre>openssl x509 -in /tmp/sample.crt -noout -fingerprint
</pre></div>
</div>

<p>Please note that case sensitivity doesn&#39;t matter here (OpenSSL will return
upper case hex codes).</p>

<p>The next one I got working was the SSH fingerprints thanks to the RFCs metioned
earlier.</p>
<div class="CodeRay">
  <div class="code"><pre>require <span class="string"><span class="delimiter">'</span><span class="content">openssl</span><span class="delimiter">'</span></span>

path_to_key = <span class="string"><span class="delimiter">'</span><span class="content">/tmp/ssh_key</span><span class="delimiter">'</span></span>

key = <span class="constant">OpenSSL</span>::<span class="constant">PKey</span>::<span class="constant">RSA</span>.new(<span class="constant">File</span>.read(path_to_key))
data_string = [<span class="integer">7</span>].pack(<span class="string"><span class="delimiter">'</span><span class="content">N</span><span class="delimiter">'</span></span>) + <span class="string"><span class="delimiter">'</span><span class="content">ssh-rsa</span><span class="delimiter">'</span></span> + key.public_key.e.to_s(<span class="integer">0</span>) + key.public_key.n.to_s(<span class="integer">0</span>)
puts <span class="constant">OpenSSL</span>::<span class="constant">Digest</span>::<span class="constant">MD5</span>.hexdigest(data_string).scan(<span class="regexp"><span class="delimiter">/</span><span class="content">..</span><span class="delimiter">/</span></span>).join(<span class="string"><span class="delimiter">'</span><span class="content">:</span><span class="delimiter">'</span></span>)
</pre></div>
</div>

<p><em>Please note: The above only works for RSA SSH keys.</em></p>

<p>Calculating a SHA1 fingerprint for SSH hosts is as simple as replacing the
&#39;MD5&#39; class with &#39;SHA1&#39; or any of the other support digest algorithms.</p>

<p>The last one was the hardest to track down and implement, eventually I found
the answer in <a href="http://www.ietf.org/rfc/rfc3279.txt">RFC3279</a> under section 2.3.1 for the format of the public key
I would need to generate before performing a digest calculation on it.</p>
<div class="CodeRay">
  <div class="code"><pre>require <span class="string"><span class="delimiter">'</span><span class="content">openssl</span><span class="delimiter">'</span></span>

path_to_key = <span class="string"><span class="delimiter">'</span><span class="content">/tmp/x509_key.pem</span><span class="delimiter">'</span></span>

key = <span class="constant">OpenSSL</span>::<span class="constant">PKey</span>::<span class="constant">RSA</span>.new(<span class="constant">File</span>.read(path_to_key))
data_string = <span class="constant">OpenSSL</span>::<span class="constant">ASN1</span>::Sequence([
  <span class="constant">OpenSSL</span>::<span class="constant">ASN1</span>::<span class="constant">Integer</span>.new(key.public_key.n),
  <span class="constant">OpenSSL</span>::<span class="constant">ASN1</span>::<span class="constant">Integer</span>.new(key.public_key.e)
])
puts <span class="constant">OpenSSL</span>::<span class="constant">Digest</span>::<span class="constant">SHA1</span>.hexdigest(data_string.to_der).scan(<span class="regexp"><span class="delimiter">/</span><span class="content">..</span><span class="delimiter">/</span></span>).join(<span class="string"><span class="delimiter">'</span><span class="content">:</span><span class="delimiter">'</span></span>)
</pre></div>
</div>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/04/disabling-gnomes-keyring-in-fedora-19/">Disabling Gnome's Keyring in Fedora 19</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on April 14, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>An update too Fedora a while ago started causing some unexpected behavior with
my dotfiles. Specifically the way I was handling my SSH agent. My SSH keys when
added to my agent automatically expire after a couple of hours.</p>

<p>After the update, when that expiration came I started receiving errors in my
shell that looked similar to the following (Since I fixed it I am not able to
get the exact working again):</p>
<div class="CodeRay">
  <div class="code"><pre>Warning: Unable to connect to SSH agent
</pre></div>
</div>

<p>I also noticed that periodically I got a Gnome keyring popup asking for my SSH
agent rather than my command-line client. I&#39;m personally not a big fan of
Gnome, but I deal with because it&#39;s the default for Fedora, tends to stay out
of your way, and switching to something else is just not a project I&#39;ve had
time for.</p>

<p>Now Gnome was very much getting in my way. I dealt with it for several months
now and finally got sick of it.</p>

<p>I tracked this down too the <code>gnome-keyring-daemon</code> which was starting up and
clobbering the contents of my <code>SSH_AUTH_SOCK</code> variable along with my
<code>GPG_AGENT_INFO</code> environment. Not very friendly.</p>

<p>There were a couple paths that I could&#39;ve gone for for solving this situation.
The first, and easiest way to probably have dealt with this was too put some
logic into my <code>~/.bashrc</code> file that detected when the <code>gnome-keying-agent</code> was
running, kill it and clean up after it. It might look something like this:</p>
<div class="CodeRay">
  <div class="code"><pre>if [ -n &quot;${GNOME_KEYRING_PID}&quot; ]; then
  if $(kill -0 ${GNOME_KEYRING_PID}); then
    kill ${GNOME_KEYRING_PID}
  fi
fi

unset GNOME_KEYRING_CONTROL SSH_AUTH_SOCK GPG_AGENT_INFO GNOME_KEYRING_PID
</pre></div>
</div>

<p>I share my dotfiles along a lot of different systems and don&#39;t like
system-specific behaivior getting in there. Instead I choose to find what was
starting up the keyring daemon and preventing it from doing so. Without a good
place to start and stubbornly refusing to Google this particular problem I took
the brute force approach of grep for the binary name in the <code>/etc</code> directory.</p>

<p>Sure enough in <code>/etc/xdg/autostart</code> I found a series of background daemons that
I definitely did not want nor need running. As root I ran the following command
to purge them from my system:</p>
<div class="CodeRay">
  <div class="code"><pre>cd /etc/xdg/autostart
rm -f gnome-keyring-{gpg,pkcs11,secrets,ssh}.desktop \
  gnome-welcome-tour.desktop imsettings-start.desktop \
  evolution-alarm-notify.desktop caribou-autostart.desktop
</pre></div>
</div>

<p>Make sure you read through that command as I&#39;m deleting more services than just
the Gnome keyring related daemons. The first solution will keep your system in
a default state, but this will permanently prevent the obnoxious behaivior on
your system for all users and prevents you from adding hacks to your bashrc to
work around mis-behaving software.</p>

<p>I hope this helps someone else!</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/03/one-liner-ssl-certificate-generation/">One-Liner SSL Certificate Generation</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on March 28, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I regularily find myself in need of generating a quick SSL key and certificate
pair. I&#39;ve been using a one-liner for a while to generate these certificates.
No annoying user prompts just a quick fast certificate pair.</p>
<div class="CodeRay">
  <div class="code"><pre>echo -e &quot;XX\n\n \n \n\n*\n\n&quot; | openssl req -new -x509 -newkey rsa:2048 \
  -keyout service.key -nodes -days 90 -out service.crt &amp;&gt; /dev/null
</pre></div>
</div>

<p>A few notes about this, it is an ultimate wildcard matching any and all
hostnames with no location specific information, it should under no
circumstances be used for a production service. It&#39;s a 2048 bit key and only
valid for for roughly three months.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/03/preventing-tmux-lockups/">Preventing Tmux Lockups</a></h1>
    <aside class="post-date">Published <time datetime=''>during lunch on March 28, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>Anyone that has used SSH, Tmux or Screen for a while will have inevitably
dumped excessive output to their terminal. Depending on the size of the output
you may have experienced the dreaded lockup. That horrible realization seconds
after you hit the command where signals just stop working and you just have to
sit there and wait for your terminal to catch up.a</p>

<p>There is a piece of remote connection software called Mosh that I&#39;ve been told
handles this pretty well, but I don&#39;t yet trust its security model and it
doesn&#39;t prevent the same thing from happening locally.</p>

<p>This is especially bad if you&#39;re working in a multi-pane tmux window as it&#39;s
locks up all the terminals in the same window, and prevents you from changing
to the other windows.</p>

<p>I&#39;ve had this issue happen to me one too many times but never thought of
looking for a solution until a friend of mine, <a href="http://gabekoss.com/">Gabe Koss</a>, made a passing
comment along the lines of &quot;Too bad tmux can&#39;t rate limit the output of a
terminal&quot;.</p>

<p>A quick search through the doc and two relatively recent configuration options
popped out doing exactly what I was looking for (c0-change-internal, and
c0-change-trigger). Googling around for good values, left me wanting. A lot of
people were recommending setting the values to 100 and 250 respectively; These
are the defaults and since I still experience the issue are clearly not working
for me.</p>

<p>To set the variables to something more reasonable I had to understand what they
were doing. A &#39;C0&#39; sequence is one that modifies the screen beyond a normal
character sequence, think newlines, carriage returns, backspaces. According to
the tmux man page, the trigger will catch if the number of c0 sequences per
<strong>millisecond</strong> exceeds the number in the configuration file, at which point it
will start displaying an update once every interval number of milliseconds.</p>

<p>I can&#39;t see faster than my eye&#39;s refresh rate so that seems like a decent
starting point. According to <a href="http://en.wikipedia.org/wiki/Frame_rate">wikipedia</a> the human eye/brain interface can
process 10-12 images per second but we can notice &#39;choppiness&#39; below 48 FPS.
Since I won&#39;t be reading anything flying by that fast I settled on a maximum
rate of 10 FPS updated in my shell, or an interval of &#39;100ms&#39;.</p>

<p>For the trigger I was signficantly less scientific, I dropped the trigger by
50, reloaded my tmux configuration, cat&#39;d a large file and tested whether I
could immediately kill the process and move between panes. I finally settled on
a value of &#39;75&#39; for the trigger rate. It does make the output seem a little
choppy but it is signficantly nicer to not kill my terminal.</p>

<p>TL;DR Add the following lines to your ~/.tmux.conf file and you&#39;ll be in a much
better shape:</p>
<div class="CodeRay">
  <div class="code"><pre>setw -g c0-change-interval 50
setw -g c0-change-trigger  75
</pre></div>
</div>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/02/finding-ruby-subclasses/">Finding Ruby Subclasses</a></h1>
    <aside class="post-date">Published <time datetime=''>far too early on February 20, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>While working through a problem I found it would be immensely useful to be able
to enumerate all of the current subclasses of a particular class. After
thinking about this for a while I settled on a good old friend of mine,
<code>ObjectSpace</code>.</p>

<p>For those not familiar with the ObjectSpace module, it is a means to inspect
and access the items being tracked by Ruby&#39;s garbage collector. This means it
has a hook into every living object, and more dangerously, every near-death
object.</p>

<p><code>ObjectSpace</code> provides a method for enumerating instances of a specific class,
specifcally named <code>each_object</code> which takes a class. With Ruby all classes are
in fact instances of the <code>Class</code> class. This allows us to enumerate every
available class by passing it to the enumerator like so:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="constant">ObjectSpace</span>.each_object(<span class="constant">Class</span>).to_a
</pre></div>
</div>

<p>Alright so we now have an array of every single class that could possibly be
instantiated, how do we narrow it down to just the ones we&#39;re interested in?
Once again Ruby provides with the <code>ancestors</code> method, combine that with a
select and we can quickly narrow it down. You can see it in the following
example:</p>
<div class="CodeRay">
  <div class="code"><pre>[<span class="integer">1</span>] pry(main)&gt; <span class="constant">TargetSubclass</span> = <span class="constant">Class</span>.new(<span class="constant">String</span>)
=&gt; <span class="constant">TargetSubclass</span>
[<span class="integer">2</span>] pry(main)&gt; <span class="constant">ObjectSpace</span>.each_object(<span class="constant">Class</span>).select { |k| k.ancestors.include?(<span class="constant">String</span>) }
=&gt; [<span class="constant">String</span>, <span class="constant">TargetSubclass</span>]
</pre></div>
</div>

<p>Hmm, that&#39;s not quite right though. We have found all the subclasses but we&#39;ve
also grabbed the parent class. With one small modification we eliminate that as
well.</p>
<div class="CodeRay">
  <div class="code"><pre>[<span class="integer">1</span>] pry(main)&gt; <span class="constant">TargetSubclass</span> = <span class="constant">Class</span>.new(<span class="constant">String</span>)
=&gt; <span class="constant">TargetSubclass</span>
[<span class="integer">2</span>] pry(main)&gt; <span class="constant">ObjectSpace</span>.each_object(<span class="constant">Class</span>).select { |k| k.ancestors.include?(<span class="constant">String</span>) &amp;&amp; k != <span class="constant">String</span> }
=&gt; [<span class="constant">TargetSubclass</span>]
</pre></div>
</div>

<p>That line is rather long though, and I generally like to avoid multiple tests
in a select block. There is a tad bit of syntactic sugar provided by Ruby
allowing us to accomplish the same thing, our final example is ultimately the
solution I went with:</p>
<div class="CodeRay">
  <div class="code"><pre>[<span class="integer">1</span>] pry(main)&gt; <span class="constant">TargetSubclass</span> = <span class="constant">Class</span>.new(<span class="constant">String</span>)
=&gt; <span class="constant">TargetSubclass</span>
[<span class="integer">2</span>] pry(main)&gt; <span class="constant">ObjectSpace</span>.each_object(<span class="constant">Class</span>).select { |k| k &lt; <span class="constant">String</span> }
=&gt; [<span class="constant">TargetSubclass</span>]
</pre></div>
</div>

<p>Putting this into a method:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="keyword">def</span> <span class="function">subclasses</span>(klass)
  <span class="constant">ObjectSpace</span>.each_object(<span class="constant">Class</span>).select { |k| k &lt; klass }
<span class="keyword">end</span>
</pre></div>
</div>

<p>If you were so inclined you could extend the <code>Class</code> class with a method to
make this available anywhere like so:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="keyword">class</span> <span class="class">Class</span>
  <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">subclasses</span>
    <span class="constant">ObjectSpace</span>.each_object(<span class="constant">Class</span>).select { |k| k &lt; <span class="predefined-constant">self</span> }
  <span class="keyword">end</span>
<span class="keyword">end</span>
</pre></div>
</div>

<p>I&#39;m personally not a fan of extending any of the core classes unless absolutely
necessary, but too each there own.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/02/creating-crypt-style-sha512-passwords-with-ruby/">Creating Crypt Style SHA512 Passwords With Ruby</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on February 17, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I needed to generate crypt-style SHA512 passwords in ruby for an <code>/etc/shadow</code>
file. After a bunch of Googling and messing around with the OpenSSL library I
finally found a very simple built-in way to handle this.</p>
<div class="CodeRay">
  <div class="code"><pre>require <span class="string"><span class="delimiter">'</span><span class="content">securerandom</span><span class="delimiter">'</span></span>

<span class="string"><span class="delimiter">'</span><span class="content">password</span><span class="delimiter">'</span></span>.crypt(<span class="string"><span class="delimiter">'</span><span class="content">$6$</span><span class="delimiter">'</span></span> + <span class="constant">SecureRandom</span>.random_number(<span class="integer">36</span> ** <span class="integer">8</span>).to_s(<span class="integer">36</span>))
</pre></div>
</div>

<p>You&#39;ll get a string that looks like:</p>
<div class="CodeRay">
  <div class="code"><pre>$6$4dksjo1b$Lt194Dwy7r/7WbM8MezYZysmGcxjaiisgTrTBbHkyBZFXeqQTG0J5hep4wLM/AmYxlGNLRy0OWATLDZCqjwCk.
</pre></div>
</div>

<p>If you don&#39;t want to use the <code>SecureRandom</code> module you can replace the random
call with simply <code>rand(36 ** 8)</code> though this isn&#39;t recommended.</p>

<p>Enjoy!</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/02/setting-linux-system-timezone/">Setting Linux System Timezone</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on February 1, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I change the timezone on the linux systems so rarely that I almost always have
to look it up. I&#39;m writing it up here for my own personal reference. With any
luck it&#39;ll also help others.</p>

<p>The system timezone is controlled by the <code>/etc/localtime</code> file and is generally
symlinked to locale files stored in <code>/usr/share/zoneinfo</code>. Generally I like to
keep my systems on UTC as I my machines are in several timezones and it makes
all the logs have consistent times.</p>

<p>To set the system time to UTC you&#39;d run the following command as root:</p>
<div class="CodeRay">
  <div class="code"><pre>ln -sf /usr/share/zoneinfo/UTC /etc/localtime
</pre></div>
</div>

<p>Other timezones can be found in the <code>/usr/share/zoneinfo</code> and are generally
broken up by continent with a few exceptions.</p>

<p>As a user it&#39;s obviously more useful to see the time in my local timezone and
this can be overridden on a per-user basis using the TZ environment variable. I
stick this in my <code>~/.bashrc</code> file and it just works transparently:</p>
<div class="CodeRay">
  <div class="code"><pre>export TZ=&quot;America/Los_Angeles&quot;
</pre></div>
</div>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2014/01/starting-puppetmaster-on-fedora-19/">Starting Puppetmaster on Fedora 19</a></h1>
    <aside class="post-date">Published <time datetime=''>in the middle of the night on January 18, 2014</time> by Sam Stelfox</aside>
    <article>
      <p>I was trying to get puppet running out of the box on Fedora 19 and found a bug
exists in their systemd service file. After installing <code>puppet</code> and
<code>puppet-server</code>, whenever I tried to start the server with the following
command:</p>
<div class="CodeRay">
  <div class="code"><pre>systemctl start puppetmaster.service
</pre></div>
</div>

<p>It would hang for a long time and the following error message would show up in
the log:</p>
<div class="CodeRay">
  <div class="code"><pre>Jan 19 03:42:18 puppet-01 puppet-master[1166]: Starting Puppet master version 3.3.1
Jan 19 03:42:18 puppet-01 systemd[1]: PID file /run/puppet/master.pid not readable (yet?) after start.
Jan 19 03:43:07 puppet-01 systemd[1]: puppetmaster.service operation timed out. Terminating.
Jan 19 03:43:07 puppet-01 puppet-master[1166]: Could not run: can't be called from trap context
</pre></div>
</div>

<p>Starting puppet directly from the command line using the same command specified
in the service file would work fine, but that wasn&#39;t really a solution. Turns
out puppet, additionally I would briefly see the <code>puppetmaster</code> service open up
port 8140 before systemd would kill it.</p>

<p>Turns out the systemd service script is looking in the wrong location for the
pidfile. All of the pids are stored in <code>/var/run/puppet/</code> with a filename of
either <code>agent.pid</code> or <code>master.pid</code> depending on the mode it was run as. The
systemd script, as the log indicates is looking for the pid files in
<code>/run/puppet</code>.</p>

<p>The real solution would be to bring this too the attention of the script
maintainers, but I haven&#39;t had a lot of luck going through those processes.
Instead you can work around the issue without any beauracracy by changing the
rundir configuration option in <code>/etc/puppet/puppet.conf</code> to <code>/run/puppet</code>, and
creating <code>/run/puppet</code> (with puppet as the user and group owning the
directory).</p>

<p>After that, voila! The service starts up. You&#39;d think a QA process would catch
that the service script doesn&#39;t work...</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/12/updating-bmc-on-dell-poweredge-c6100/">Updating BMC on Dell PowerEdge C6100</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on December 16, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>I just received my Dell PowerEdge C6100 and found it&#39;s software quite a bit
outdated. After searching around quite a bit I found the resources lacking for
explaining how to perform these updates. So in this post I&#39;m going to quickly
cover updating the BMC firmware on each blade.</p>

<p>The system I received had four different versions of the BMC software
installed, additionally Two were branded as MegaRAC and the others branded as
Dell. This update didn&#39;t fix the branding (and I&#39;d love to remove the Dell
branding as it&#39;s kind of annoying) it did, however, fix a number of other
issues that I was experiencing such as:</p>

<ol>
<li>Console Redirection failing to connect</li>
<li>BMC losing it&#39;s network connection after a couple of minutes</li>
<li>Slow responses, with occasional failures to load pages</li>
<li>Remote IPMI tools being unable to read sensors status</li>
</ol>

<p>The first step is too download the latest version of of the BMC software from
<a href="https://support.dell.com/">Dell&#39;s support site</a> (Or a <a href="http://downloads.dell.com/Pages/Drivers/poweredge-c6100-all.html">direct link</a>, I&#39;ve also taken the liberty of
<a href="http://static.stelfox.net/files/PEC6100BMC130.exe">hosting a copy myself</a>). I recommend you go through the process of entering
the service tag of each of the blades and make sure that Dell recognizes them
as existing even if they&#39;re out of support.</p>

<p>There has been mention of versions of these blades that had custom
modifications for DCS and any attempts to modify the BIOS or BMC will likely
cause you to end up bricking the remote management board or the motherboard.</p>

<p>Even with the regular board there is always a risk of bricking it, though
firmware updates have gotten a lot more reliable and I haven&#39;t experienced a
mis-flashed motherboard in years. You&#39;ve been warned.</p>

<p>The BMC was fairly straight-foward. I installed the 64-bit version of Fedora 19
on a thumbdrive, downloaded version 1.30 of the BMC software (get the file
named <code>PEC6100BMC130.exe</code>). The file itself is a self-extracting zip archive
which can be extracted using the regular unzip utility.</p>
<div class="CodeRay">
  <div class="code"><pre>unzip PEC6100BMC130.exe
</pre></div>
</div>

<p>Inside you&#39;ll find two folders, KCSFlash and SOCFlash should both be put on the
live drive within the KCSFlash. You&#39;ll need to set the execute bit on the
contents of the linux directory and the linux.sh file. You&#39;ll also need to
install the <code>glibc.i686</code> package. Afterwards it&#39;s as simple as booting each
chassis off the drive and as root run the linux.sh script.</p>

<p>If the KCSFlash fails, the SOCFlash will more likely than not work but it is
slightly more dangerous. If you need it mark the <code>linux/flash8.sh</code>,
<code>linux/socflash</code>, and <code>linux/socflash_x64</code> as executable in the SOCFlash folder
and run the flash8.sh script.</p>

<p>After that you&#39;re going to want to reboot into the BIOS and ensure the IPMI
ethernet port is set to dedicated, as this switched it back to &quot;Shared&quot; on me.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/12/using-dnsmasq-as-a-standalone-tftp-server/">Using Dnsmasq as a Standalone TFTP Server</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on December 12, 2013</time> by Sam Stelfox</aside>
    <article>
      <p><em>If you&#39;ve come across this blog post with the intention of setting up TFTP on
an modern version of OpenWRT I have a <a href="/blog/2014/07/using-openwrts-dnsmasq-as-a-tftp-server/">more recent blog post</a> detailing how
too configure your system.</em></p>

<p>I found myself in need of a TFTP server but wanted to avoid having all of the
xinet.d packages and services on my system (even if they were disabled). While
looking for alternatives I found out that <code>dnsmasq</code> has a built-in read-only
TFTP server.</p>

<p>I already have a DNS and DHCP server on my network and didn&#39;t want dnsmasq to
take on either of those roles so my first challenge was finding a way to
prevent dnsmasq from running those bits of it&#39;s code, or failing that I would
just firewall off the service. Luckily it&#39;s quite easy to disable both bits of
funtionality.</p>

<p>For DHCP you simply have to leave out any of the dhcp option in the
configuation file, DNS you just tell it to operate on port 0 and it will be
disabled.</p>

<p>So my whole config starting out looks like this:</p>
<div class="CodeRay">
  <div class="code"><pre># Disable DNS
port=0
</pre></div>
</div>

<p>Now I need to configure the TFTP bits of dnsmasq. This too was rather simple
only requiring me to add the following to my already terse config file:</p>
<div class="CodeRay">
  <div class="code"><pre># Enable the TFTP server
enable-tftp
tftp-root=/var/lib/tftp
</pre></div>
</div>

<p>I created the root directory for my TFTP server and started it up with the
following commands:</p>
<div class="CodeRay">
  <div class="code"><pre>mkdir /var/lib/tftp
systemctl enable dnsmasq.service
systemctl start dnsmasq.service
</pre></div>
</div>

<p>Voila, TFTP running and happy. If you have a firewall running you&#39;ll also want
to open ports 69/tcp and 69/udp (though I suspect only the UDP one is needed).</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/12/configuring-pxe-booting-on-openwrt/">Configuring PXE Booting on OpenWRT</a></h1>
    <aside class="post-date">Published <time datetime=''>far too early on December 11, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>I needed to support PXE booting on my home network. I use OpenWRT as my main
router and DHCP server and it took me a bit of searching how to configure the
BOOTP next server to redirect local clients to my Arch TFTP/NFS server for
booting, so I&#39;m placing the config here to help others who might be looking to
do the same thing.</p>

<p>It&#39;s worth noting that this isn&#39;t a guide on setting up PXE booting completely
on an OpenWRT, you&#39;ll need another system that is running a configured TFTP
server. I&#39;ll write up how I setup my Arch box as a TFTP server at a later date.</p>

<p>The config itself was very simple; You just need to add a couple lines to
<code>/etc/config/dhcp</code>. You&#39;ll want to replace 10.0.0.45 with whatever your local
TFTP server is.</p>
<div class="CodeRay">
  <div class="code"><pre>config boot linux
  option filename      'pxelinux.0'
  option serveraddress '10.0.0.45'
  option servername    'Arch-Pixie'
</pre></div>
</div>

<p>The filename <code>pxelinux.0</code> is from syslinux, and the servername has no technical
meaning, but it provides nice information to the clients. In this case I&#39;ve
used the name of my Arch linux server that I&#39;ll be booting off of.</p>

<p>Hope this helps someone out. Cheers!</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/12/running-emails-through-ruby/">Running Emails Through Ruby</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on December 8, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>Following up on my <a href="/blog/2013/11/backing-up-gmail-with-fetchmail/">earlier post</a> where I covered how to backup your Gmail
account using <code>fetchmail</code> and <code>procmail</code>; I wanted to cover how I was
additionally processing received mail through ruby.</p>

<p>This was part of a larger project where I was doing statistical analysis on my
email while evaluating various data stores. To get the emails into the various
data stores, I used the ruby script to parse, process and store the emails as
they came in.</p>

<p>If you&#39;re going to be doing any form of mail manipulation or statistics I
highly recommend the <a href="https://github.com/mikel/mail">mail</a> gem. It did almost everything I needed out of
the box, though it didn&#39;t correctly enumerate any of the additional headers.</p>

<p>Procmail is a highly flexible mail filtering and local delivery agent. Without
much effort you can pass the mail it is handling through a series of filters
which can manipulate and reject mail before eventually delivering it to your
inbox. In light of this, we&#39;re going to make a filter that simply counts the
total number of emails the script has processed, and add a header to the
message that indicates this count.</p>
<div class="CodeRay">
  <div class="code"><pre><span class="doctype">#!/usr/bin/env ruby</span>

require <span class="string"><span class="delimiter">'</span><span class="content">mail</span><span class="delimiter">'</span></span>

<span class="comment"># Get the email message from STDIN or a passed filename</span>
message = <span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span>
<span class="keyword">while</span> input = <span class="predefined-constant">ARGF</span>.gets
  message += input
<span class="keyword">end</span>

<span class="comment"># Parse the email into a ruby object</span>
msg = <span class="constant">Mail</span>.new(message)

<span class="comment"># Location of our count file</span>
count_file = <span class="string"><span class="delimiter">&quot;</span><span class="inline"><span class="inline-delimiter">#{</span><span class="predefined-constant">ENV</span>[<span class="string"><span class="delimiter">'</span><span class="content">HOME</span><span class="delimiter">'</span></span>]<span class="inline-delimiter">}</span></span><span class="content">/.mail_counter.txt</span><span class="delimiter">&quot;</span></span>

<span class="comment"># Load or initialize our count value and increment it</span>
count = <span class="constant">File</span>.exists?(count_file) ? <span class="constant">File</span>.read(count_file).to_i : <span class="integer">0</span>
count += <span class="integer">1</span>

<span class="comment"># Update our count on disk</span>
<span class="constant">File</span>.write(count_file, count.to_s)

<span class="comment"># Add our header with the count</span>
msg.header.fields &lt;&lt; <span class="constant">Mail</span>::<span class="constant">Field</span>.new(<span class="string"><span class="delimiter">&quot;</span><span class="content">X-Mail-Counter: </span><span class="inline"><span class="inline-delimiter">#{</span>count<span class="inline-delimiter">}</span></span><span class="delimiter">&quot;</span></span>)

<span class="comment"># Output the now modified message back out to $stdout</span>
<span class="keyword">begin</span>
  <span class="global-variable">$stdout</span>.puts msg.to_s
<span class="keyword">rescue</span> <span class="constant">Errno</span>::<span class="constant">EPIPE</span>
  exit(<span class="integer">74</span>)
<span class="keyword">end</span>
</pre></div>
</div>

<p>Make sure you mark the script executable after saving it.</p>

<p>If you followed along with <a href="/blog/2013/11/backing-up-gmail-with-fetchmail/">my earlier post</a> the only change we need to make
is to add our ruby mail processor as a procmail filter. I&#39;ve stored the script
in <code>~/.bin/mail-counter.rb</code>, if you&#39;ve stored it in a different location you&#39;ll
want to update your path to reflect that.</p>

<p>Filters in procmail are handled by using the pipe helper. The following is a
minimum working example of a procmailrc file to make use of our filter:</p>
<div class="CodeRay">
  <div class="code"><pre>MAILDIR=$HOME
VERBOSE=on

:0fw
| /home/sstelfox/Documents/ruby/riak-mail-indexer/counter.rb

:0
Maildir/
</pre></div>
</div>

<p>Store the above file in <code>~/.procmailrc</code>. The next time you run <code>fetchmail</code>
those headers will be added to the messages before being delivered and you can
watch the count increment by looking at the contents of <code>~/.mail_counter.txt</code>.</p>

<p>The following are a few additional sources I made use of while writing this
article:</p>

<ul>
<li><a href="http://stackoverflow.com/questions/273262/best-practices-with-stdin-in-ruby">http://stackoverflow.com/questions/273262/best-practices-with-stdin-in-ruby</a></li>
<li><a href="http://www.jstorimer.com/blogs/workingwithcode/7766125-writing-ruby-scripts-that-respect-pipelines">http://www.jstorimer.com/blogs/workingwithcode/7766125-writing-ruby-scripts-that-respect-pipelines</a></li>
</ul>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/12/access-get-parameters-with-coffeescript/">Access GET Parameters With Coffeescript</a></h1>
    <aside class="post-date">Published <time datetime=''>while he should be socializing on December 7, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>I&#39;ve been working on a pure javascript based search engine for this static
website and needed to access a get parameter within the URL.</p>

<p>I found a few solutions online but they usually made use of jQuery or weren&#39;t
in coffeescript. A few others would only extract an individual named parameter
at a time. The following will return all of them in Javascript&#39;s equilvalent of
a hash (or dictionary if you prefer) in the form of an object.</p>
<div class="CodeRay">
  <div class="code"><pre>getParams = -&gt;
  query = window.location.search.substring(1)
  raw_vars = query.split(&quot;&amp;&quot;)

  params = {}

  for v in raw_vars
    [key, val] = v.split(&quot;=&quot;)
    params[key] = decodeURIComponent(val)

  params

console.log(getParams())
</pre></div>
</div>

<p>If compiled and included in a page the above will print out the parameters as a
hash object to the console.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/12/downloading-google-mail-and-calendar-data/">Downloading Google Mail and Calendar Data</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on December 5, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>I <a href="/blog/2013/11/backing-up-gmail-with-fetchmail/">recently posted</a> a guide on backing up your Gmail with fetchmail. This
unfortunately doesn&#39;t include your calendar data. It seems like backing up was
a hot enough topic that the Google Gmail team are <a href="http://gmailblog.blogspot.com/2013/12/download-copy-of-your-gmail-and-google.html">releasing an official backup
method</a>. It&#39;s not completely in the wild yet but I definitely look forward
to poking around in it.</p>

<p>Now if only Google let you download everything they know about you as well...
Would definitely make for an interesting read.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/12/taking-back-the-sky/">Taking Back the Sky</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on December 4, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>During my daily review of various new sources I came across one particular
article that was both concerning and very amusing. Drones have been getting
more and more popular, and more accessible. They&#39;ve been getting used by the
military, law enforcement, <a href="http://www.cnn.com/2013/12/02/tech/innovation/amazon-drones-questions/">recently Amazon</a> (though they&#39;ve abandoned that
for now), you can even purchase one for your iPhone at airports.</p>

<p>The security of these systems hasn&#39;t been thoroughly tested publicly, though
<a href="http://rt.com/news/iran-us-drone-gulf-216/">there is at least</a> one report of a military drone being stolen already.
With the beginnings of <a href="http://www.fastcompany.com/3019913/watch-the-skies-tonight-for-a-taco-delivering-drone-brought-to-you-by-taco-bell">various commercial uses</a> of drones and not just
hobbiest seeing <a href="http://gizmodo.com/5947033/this-team-of-quadrocopters-can-throw-and-catch-better-than-you">what they can do with them</a>.</p>

<p>Someone had to start the testing eventually and Samy Kamkar took the lead this
time with his new project <a href="http://samy.pl/skyjack/">Skyjack</a>. The article that tipped me off to this
project can be found <a href="http://threatpost.com/how-to-skyjack-drones-in-an-hour-for-less-than-400/103086">over on threatpost</a></p>

<p>The gist of the project is a drone that can forcibly disconnect other drone&#39;s
controller and take it&#39;s place to &quot;steal&quot; the drone.</p>

<p>I can imagine a whole cyber-punk thriller action scene where corporate
anarchists hijack a drone and use it&#39;s trusted status within the drone&#39;s
network to hack in and take control of the entire CNC drone system to further
their goals.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/11/fail-fast-in-bash-scripts/">Fail Fast in Bash Scripts</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on November 26, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>I found myself writing another bash script that should exit should any of the
few commands within it fail to run. As I began writing some error handling
after each command, and isolating the sections into bash functions I figured
there had to be a better way. After a little Googling and a trip through the
bash manpages sure enough:</p>
<div class="CodeRay">
  <div class="code"><pre>#!/bin/bash

function error_handler() {
  echo &quot;Error occurred in script at line: ${1}.&quot;
  echo &quot;Line exited with status: ${2}&quot;
}

trap 'error_handler ${LINENO} $?' ERR

set -o errexit
set -o errtrace
set -o nounset

echo &quot;Everything is running fine...&quot;

# A command outside of a conditional that will always return a exit code of 1
test 1 -eq 0

echo &quot;This will never run, as a command has failed&quot;
echo &quot;Using unset variable ${TEST} will also cause this script to exit&quot;
</pre></div>
</div>

<p>The first piece of that is setting up an error handler that will get run
whenever an error condition occurs with the script. You can use this section to
roll back any changes or cleanup your environment as well as give you some
debug information about the failure.</p>

<p>I&#39;m then setting a few bash options, The following is a description taken more
or less directly from the bash man pages:</p>

<blockquote>
<p>-o errexit: Exit immediately if a pipeline (which may consist of a single
simple command), a subshell command enclosed in parentheses, or one of the
commands executed as part of a command list enclosed by braces exits with a
non-zero status.</p>

<p>-o errtrace: If set, any trap on ERR is inherited by shell functions, command
substitutions, and commands execute in a subshell environment.</p>

<p>-o nounset: Treat unset variables and parameters other than the special
parameters &quot;@&quot; and &quot;*&quot; as an error when performing parameter expansion.</p>
</blockquote>

<p>If anything goes wrong in the script it will fail once, fail fast, and let you
know where it died.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/11/using-vim-as-your-password-manager/">Using VIM as Your Password Manager</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on November 25, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>There are all kinds of password managers out there. Everything from <a href="https://www.passpack.com/en/home/">web
services</a> that are quite solid and respectible, to <a href="https://lastpass.com/">native</a> <a href="http://keepass.info/">desktop</a>
apps.</p>

<p>A lot of these are simply too heavy for me, involve installing software on a
computer to access in addition to sharing the file around, or required you to
remember multiple account details before you could get access to any individual
password.</p>

<p>Due too the various complexities and lack of matching use cases a couple years
ago I set out to develop my own open-source version of <a href="https://www.passpack.com/en/home/">Passpack</a>. In the
interim though I needed a solution for keeping track of my hundreds of various
accounts and their passwords.</p>

<p>Around this time I was ramping up my usage of vim and happened to come across a
very fortunate command entirely by accident. Enter <em>vimcrypt</em>.</p>

<p>For any plaintext file you, while in command mode you can type the command <code>:X</code>
and it will ask you for a password to encrypt your file with. By default this
uses a remarkably weak algorithm called <a href="https://en.wikipedia.org/wiki/PKZIP">pkzip</a> which isn&#39;t secure enough
for me to trust it with my keys.</p>

<p>Since vim 7.3 and later, <code>:X</code> has also supported an additional cipher; The much
stronger blowfish algorithm. You can enable this by running the command <code>:set
cryptmethod=blowfish</code>. I chose to add the following lines to my <code>~/.vimrc</code>
file:</p>
<div class="CodeRay">
  <div class="code"><pre>&quot; When encrypting any file, use the much stronger blowfish algorithm
set cryptmethod=blowfish
</pre></div>
</div>

<p>This was a fantastic interim solution as I have yet to find a development or
production linux system that hasn&#39;t been excessively locked down (and probably
not somewhere I&#39;d put my password file anyway) that didn&#39;t already have vim
installed.</p>

<p>Using this personally required me coming up with a pseudo-file format that
would allow me to quickly and easily find the credentials I needed. I settled
on the simple format shown off below:</p>
<div class="CodeRay">
  <div class="code"><pre>Oneline Account Description
  Site: &lt;URL of Site's login page&gt;
  Username: &lt;username for the site&gt;
  Password: &lt;password for the site&gt;
  Email: &lt;email I used to register&gt;

  Login with: &lt;email|username&gt; # Only necessary when I have both

  ** Address on file **
  ** Phone on file **
</pre></div>
</div>

<p>You&#39;ll notice I also used this to keep track of whether an account had physical
information tied to it. When I moved this made it very quick for me to search
for accounts that I needed to update with my new mailing address.</p>

<p>As with many solutions this &quot;temporary&quot; one became more and more permanent as
my motivation to build the Passpack competitor dwindled. My problem had been
solved and I was no longer compelled to put any effort into a solution.</p>

<p>If this still isn&#39;t strong enough for your tastes, the <a href="http://vim.wikia.com/wiki/Encryption">vim wiki</a> has some
additional ways you can encrypt your files. These all require additional setup
and failed my requirements in that they generally require additional files or
setup before I can access my passwords.</p>

<p>Hope this helps some other weary CLI warrior some trouble. Cheers!</p>

<p><strong><em>Update</em></strong>: I received a wonderful recommendation from a user named
<a href="http://www.reddit.com/r/vim/comments/1rg3ji/wrote_up_my_thoughts_on_using_vim_as_a_password/cdn20o8">sigzero</a> over on Reddit. For additional security they added the following
line to their <code>~/.vimrc</code> file.</p>
<div class="CodeRay">
  <div class="code"><pre>autocmd BufReadPost * if &amp;key != &quot;&quot; | set noswapfile nowritebackup viminfo= nobackup noshelltemp history=0 secure | endif
</pre></div>
</div>

<p>It disables additional files that vim may write copies to such as swap files
and backups, prevents dangerous shell commands, and prevents vim from storing a
history of commands.</p>

<p><strong><em>Update 2</em></strong>: I received another fantastic recommendation from another reddit
user, this time from <a href="http://www.reddit.com/r/vim/comments/1rg3ji/wrote_up_my_thoughts_on_using_vim_as_a_password/cdnn94z">NinlyOne</a>. At their recommendation, I&#39;ve prepended the
following modeline to my password. It automatically folds each password entry
to prevent potential shoulder surfing. You can open up an entry using the
command <code>zo</code> and close it back up with <code>zc</code>. It&#39;s worth noting that this is
tied to my indented file format.</p>
<div class="CodeRay">
  <div class="code"><pre># vim: fdm=indent fdn=1 sw=2:
</pre></div>
</div>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/11/riak-talk-summary/">Riak Talk Summary</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on November 21, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>This evening <a href="http://gabekoss.com/">Gabe Koss</a> and myself gave a lightning talk on <a href="http://basho.com/riak/">Riak</a> at
the <a href="http://www.btvwag.org/">Burlington Web Applications Group</a>. Due too time constraints there was
a lot of material that we simply weren&#39;t able to cover, but with any luck I&#39;ll
be covering in future blog posts.</p>

<p>There was a great turn out as usual, and it was lots of fun. If you&#39;re in the
Burlington, VT area and are interested in web applications written in any
language you should show up. You&#39;ll learn something and meet a lot of cool
people. You might even get a book out of the deal.</p>

<p>You can <a href="/static/20131118-riak-talk-slides.pdf">take a look at the slides</a> if you missed the talk.</p>

<p><strong><em>Update:</em></strong> Gabe has <a href="http://gabekoss.com/blog/2013/11/riak_101/">taken the time</a> to write up our presentation. You
can get closer to the full experience of our talk through his solid writeup. Go
check it out!</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/11/backing-up-gmail-with-fetchmail/">Backing up Gmail with fetchmail</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on November 19, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>This morning I found myself in need of a large set of emails to test a
particular set of code. Ideally these emails would be broken out into easily
digestable pieces, and it was strictly for my own personal testing so I wasn&#39;t
concerned with using my own live data for this test (There will probably be
another post on this project later on).</p>

<p>Having used <code>fetchmail</code> with good results in the past I decided it was a good
idea to take this opportunity to also backup my Gmail account into the common
Maildir format (which essentially breaks out emails into individual files
meeting my requirements).</p>

<p>The first step was to enable POP access to my account through Gmail&#39;s
interface. You can accomplish this with the following steps.</p>

<ol>
<li>Login to Gmail</li>
<li>Click on the gear icon</li>
<li>Choose settings</li>
<li>Forwarding and POP/IMAP</li>
<li>Enable POP for all mail</li>
<li>When messages are accessed with POP... Keep&quot;</li>
<li>Save Changes.</li>
</ol>

<p>Ensure you have <code>fetchmail</code> and <code>procmail</code> installed. For me on Fedora this can
be accomplished using yum by running the following commands:</p>
<div class="CodeRay">
  <div class="code"><pre>$ sudo yum install fetchmail procmail -y
</pre></div>
</div>

<p>We need to configure fetchmail to let it know where to retrieve our mail from.
This configuration file lives at <code>$HOME/.fetchmailrc</code>. By default fetchmail
will send all retrieved mail to the local SMTP server over a normal TCP
connection. This isn&#39;t necessary or ideal, rather we&#39;ll additionally supply a
local mail delivery agent (procmail) to handle processing the mail into the
Maildir format.</p>
<div class="CodeRay">
  <div class="code"><pre>poll pop.gmail.com
protocol pop3
timeout 300
port 995
username &quot;full_email@withdomain.tld&quot; password &quot;yourpassword&quot;
keep
ssl
sslcertck
sslproto TLS1
mda &quot;/usr/bin/procmail -m '/home/&lt;username&gt;/.procmailrc'&quot;
</pre></div>
</div>

<p>Be sure to set the permissions on the <code>.fetchmailrc</code> file to 0600:</p>
<div class="CodeRay">
  <div class="code"><pre>$ chmod 0600 $HOME/.fetchmailrc
</pre></div>
</div>

<p>We&#39;ll now need to configure procmail to properly deliver our mail to the local
<code>Maildir</code> folder. Procmail&#39;s configuration by default lives in
<code>$HOME/.procmailrc</code></p>
<div class="CodeRay">
  <div class="code"><pre>LOGFILE=$HOME/.procmail.log
MAILDIR=$HOME
VERBOSE=on

:0
Maildir/
</pre></div>
</div>

<p>With that done, simply run the <code>fetchmail</code> command. In my experience this can
take a while process and it seems like Google limits the number of emails you
can download at a time, so you may need to run the command a couple of times to
get all your emails.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2013/09/talking-about-laboratory-b/">Talking about Laboratory B</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on September 19, 2013</time> by Sam Stelfox</aside>
    <article>
      <p>Recently Justin England and myself were interviewed on a local television
channel about the <a href="http://laboratoryb.org/">local hackerspace</a> which we are both founding members of.</p>

<p>We covered several general topics about hackerspaces, how the organization is
run, and some of the stuff we do at the Lab. Take a look if you&#39;re at all
interested in any of those!</p>

<iframe width="640" height="360" src="//www.youtube.com/embed/3V7Sio6sBtk?feature=player_detailpage" frameborder="0" allowfullscreen></iframe>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/12/rubys-option-parser-a-more-complete-example/">Ruby's Option Parser - a More Complete Example</a></h1>
    <aside class="post-date">Published <time datetime=''>in the middle of the night on December 2, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>Recently while writing a Ruby program I needed to parse some command line
options. Helpfully Ruby provides a module named OptionParser to make this easy.
I found a few parts of the documentation ambiguous and a few others down right
confusing.</p>

<p>The catch I hit was the required field. In my mind the definition of a required
argument is something that needs to be passed on the commandline to continue.
What OptionParser actually means is that a value isn&#39;t required when the
argument is passed. OptionParser already provides boolean switches, so when
someone would use an optional switch is beyond me.</p>

<p>To make it a little more clear and to have something to work from in the future
I created the following chunk of code that includes a Configuration singleton
that can be used anywhere within your codebase to access the run-time
configuration, a sample parser with a wide range of different types of options,
and it will load configuration from a file named config.yml in the same
directory.</p>

<p>I feel like the following is a much more complete explanation of how
OptionParser is supposed to be used with supporting code.</p>
<div class="CodeRay">
  <div class="code"><pre><span class="doctype">#!/usr/bin/env ruby</span>

<span class="comment"># This file provides an example of creating a command line application with a</span>
<span class="comment"># wide variety of command line options, parsing and the like as well as global</span>
<span class="comment"># configuration singleton that can be relied on throughout a program.</span>
<span class="comment">#</span>
<span class="comment"># This entire setup lives within the &quot;Example&quot; module. These are really common</span>
<span class="comment"># names and it would be a shame to override required functionality in other code</span>
<span class="comment"># that wasn't properly namespaced.</span>

require <span class="string"><span class="delimiter">'</span><span class="content">optparse</span><span class="delimiter">'</span></span>
require <span class="string"><span class="delimiter">'</span><span class="content">singleton</span><span class="delimiter">'</span></span>
require <span class="string"><span class="delimiter">'</span><span class="content">yaml</span><span class="delimiter">'</span></span>

<span class="keyword">module</span> <span class="class">Example</span>
  <span class="comment"># Defines the available configuration options for the configuration</span>
  <span class="constant">ConfigurationStruct</span> = <span class="constant">Struct</span>.new(<span class="symbol">:enum</span>, <span class="symbol">:list</span>, <span class="symbol">:required</span>, <span class="symbol">:optional</span>, <span class="symbol">:verbose</span>, <span class="symbol">:float</span>)

  <span class="keyword">class</span> <span class="class">Configuration</span>
    include <span class="constant">Singleton</span>

    <span class="comment"># Initialize the configuration and set defaults:</span>
    <span class="class-variable">@@config</span> = <span class="constant">ConfigurationStruct</span>.new

    <span class="comment"># This is where the defaults are being set</span>
    <span class="class-variable">@@config</span>.enum = <span class="symbol">:one</span>
    <span class="class-variable">@@config</span>.list = []
    <span class="class-variable">@@config</span>.optional = <span class="predefined-constant">nil</span>
    <span class="class-variable">@@config</span>.verbose = <span class="predefined-constant">false</span>

    <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">config</span>
      <span class="keyword">yield</span>(<span class="class-variable">@@config</span>) <span class="keyword">if</span> block_given?
      <span class="class-variable">@@config</span>
    <span class="keyword">end</span>

    <span class="comment"># Loads a YAML configuration file and sets each of the configuration values to</span>
    <span class="comment"># whats in the file.</span>
    <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">load</span>(file)
      <span class="constant">YAML</span>::load_file(file).each <span class="keyword">do</span> |key, value|
        <span class="predefined-constant">self</span>.send(<span class="string"><span class="delimiter">&quot;</span><span class="inline"><span class="inline-delimiter">#{</span>key<span class="inline-delimiter">}</span></span><span class="content">=</span><span class="delimiter">&quot;</span></span>, value)
      <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="comment"># This provides an easy way to dump the configuration as a hash</span>
    <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">to_hash</span>
      <span class="constant">Hash</span>[<span class="class-variable">@@config</span>.each_pair.to_a]
    <span class="keyword">end</span>

    <span class="comment"># Pass any other calls (most likely attribute setters/getters on to the</span>
    <span class="comment"># configuration as a way to easily set/get attribute values </span>
    <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">method_missing</span>(method, *args, &amp;block)
      <span class="keyword">if</span> <span class="class-variable">@@config</span>.respond_to?(method)
        <span class="class-variable">@@config</span>.send(method, *args, &amp;block)
      <span class="keyword">else</span>
        raise <span class="constant">NoMethodError</span>
      <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="comment"># Handles validating the configuration that has been loaded/configured</span>
    <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">validate!</span>
      valid = <span class="predefined-constant">true</span>

      valid = <span class="predefined-constant">false</span> <span class="keyword">if</span> <span class="constant">Configuration</span>.required.nil?

      raise <span class="constant">ArgumentError</span> <span class="keyword">unless</span> valid
    <span class="keyword">end</span>
  <span class="keyword">end</span>

  <span class="keyword">class</span> <span class="class">ConfigurationParser</span>
    <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">parse</span>(args)
      opts = <span class="constant">OptionParser</span>.new <span class="keyword">do</span> |parser|

        parser.separator <span class="string"><span class="delimiter">&quot;</span><span class="delimiter">&quot;</span></span>
        parser.separator <span class="string"><span class="delimiter">&quot;</span><span class="content">Specific options:</span><span class="delimiter">&quot;</span></span>

        parser.on(<span class="string"><span class="delimiter">&quot;</span><span class="content">--enum ENUM</span><span class="delimiter">&quot;</span></span>, [<span class="symbol">:one</span>, <span class="symbol">:two</span>, <span class="symbol">:three</span>], <span class="string"><span class="delimiter">&quot;</span><span class="content">This field requires one of a set of predefined values be</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">set. If wrapped in brackets this option can be set to nil.</span><span class="delimiter">&quot;</span></span>) <span class="keyword">do</span> |setting|
          <span class="constant">Configuration</span>.enum = setting
        <span class="keyword">end</span>

        parser.on(<span class="string"><span class="delimiter">&quot;</span><span class="content">-l</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">--list x,y</span><span class="delimiter">&quot;</span></span>, <span class="constant">Array</span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">This command flag takes a comma separated list (without</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">spaces) of values and turns it into an array. This requires</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">at least one argument.</span><span class="delimiter">&quot;</span></span>) <span class="keyword">do</span> |setting|
          <span class="constant">Configuration</span>.list = setting
        <span class="keyword">end</span>

        parser.on(<span class="string"><span class="delimiter">&quot;</span><span class="content">--[no-]verbose</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">This is a common boolean flag, setting verbosity to either</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">true or false.</span><span class="delimiter">&quot;</span></span>) <span class="keyword">do</span> |setting|
          <span class="constant">Configuration</span>.verbose = setting
        <span class="keyword">end</span>

        parser.on(<span class="string"><span class="delimiter">&quot;</span><span class="content">--optional [STR]</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">This command doesn't require a string to be passed to it, if</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">nothing is passed it will be nil. No error will be raised if</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">nothing is passed to it that logic needs to be handled</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">yourself.</span><span class="delimiter">&quot;</span></span>) <span class="keyword">do</span> |setting|
          <span class="constant">Configuration</span>.optional = setting
        <span class="keyword">end</span>

        parser.on(<span class="string"><span class="delimiter">&quot;</span><span class="content">-r</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">--required STR</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">This command requires a string to be passed to it.</span><span class="delimiter">&quot;</span></span>) <span class="keyword">do</span> |setting|
          <span class="constant">Configuration</span>.required = setting
        <span class="keyword">end</span>

        parser.on(<span class="string"><span class="delimiter">&quot;</span><span class="content">--float NUM</span><span class="delimiter">&quot;</span></span>, <span class="constant">Float</span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">This command will only accept an integer or a float.</span><span class="delimiter">&quot;</span></span>) <span class="keyword">do</span> |setting|
          <span class="constant">Configuration</span>.float = setting
        <span class="keyword">end</span>

        parser.on_tail(<span class="string"><span class="delimiter">&quot;</span><span class="content">-h</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">--help</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">--usage</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">Show this usage message and quit.</span><span class="delimiter">&quot;</span></span>) <span class="keyword">do</span> |setting|
          puts parser.help
          exit
        <span class="keyword">end</span>

        parser.on_tail(<span class="string"><span class="delimiter">&quot;</span><span class="content">-v</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">--version</span><span class="delimiter">&quot;</span></span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">Show version information about this program and quit.</span><span class="delimiter">&quot;</span></span>) <span class="keyword">do</span>
          puts <span class="string"><span class="delimiter">&quot;</span><span class="content">Option Parser Example v1.0.0</span><span class="delimiter">&quot;</span></span>
          exit
        <span class="keyword">end</span>
      <span class="keyword">end</span>

      opts.parse!(args)
    <span class="keyword">end</span>
  <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">if</span> <span class="constant">File</span>.exists?(<span class="string"><span class="delimiter">&quot;</span><span class="content">config.yml</span><span class="delimiter">&quot;</span></span>)
  <span class="constant">Example</span>::<span class="constant">Configuration</span>.load(<span class="string"><span class="delimiter">&quot;</span><span class="content">config.yml</span><span class="delimiter">&quot;</span></span>)
<span class="keyword">end</span>

<span class="constant">Example</span>::<span class="constant">ConfigurationParser</span>.parse(<span class="predefined-constant">ARGV</span>)
<span class="constant">Example</span>::<span class="constant">Configuration</span>.validate!

require <span class="string"><span class="delimiter">&quot;</span><span class="content">json</span><span class="delimiter">&quot;</span></span>
puts <span class="constant">JSON</span>.pretty_generate(<span class="constant">Example</span>::<span class="constant">Configuration</span>.to_hash)
</pre></div>
</div>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/11/keep-your-gems-updated/">Keep Your Gems Updated</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on November 27, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>I recently went back through my backups recently and found quite a few old
abandoned projects. Looking back on the code I see some things I&#39;m impressed
with, but the majority of the code I wouldn&#39;t write today.  Thats not to say
the code is bad, or doesn&#39;t function. It did exactly what I wanted to
accomplish at the time, just not necessarily in the most efficient way.</p>

<p>This archive of old code made me start wondering how much old code I&#39;m using in
the projects that I&#39;m currently writing. Not code that I&#39;ve written but code
that I&#39;m depending on, specifically gems. As of this writing I have 26 active
ruby projects in various states of development all of which make use of RVM and
bundler.</p>

<p>Conveniently enough, bundler provides an easy way to update all the gems
installed in a project unless specific version information was provided in the
Gemfile. None of my projects have had a version directly specified in the
Gemfile with the exception of Rails. Each project also has solid test coverage
(though I must admit it&#39;s usually not complete).</p>

<p>For each project I went through and ran <code>bundle update</code> and kept track of the
results. I did not keep track of unique gems so the four Rails projects
probably had a lot of duplicate gems each one more or less likely to have
different versions of different gems installed depending on when I started the
project.</p>

<p>Across all of the different projects I had 2214 gems installed. Of those 813
had updates. My initial plan was to go through the updates and see how many of
those updates were security or bugfixes, how many were added features, or
performance improvements, but I wasn&#39;t counting on the shear number of gems
that my projects were depending on.</p>

<p>The big question for myself after I updated the Gems was how much will this be
now? Running through the thousands of tests in all of the projects I had
exactly 7 tests that were now failing and they were all due too projects that
removed or renamed a piece of functionality that I was making use of. In one
case I had to extend the core Hash method to replace the functionality. All in
all it took me about a quarter of an hour to fix all the tests after updating
my Gems.</p>

<p>Since I didn&#39;t actually go through all of the gems I don&#39;t know for sure that
my projects are in anyway more secure, faster, or more stable but I can&#39;t
imagine they&#39;re in a worse state. If you have test coverage on your projects
you should try and update the gems and see for yourself.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/11/auditing-heroku-ssh-keys/">Auditing Heroku SSH Keys</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on November 26, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>A good friend of mine recently left the organization I work for and the task of
resetting our passwords and auditing credentials fell on me. Since we use
<a href="https://www.heroku.com/">Heroku</a> for our development platform I needed to not only reset the
credentials for the web portion (which conveniently also handles resetting the
API key) but also revoke any SSH keys he may have added to access it.</p>

<p>Sadly Heroku does not seem to provide any web interface that I could find for
examining what keys were associated with the account. Searching for this
information also didn&#39;t turn up very valuable results; most people were looking
to add keys or resolve issues with missing keys rather than revoking them. I
suspect not many people think of SSH keys when it comes time to revoke access
which is a dire mistake.</p>

<p>I took to the command line to solve my issue as I knew you could list and add
keys that way, so it was a minor leap of logic to assume they could revoke keys
as well. I ran <code>heroku help keys</code> to get the syntax for the commands and was
pleasantly surprised to see an additional option listed in there:</p>
<div class="CodeRay">
  <div class="code"><pre>keys:clear       #  remove all authentication keys from the current user
</pre></div>
</div>

<p>As a now two person web-shop it&#39;s not a terrible amount of work to add our keys
back in and looking through there were already some keys in there that should
have been revoked long ago. One command and our applications were safe from
mischief, though I know my former associate wouldn&#39;t abuse that privilege
beyond perhaps pointing out the security flaw I&#39;d allowed.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/08/carrierwave-s3-and-filenames/">CarrierWave, S3 and Filenames</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on August 9, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>This is going to be a real quick post. I&#39;m using the &quot;carrier_wave&quot; gem with
&quot;fog&quot; for one of my projects and found that when a file is stored on S3 the
&quot;identifier&quot;, and &quot;filename&quot; methods return nil. I got around this issue in two
separate ways neither of which I&#39;m particularly happy about.</p>

<p>Outside of the uploader, you can use the File utility and the URL of the object
to get the base filename like so:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="constant">File</span>.basename(<span class="constant">Model</span>.asset.url)
</pre></div>
</div>

<p>If you try and do this within the uploader itself like this:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="constant">File</span>.basename(<span class="predefined-constant">self</span>.url)
</pre></div>
</div>

<p>It will work, but not when creating additional versions such as thumbnails as
the file hasn&#39;t actually been created yet so a URL can&#39;t be built and you&#39;ll
get an error trying to perform File.basename(nil). You&#39;d need to go back up to
the model and get the normal version&#39;s URL like so:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="constant">File</span>.basename(<span class="predefined-constant">self</span>.model.asset.url)
</pre></div>
</div>

<p>Now if you&#39;re trying to get the file name to build part of the store_dir,
you&#39;ve just created an infinite loop! Ruby will be happy to tell you that the
stack level too deep (SystemStackError). So ultimately how did I end up getting
it into my store_dir?</p>
<div class="CodeRay">
  <div class="code"><pre><span class="predefined-constant">self</span>.model.attributes[<span class="string"><span class="delimiter">&quot;</span><span class="content">asset</span><span class="delimiter">&quot;</span></span>]
</pre></div>
</div>

<p>The file name gets stored raw directly in the database, and thus you can pull
it out by accessing the value directly without going through the accessor that
get overridden by CarrierWave. I&#39;m pretty sure this is a bug, and will report
it with example code and a test (as is appropriate for any bug report <em>hint</em>)
as soon as my dead line has passed.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/08/security-through-obesity/">Security Through Obesity</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on August 8, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>Jeremy Spilman recently <a href="http://www.opine.me/a-better-way-to-store-password-hashes/">proposed changes</a> to how user&#39;s hashes are stored
in website&#39;s and companies databases. This post was originally going to look
at some of the issues involved in the scheme he envisioned, however, he rather
quickly posted a <a href="http://www.opine.me/all-your-hashes-arent-belong-to-us/">followup article</a> with a well thought out solution that
countered all of the issues that other people and myself were able to come up
with. I&#39;d strongly recommend reading both if you haven&#39;t done so. Instead of
announcing flaws, I&#39;m turning this into a post with a simple functional
implementation of the described scheme in Ruby using DataMapper.</p>

<p>At first I&#39;d like to point out that this is one of those few examples where a
form of security through obscurity is actually increasing not only the
perceived security but the cost to attack a system as well.</p>

<p>Please note this code is a minimal, functional, example and should not be used
in production. It is missing a lot of things that I personally would add before
attempting to use this but that is an exercise for the reader. It is licensed
under the MIT license. I&#39;ll walk through the code briefly afterwards going over
some bits.</p>
<div class="CodeRay">
  <div class="code"><pre><span class="comment"># encoding: utf-8</span>

require <span class="string"><span class="delimiter">&quot;</span><span class="content">rubygems</span><span class="delimiter">&quot;</span></span>           <span class="comment"># You only need this if you use bundler</span>
require <span class="string"><span class="delimiter">&quot;</span><span class="content">dm-core</span><span class="delimiter">&quot;</span></span>
require <span class="string"><span class="delimiter">&quot;</span><span class="content">dm-migrations</span><span class="delimiter">&quot;</span></span>
require <span class="string"><span class="delimiter">&quot;</span><span class="content">dm-sqlite-adapter</span><span class="delimiter">&quot;</span></span>
require <span class="string"><span class="delimiter">&quot;</span><span class="content">dm-validations</span><span class="delimiter">&quot;</span></span>
require <span class="string"><span class="delimiter">&quot;</span><span class="content">scrypt</span><span class="delimiter">&quot;</span></span>

<span class="constant">DataMapper</span>.setup <span class="symbol">:default</span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">sqlite:hash.db</span><span class="delimiter">&quot;</span></span>

<span class="keyword">class</span> <span class="class">User</span>
  include <span class="constant">DataMapper</span>::<span class="constant">Resource</span> 

  property <span class="symbol">:id</span>,             <span class="constant">Serial</span>
  property <span class="symbol">:username</span>,       <span class="constant">String</span>, <span class="symbol">:required</span> =&gt; <span class="predefined-constant">true</span>,
                                    <span class="symbol">:unique</span> =&gt; <span class="predefined-constant">true</span> 
  property <span class="symbol">:crypt_hash</span>,     <span class="constant">String</span>, <span class="symbol">:required</span> =&gt; <span class="predefined-constant">true</span>,
                                    <span class="symbol">:length</span> =&gt; <span class="integer">64</span>
  property <span class="symbol">:salt</span>,           <span class="constant">String</span>, <span class="symbol">:required</span> =&gt; <span class="predefined-constant">true</span>,
                                    <span class="symbol">:length</span> =&gt; <span class="integer">25</span> 

  <span class="keyword">def</span> <span class="function">check_password</span>(plaintext_password)
    encrypted_hash = scrypt_helper(plaintext_password, <span class="predefined-constant">self</span>.salt)
    hash_obj = <span class="constant">SiteHash</span>.first(<span class="symbol">:crypt_hash</span> =&gt; encrypted_hash)

    <span class="keyword">if</span> hash_obj.nil?
      puts <span class="string"><span class="delimiter">&quot;</span><span class="content">Invalid password</span><span class="delimiter">&quot;</span></span>
      <span class="keyword">return</span> <span class="predefined-constant">false</span>
    <span class="keyword">end</span>

    verification_hash = scrypt_helper(plaintext_password, hash_obj.salt)

    <span class="keyword">if</span> <span class="predefined-constant">self</span>.crypt_hash == verification_hash
      <span class="keyword">return</span> <span class="predefined-constant">true</span>
    <span class="keyword">else</span>
      puts <span class="string"><span class="delimiter">&quot;</span><span class="content">WARNING: Found matching hash, but verification failed.</span><span class="delimiter">&quot;</span></span>
      <span class="keyword">return</span> <span class="predefined-constant">false</span>
    <span class="keyword">end</span>
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="function">password=</span>(plaintext_password)
    generate_salt

    encrypted_password = <span class="constant">SiteHash</span>.new
    encrypted_password.crypt_hash = scrypt_helper(plaintext_password,
                                                  <span class="predefined-constant">self</span>.salt)
    encrypted_password.save

    <span class="predefined-constant">self</span>.crypt_hash = scrypt_helper(plaintext_password,
                                    encrypted_password.salt)
  <span class="keyword">end</span>

  private

  <span class="keyword">def</span> <span class="function">generate_salt</span>
    <span class="predefined-constant">self</span>.salt = <span class="constant">SCrypt</span>::<span class="constant">Engine</span>.generate_salt(<span class="symbol">:max_time</span> =&gt; <span class="float">1.0</span>)
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="function">scrypt_helper</span>(plaintext_password, salt)
    <span class="constant">SCrypt</span>::<span class="constant">Engine</span>.scrypt(plaintext_password, salt,
                          <span class="constant">SCrypt</span>::<span class="constant">Engine</span>.autodetect_cost(salt),
                          <span class="integer">32</span>).unpack(<span class="string"><span class="delimiter">'</span><span class="content">H*</span><span class="delimiter">'</span></span>).first
  <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">class</span> <span class="class">SiteHash</span>
  include <span class="constant">DataMapper</span>::<span class="constant">Resource</span>

  property <span class="symbol">:id</span>,             <span class="constant">Serial</span>
  property <span class="symbol">:crypt_hash</span>,     <span class="constant">String</span>,   <span class="symbol">:required</span> =&gt; <span class="predefined-constant">true</span>,
                                      <span class="symbol">:length</span> =&gt; <span class="integer">64</span>
  property <span class="symbol">:salt</span>,           <span class="constant">String</span>,   <span class="symbol">:required</span> =&gt; <span class="predefined-constant">true</span>,
                                      <span class="symbol">:length</span> =&gt; <span class="integer">25</span>

  <span class="keyword">def</span> <span class="function">initialize</span>(*args)
    <span class="keyword">super</span>
    generate_salt
  <span class="keyword">end</span>

  private

  <span class="keyword">def</span> <span class="function">generate_salt</span>
    <span class="predefined-constant">self</span>.salt = <span class="constant">SCrypt</span>::<span class="constant">Engine</span>.generate_salt(<span class="symbol">:max_time</span> =&gt; <span class="float">1.0</span>)
  <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="constant">DataMapper</span>.finalize
<span class="constant">DataMapper</span>.auto_upgrade!
</pre></div>
</div>

<p>I tried to keep this as a simple minimum implementation without playing golf.
Strictly speaking the validations on the data_mapper models aren&#39;t necessary
and could have been removed, in this case, however, the length fields do
actually indicate a bit more of what you might expect to see in the database,
while the requires are just good habits living on.</p>

<p>Both of the two models are required to have both a salt and a hash, the name
&#39;crypt_hash&#39; was chosen do too a conflict with one of data_mapper&#39;s reserved
words &#39;hash&#39;, the same goes for the model name, however, that class comes from
elsewhere. Raw scrypt&#39;d hashes are 256 bits long or 64 hex characters long,
while the salts are 64 bits (16 hex characters) plus some meta-data totaling 25
  hex characters in this example.</p>

<p>Salts are hashes are computed by the &#39;scrypt&#39; gem. In this example I&#39;ve bumped
up the max time option to create a hash from the default of 0.2 seconds up to 1
second. This is one of those things that I could have left out as the default
is fine for an example, but it also couldn&#39;t hurt slightly increasing it in
case someone did copy-paste this into production.</p>

<p>The one thing that I&#39;d like to point out is a couple of &#39;puts&#39; statements I
dropped in the check_password method on the User model. The first one simply
announces an invalid password. A lot of these could indicate a brute force
attack. The second one is more serious, it indicates that there is either a bug
in the code, a hash collision has occurred, or an attacker has been able to
drop in hash of their choosing into the site_hashes table, but haven&#39;t updated
the verification hash on the user model yet. I&#39;d strongly recommend reading
through both of Jeremy&#39;s posts if you want to understand how this threat works
and specifically the second post to see how the verification hash protects what
it does.</p>

<p>So how would you use this code? Well you&#39;d want to create a user with a
password and then check if their password is valid or not later on like so:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="constant">User</span>.create(<span class="symbol">:username</span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">admin</span><span class="delimiter">'</span></span>, <span class="symbol">:password</span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">admin</span><span class="delimiter">'</span></span>)
<span class="constant">User</span>.first(<span class="symbol">:username</span> =&gt; <span class="string"><span class="delimiter">'</span><span class="content">admin</span><span class="delimiter">'</span></span>).check_password(<span class="string"><span class="delimiter">'</span><span class="content">admin</span><span class="delimiter">'</span></span>)
</pre></div>
</div>

<p>One of the key ways this separation increases the security of real users&#39;s
hashes is by having a large number of fake hashes in the hash table that the
attackers will have to crack at the same time. As a bonus I&#39;ve written a module
to handle just that for the code I&#39;ve already provided. Once again this is
licensed under the MIT license and should not be considered production ready.</p>
<div class="CodeRay">
  <div class="code"><pre><span class="comment"># This is the code above, you can also include everything below</span>
<span class="comment"># this in the same file if you're into that sort of thing</span>
require <span class="string"><span class="delimiter">&quot;</span><span class="content">user_hash_example</span><span class="delimiter">&quot;</span></span>

<span class="keyword">module</span> <span class="class">HashFaker</span>
  <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">fast_hash</span>
    <span class="constant">SiteHash</span>.create(<span class="symbol">:crypt_hash</span> =&gt; get_bytes(<span class="integer">32</span>))
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">hash</span>
    <span class="constant">SiteHash</span>.create(<span class="symbol">:crypt_hash</span> =&gt; scrypt_helper(get_bytes(<span class="integer">24</span>),
                                                 generate_salt))
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">generate_hashes</span>(count = <span class="integer">5000</span>, fast = <span class="predefined-constant">false</span>)
    count.times <span class="keyword">do</span>
      fast ? fast_hash : hash
    <span class="keyword">end</span>
  <span class="keyword">end</span>

  private

  <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">generate_salt</span>
    <span class="constant">SCrypt</span>::<span class="constant">Engine</span>.generate_salt(<span class="symbol">:max_time</span> =&gt; <span class="float">1.0</span>)
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">get_bytes</span>(num)
    <span class="constant">OpenSSL</span>::<span class="constant">Random</span>.random_bytes(num).unpack(<span class="string"><span class="delimiter">'</span><span class="content">H*</span><span class="delimiter">'</span></span>).first
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">scrypt_helper</span>(plaintext_password, salt)
    <span class="constant">SCrypt</span>::<span class="constant">Engine</span>.scrypt(plaintext_password, salt,
                          <span class="constant">SCrypt</span>::<span class="constant">Engine</span>.autodetect_cost(salt),
                          <span class="integer">32</span>).unpack(<span class="string"><span class="delimiter">'</span><span class="content">H*</span><span class="delimiter">'</span></span>).first
  <span class="keyword">end</span>
<span class="keyword">end</span>
</pre></div>
</div>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/08/adding-a-table-prefix-to-datamapper-tables/">Adding a table prefix to DataMapper tables</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on August 7, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>So I recently encountered a situation where I needed to define a prefix on the
tables used by the &quot;data_mapper&quot; gem. When I went searching I found quite a bit
of information about similar projects in Python, and PHP named DataMapper but
nothing about the ruby &quot;data_mapper&quot;. The search continued eventually ending in
my reading through the source of the data_mapper gem only to find that there
was no feature for simply defining a prefix.</p>

<p>Reading through the source though did allow me to find any easy way to
implement such functionality. The following snippet is a minimalistic
data_mapper initialization and setup of one model with a table prefix of
&quot;source_&quot; (chosen at random and of no significance).</p>
<div class="CodeRay">
  <div class="code"><pre><span class="comment"># encoding: utf-8</span>

<span class="comment"># (1)</span>
require <span class="string"><span class="delimiter">&quot;</span><span class="content">dm-core</span><span class="delimiter">&quot;</span></span>
require <span class="string"><span class="delimiter">&quot;</span><span class="content">dm-migrations</span><span class="delimiter">&quot;</span></span>

<span class="comment"># (2)</span>
<span class="keyword">module</span> <span class="class">PrefixNamingConvention</span>
  <span class="keyword">def</span> <span class="predefined-constant">self</span>.<span class="function">call</span>(model_name)
    <span class="comment"># (3)</span>
    prefix = <span class="string"><span class="delimiter">&quot;</span><span class="content">source_</span><span class="delimiter">&quot;</span></span>
    <span class="comment"># (4)</span>
    table_name = <span class="constant">DataMapper</span>::<span class="constant">NamingConventions</span>::<span class="constant">Resource</span>::<span class="constant">UnderscoredAndPluralized</span>.call(model_name)

    <span class="string"><span class="delimiter">&quot;</span><span class="inline"><span class="inline-delimiter">#{</span>prefix<span class="inline-delimiter">}</span></span><span class="inline"><span class="inline-delimiter">#{</span>table_name<span class="inline-delimiter">}</span></span><span class="delimiter">&quot;</span></span>
  <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment"># (5)</span>
<span class="constant">DataMapper</span>::<span class="constant">Logger</span>.new(<span class="global-variable">$stdout</span>, <span class="symbol">:debug</span>)

<span class="comment"># (6)</span>
<span class="constant">DataMapper</span>.setup(<span class="symbol">:default</span>, <span class="string"><span class="delimiter">&quot;</span><span class="content">sqlite:example.db</span><span class="delimiter">&quot;</span></span>)
<span class="constant">DataMapper</span>.repository(<span class="symbol">:default</span>).adapter.resource_naming_convention = <span class="constant">PrefixNamingConvention</span>

<span class="comment"># (7)</span>
<span class="keyword">class</span> <span class="class">Person</span>
  include <span class="constant">DataMapper</span>::<span class="constant">Resource</span>

  property <span class="symbol">:id</span>, <span class="constant">Serial</span>
  property <span class="symbol">:first_name</span>, <span class="constant">String</span>
  property <span class="symbol">:last_name</span>, <span class="constant">String</span>
  property <span class="symbol">:email</span>, <span class="constant">String</span>
<span class="keyword">end</span>

<span class="comment"># (8)</span>
<span class="constant">DataMapper</span>.finalize
<span class="constant">DataMapper</span>.auto_upgrade!
</pre></div>
</div>

<p>So here are some notes on what&#39;s going on in this snippet. Each area that I
will be discussing has been annotated with a number like &quot;# (1)&quot; to make it
easier to find a section you have questions about.</p>

<ol>
<li>Since this is an example I&#39;m only including the bare minimum data mapper
gems to accomplish the task. If you&#39;re using bundler you may need to also
require &quot;rubygems&quot; to get this too work.</li>
<li>This is where the real work happens, DataMapper uses external modules that
receive the &quot;call&quot; method to handle the conversion of class names to table
names. By default DataMapper uses the module
&quot;DataMapper::NamingConventions::Resource::UnderscoredAndPluralized&quot;, which
I&#39;ll use later to maintain the same names.</li>
<li>This is where I&#39;m defining the table prefix. This could be defined in a
global, call another method or class, whatever your heart desires to get a
string that will be used as a prefix.</li>
<li>Here I&#39;m getting what DataMapper would have named the table if I wasn&#39;t
interferring</li>
<li>I&#39;m logging to standard out so that I can see the queries called to verify
that DataMapper is creating tables with the names that I want. This is used
later on in this post to demonstrate this solution working, however, it
could be left out without affecting anything.</li>
<li>Initial setup of a sqlite database, and then the good stuff. Once a database
has been setup with a specific adapter you can change the naming convention
DataMapper will use to generate table names. This is accomplished by passing
the module constant name through the repositories adapter and too
&quot;resource_naming_convention&quot; as demonstrated in the code.</li>
<li>Here I&#39;m defining an example model of no importance. This is purely for
demonstration, normally DataMapper would name this model &quot;people&quot;.</li>
<li>Inform DataMapper we&#39;re done setting it up and to run the migrations to
create the model defined.</li>
</ol>

<p>When you run this ruby file (assuming you have the &quot;data_mapper&quot; and
&quot;dm-sqlite-adapter&quot; gem installed) you&#39;ll see output very similar too this:</p>
<div class="CodeRay">
  <div class="code"><pre>~ (0.001402) PRAGMA table_info(&quot;source_people&quot;)
~ (0.000089) SELECT sqlite_version(*)
~ (0.077840) CREATE TABLE &quot;source_people&quot; (&quot;id&quot; INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, &quot;first_name&quot; VARCHAR(50), &quot;last_name&quot; VARCHAR(50), &quot;email&quot; VARCHAR(50))
</pre></div>
</div>

<p>Notice the third line? Specifically the name of the table? It&#39;s named exactly
as it would have been except now it has a prefix of &quot;source_&quot;.</p>

<p>Hope this saves someone else some trouble. Cheers!</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/07/thoughts-on-ipv6-security-and-mitigation/">Thoughts on IPv6 Security and Mitigation</a></h1>
    <aside class="post-date">Published <time datetime=''>in the middle of the night on July 21, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>I setup IPv6 on my home network with an OpenWRT router and Hurricane Electric
and now I suddenly have an opinion on the state of IPv6 security. This is
something that I&#39;ve been meaning to do for some time and have been mulling over
in the back of my mind. I&#39;ll go over the details from start to finish of
setting up hurricane electric on the router in another post as the information
to do so is very scattered and disjointed. It does appear to be very well
documented on the OpenWRT wiki but I found that they leave out some very
important steps, so stay tuned for that.</p>

<p>Lets start with the loss of NAT. NAT was never intended to be a security
measure and lots of people will argue with me for saying that it was. However,
the truth of the matter is that any machine that is behind a NAT is not
directly addressable from the internet without someone on the inside
intentionally poking holes (even if that someone is a bad-guy).</p>

<p>Anyone technically knowledgeable enough can usually use fingerprints of how a
machine responds to different types of traffic both normal and unusual to
identify what operating system, version, and specific details about the
services and potential vulnerabilities of that machine. This information is
invaluable to attackers.</p>

<p>One of IPv6&#39;s biggest selling points (and one that I quite enjoy, don&#39;t
misunderstand this post) is that every device is addressable. This can
potentially allow attackers to learn more about what they&#39;re attacking.</p>

<p>So how do you counter this? Well firewalls can help quite a bit in thwarting OS
fingerprinting, but even the strongest firewall won&#39;t completely prevent this.
Another, more protective layer that IPv6 gives you for free is it&#39;s sheer size.</p>

<p>Doing a pure enumeration of a single home subnet remotely (that is you are not
on the link IPv6 local link) would takemillenniaby some estimations, as
opposed the the IPv4 address space which could be done at home in a matter of
weeks. One house vs the world. That is the scale we are now working at in IPv6.</p>

<p>The vast scale, however, while enough to defend against random scans, will not
prevent your address showing up in server logs that you connect to. A single
IPv6 address can be scanned just as easily as an IPv4 address.</p>

<p>What&#39;s more is that once an attacker has a presence on a subnet they can
enumerate every single machine on that network in a matter of seconds to
minutes. Since most home users are infected through drive by trojans, found in
emails, and websites that the user chooses to go to, and attackers are already
used to not having direct access to a machine from the internet, means the
slowness and difficulty of the raw scans just simply won&#39;t be an issue.</p>

<p>Due too the ease of enumerating local networks and that they probably contain
more vulnerable machines.... I&#39;ll leave that extrapolation as an exercise to my
readers.I do predict that infrastructure will become a larger target due to
this, just to collect their logs to attack home users.</p>

<p>The next thing that I want to bring up is IPv6, by default, uses the
interface&#39;s MAC address to generate the last 12 characters / 48 bits of the
IPv6 address. The rest of the local address consists of an identifier
indicating that the address was generated using a MAC address and was not
randomly generated.</p>

<p>So what does this actually tell us? Well if the OS and OS version can help up
specify attacks, why not the brand and possibly the model of the MAC address?
What attack vectors are waiting in the firmware of our ethernet and wireless
cards? Firmware that almost never gets updated, and is known to have bugs and
quirks?</p>

<p>That one is actually an easy one, RFC 3041 defines &quot;Privacy Addresses&quot;. These
are completely random local addresses that get generated once a day. Logs
become increasingly useless on the server end, there is a lot of decoys on
networks, and we&#39;re no longer exposing as much information to potential
hostiles.</p>

<p>I use Fedora 17 and it took me a while to figure out how to enable privacy
addresses the &quot;Red Hat&quot; way. You can easily do it generally on any Linux system
with sysctl. Just add the following to your /etc/sysctl.conf and reload sysctl:</p>
<div class="CodeRay">
  <div class="code"><pre>net.ipv6.conf.all.use_tempaddr = 2
net.ipv6.conf.default.use_tempaddr = 2
</pre></div>
</div>

<p>But that isn&#39;t the &quot;Red Hat&quot; way. Red Hat manages it&#39;s interfaces and network
configuration through various interface configuration files living in
/etc/sysconfig/network-scripts. For any IPv6 enabled interface you can turn on
privacy addresses with the following line for example in
&quot;/etc/sysconfig/network-scripts/ifcfg-eth0&quot;:</p>
<div class="CodeRay">
  <div class="code"><pre>IPV6_PRIVACY=&quot;rfc3041&quot;
</pre></div>
</div>

<p>After restarting your network interfaces they will additionally have privacy
addresses that will be change automatically. The interfaces still have the MAC
based addresses as well but they will not longer be the default and thus will
not show up in remote server logs.</p>

<p>Now, what would be a solid and strong step forward was a way to have a local
machine register it&#39;s privacy address with a local IDS/IPS with an expiration,
and to automatically trigger the IDS/IPS whenever a new connection is made to
an expired privacy address. It would almost be like a free honey pot on your
own network.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/02/updating-to-a-newer-rails-on-dreamhost/">Updating to a Newer Rails on DreamHost</a></h1>
    <aside class="post-date">Published <time datetime=''>in the middle of the night on February 19, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>I&#39;ve started getting heavily into Ruby on Rails development and wanted to use
it in my DreamHost account. I&#39;ve had a shared web account with them since 2004
and they&#39;ve always treated me well. As a former PHP developer they&#39;ve always
had everything that I&#39;ve needed (minus PostgreSQL but everyone has their flaws
hahah) and I was sure they would have my back with Rails.</p>

<p>Unfortunately I found a very old version of Ruby, an old version of Rails and a
sort of locked down way to install gems. Googling and DreamHost&#39;s wiki resulted
in lots of questions but few real this-is-how-you-do-it answers. I finally
managed to piece together a solid solution to get a newer Rails running on
DreamHost through their Passenger installation. This solution doesn&#39;t fix the
version of Ruby I have to use but it gives me enough control over the actual
Rails environment that I&#39;m willing to look past it.</p>

<p>For those out there, yes I am aware of Heroku and professionally I have sites
on there. Yes I know it&#39;s free for a basic account but as soon as you start
getting into real hosting the web worker dynos, database dynos, log drains all
quickly add up to a monthly price that costs me more than two years of
DreamHost hosting.</p>

<p>Please note that this guide assumes you are starting from a completely fresh
DreamHost user. If you&#39;ve made changes to your shell files, you&#39;ll need to
adapt them for this. I also assume that <em>you have not yet setup the site to be
&quot;hosted&quot;</em>. What I mean by this is the domain shows up in your DreamHost account
under a heading of &quot;Registered domains without hosting&quot;. It isn&#39;t a big deal if
you have already set it up but you&#39;ll probably need pay attention to the last
part to ensure it is setup properly.</p>

<p>So what will this guide get you?</p>

<ul>
<li>A version of Rails that is 8 minor revisions newer (3.0.11 vs 3.0.3). This
includes several security fixes.</li>
<li>An isolated gemset from other applications, preventing nightmare gem
dependency issues when hosting several rails app in the same account</li>
<li>A very well defined environment that will allow you to replicate a live
server environment easily in a development environment</li>
</ul>

<p>SSH into your DreamHost user, open up .bashrc file and add this:</p>
<div class="CodeRay">
  <div class="code"><pre>export PATH=$HOME/.gems/bin:$HOME/opt/bin:$PATH
export GEM_HOME=$HOME/.gems
export GEM_PATH=&quot;$GEM_HOME&quot;
export RUBYLIB=&quot;$HOME/opt/lib:$RUBYLIB&quot;

alias gem=&quot;nice -n19 ~/opt/bin/gem&quot;
</pre></div>
</div>

<p>And .bash_profile:</p>
<div class="CodeRay">
  <div class="code"><pre>source ~/.bashrc
</pre></div>
</div>

<p>Run the following commands to setup the environment for the upcoming steps:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ mkdir ~/{src,opt}
[dreamhost]$ cd src
[dreamhost]$ wget http://production.cf.rubygems.org/rubygems/rubygems-1.3.7.tgz
[dreamhost]$ tar -xzf rubygems-1.3.7.tgz
[dreamhost]$ rm -f rubygems-1.3.7.tgz
[dreamhost]$ cd rubygems-1.3.7/
[dreamhost]$ ruby setup.rb --prefix=$HOME/opt
[dreamhost]$ cd ~/opt/bin/
[dreamhost]$ ln -s gem1.8 gem
</pre></div>
</div>

<p>At this point you&#39;re ready to start using the rubygems version you just
installed.</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ gem -v
1.3.6
[dreamhost]$ source ~/.bash_profile
[dreamhost]$ gem -v
1.3.7
</pre></div>
</div>

<p>You&#39;ll want to update to the latest version locally:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ gem update --system
Updating RubyGems
Updating rubygems-update
Successfully installed rubygems-update-1.8.17
Updating RubyGems to 1.8.17
Installing RubyGems 1.8.17
RubyGems 1.8.17 installed

RubyGems installed the following executables:
        /home/&lt;username&gt;/opt/bin/gem1.8
[dreamhost]$ gem -v
1.8.17
</pre></div>
</div>

<p>Please note that you might have a newer version if one has been released since
I wrote this guide.</p>

<p>Because I don&#39;t need ruby documentation in my server environment I disable the
installation and generation by default by creating a ~/.gemrc file and
populating it like so:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="key">install</span>: <span class="string"><span class="content">--no-rdoc --no-ri</span></span>
<span class="key">update</span>: <span class="string"><span class="content">--no-rdoc --no-ri</span></span>
</pre></div>
</div>

<p>Install bundler and rake locally.</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ gem install bundler
Fetching: bundler-1.0.22.gem (100%)
Successfully installed bundler-1.0.22
1 gem installed
[dreamhost]$ gem install rake
Fetching: rake-0.9.2.2.gem (100%)
Successfully installed rake-0.9.2.2
1 gem installed
</pre></div>
</div>

<p>Installing more gems than this into the local system isn&#39;t recommended. If you
define the gems for individual applications you want inside your project&#39;s
Gemfile you can prevent dependency hell when you&#39;re updating gems.</p>

<p>Instead we can setup RVM to handle gemsets.</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ bash -s stable &lt; &lt;(curl -s https://raw.github.com/wayneeseguin/rvm/master/binscripts/rvm-installer)
</pre></div>
</div>

<p>You&#39;ll need to source your .bash_profile file again and make sure that RVM is
up and working like so:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ source ~/.bash_profile
[dreamhost]$ rvm -v

rvm 1.10.2 by Wayne E. Seguin , Michal Papis  [https://rvm.beginrescueend.com/]
</pre></div>
</div>

<p>Before we can start using project specific gemsets we need to install a
matching ruby version with the DreamHost one. This is where most people will
want to differ from my instructions but I&#39;ll tell you now it won&#39;t work.
DreamHost as of this tutorial was using ruby-1.8.7-p72 you can check this by
running the following:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ ruby -v
ruby 1.8.7 (2008-08-11 patchlevel 72) [x86_64-linux]
</pre></div>
</div>

<p>We need to use this version specifically because this is what DreamHost&#39;s
passenger (aka mod_rails) will be running under. Using another version will
work while testing from your command line, but issues will crop up on your
production site. There isn&#39;t anyway to work around that short of purchasing a
VPS or dedicated server, since you&#39;re reading this I&#39;m going to assume you&#39;ve
already considered that and passed on that option. Of course you&#39;re also
welcome to completely disregard this warning as well.</p>

<p>So lets go ahead and install the appropriate ruby version through RVM:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ rvm install ruby-1.8.7-p72
[dreamhost]$ rvm use --default ruby-1.8.7-p72
[dreamhost]$ ruby -v
ruby 1.8.7 (2008-08-11 patchlevel 72) [x86_64-linux]
[dreamhost]$ which ruby
/home//.rvm/rubies/ruby-1.8.7-p72/bin/ruby
</pre></div>
</div>

<p>And now we&#39;re using our own copy of the same version of ruby and it&#39;s being run
out of our home directory. Excellent. This means we can now create unique
gemsets for our projects without worrying about dependencies between them.</p>

<p>Lets setup a simple project for example.com using rails 3.0.11 just as a
sample. Why not 3.1.x or 3.2.x? Well the catch is another old gem running in
DreamHost&#39;s Passenger. They are running rack version 1.2.1 and as of 3.1.0
rails started requiring rack 1.3.2 or later, with rails 3.2.x it jumped all the
way up to 1.4.5 or later. Of course I found this out the hard way... This could
be worked around by running the application as a FastCGI application and I
intend to put up a guide for that as soon as I can get that environment stable.</p>

<p>We&#39;ll start by creating a the domain folder for it and setting up an .rvmrc
file with a unique gemset for the project.</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ mkdir ~/example.com
[dreamhost]$ cd ~/example.com
[dreamhost]$ rvm --create --rvmrc ruby-1.8.7-p72@example_com
</pre></div>
</div>

<p>Leave the directory and come back in. It should alert you about a &quot;new or
modified&quot; .rvmrc file in the directory. This is the one you just created and
yes you want to trust it. You trust yourself don&#39;t you?</p>

<p>Verify we&#39;re inside our gemset real quick:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ rvm gemset list

gemsets for ruby-1.8.7-p72 (found in /home//.rvm/gems/ruby-1.8.7-p72)
=&gt; example_com
   global
</pre></div>
</div>

<p>Perfect the arrow is next to our gemset. Lets install rails 3.0.11 (DreamHost
currently provides version 3.0.3).</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ gem install rails -v 3.0.11
</pre></div>
</div>

<p>It will take a few moments for ruby gems to go out pull down the package lists,
figure out dependencies, grab to source and install them so get a drink of
water and come back.</p>

<p>Great! You&#39;re back lets make sure we&#39;re running the right version of rails now:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ rails -v
Rails 3.0.11
</pre></div>
</div>

<p>Voila! Lets get that project going with a mysql backend:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ rails new . -d mysql
</pre></div>
</div>

<p>And because it&#39;s good to do lets get this under version control.</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ git init
Initialized empty Git repository in /home/&lt;username&gt;/example.com/.git/
[dreamhost]$ git add .
[dreamhost]$ git commit -m &quot;Initial project commit&quot;
</pre></div>
</div>

<p>Before we go any further there is a gem that needs to be added to our Gemfile.
If you bundled and ran the console right now it would be seem happy but there
is a subtle error that you wouldn&#39;t find out until the very end and it&#39;s better
to get it out of the way now.</p>

<p>Add the following line to the Gemfile anywhere in the main part of the config,
I prefer near the top:</p>
<div class="CodeRay">
  <div class="code"><pre>gem 'rack', '1.2.1'
</pre></div>
</div>

<p>Then we&#39;ll re-bundle to make sure we have it:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ bundle install
</pre></div>
</div>

<p>You can make sure your project is happy by popping open the rails console.</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ rails console
Loading development environment (Rails 3.0.11)
1.8.7 :001 &gt;
</pre></div>
</div>

<p>Woo! That right there is Rails 3.0.11 working on DreamHost. Since it&#39;s working
lets add another commit:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ git commit -a -m &quot;Added rack 1.2.1 and tested for working rails 3.0.11&quot;
</pre></div>
</div>

<p>I&#39;ve already setup a database for this site named &quot;example_com&quot; with user
&quot;examplewebperson&quot; and password &quot;web_persons_password&quot; on &quot;mysql.example.com&quot;.
DreamHost makes this process pretty intuitive through their panel and there are
plenty of other tutorials out there to help you along if you get stuck so I&#39;m
going to skip over that part. I also personally prefer to use sqlite3 for
development and testing as it means I don&#39;t have to run another service on my
development machines. In that light this is what my config/database.yml looks
like:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="key">development</span>:
  <span class="key">adapter</span>: <span class="string"><span class="content">sqlite3</span></span>
  <span class="key">encoding</span>: <span class="string"><span class="content">utf8</span></span>
  <span class="key">database</span>: <span class="string"><span class="content">db/development.sqlite3</span></span>

<span class="key">test</span>:
  <span class="key">adapter</span>: <span class="string"><span class="content">sqlite3</span></span>
  <span class="key">encoding</span>: <span class="string"><span class="content">utf8</span></span>
  <span class="key">database</span>: <span class="string"><span class="content">db/test.sqlite3</span></span>

<span class="key">production</span>:
  <span class="key">adapter</span>: <span class="string"><span class="content">mysql2</span></span>
  <span class="key">encoding</span>: <span class="string"><span class="content">utf8</span></span>
  <span class="key">reconnect</span>: <span class="string"><span class="content">false</span></span>
  <span class="key">database</span>: <span class="string"><span class="content">example_com</span></span>
  <span class="key">pool</span>: <span class="string"><span class="content">5</span></span>
  <span class="key">username</span>: <span class="string"><span class="content">examplewebperson</span></span>
  <span class="key">password</span>: <span class="string"><span class="content">web_persons_password</span></span>
  <span class="key">host</span>: <span class="string"><span class="content">mysql.example.com</span></span>
</pre></div>
</div>

<p>We&#39;ll need to add the sqlite3 gem for the test and development environment, add
this to the end of your Gemfile:</p>
<div class="CodeRay">
  <div class="code"><pre><span class="error">group :development, :test do</span>
  <span class="error">gem 'sqlite3'</span>
<span class="error">end</span>
</pre></div>
</div>

<p>And once again run:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ bundle install
</pre></div>
</div>

<p>Lets make sure our development and then production databases are happy:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ rake db:migrate
[dreamhost]$ sqlite3 db/development.sqlite3
SQLite version 3.5.9
Enter &quot;.help&quot; for instructions
sqlite&gt; .schema
CREATE TABLE &quot;schema_migrations&quot; (&quot;version&quot; varchar(255) NOT NULL);
CREATE UNIQUE INDEX &quot;unique_schema_migrations&quot; ON &quot;schema_migrations&quot; (&quot;version&quot;);
sqlite&gt; .quit
[dreamhost]$ RAILS_ENV=production rake db:migrate
[dreamhost]$ mysql -u examplewebperson -pweb_persons_password -h mysql.example.com example_com

mysql&gt; show tables;
+----------------------------+
| Tables_in_example_com |
+----------------------------+
| schema_migrations |
+----------------------------+
1 row in set (0.01 sec)
mysql&gt;; quit
</pre></div>
</div>

<p>Lets commit one last time now that we have some schema:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ git add .
[dreamhost]$ git commit -m &quot;Configured database&quot;
</pre></div>
</div>

<p>We&#39;re almost there, open up <u>config/environment.rb</u> and add this line to the
top of this file. Pay close attention after the @ sign on that as it should be
the same as the gemset you created earlier.</p>
<div class="CodeRay">
  <div class="code"><pre><span class="keyword">if</span> <span class="predefined-constant">ENV</span>[<span class="string"><span class="delimiter">&quot;</span><span class="content">RACK_ENV</span><span class="delimiter">&quot;</span></span>] == <span class="string"><span class="delimiter">&quot;</span><span class="content">production</span><span class="delimiter">&quot;</span></span>
  <span class="predefined-constant">ENV</span>[<span class="string"><span class="delimiter">'</span><span class="content">GEM_PATH</span><span class="delimiter">'</span></span>] = <span class="constant">File</span>.expand_path(<span class="string"><span class="delimiter">'</span><span class="content">~/.rvm/gems/ruby-1.8.7-p72@example_com</span><span class="delimiter">'</span></span>) + <span class="string"><span class="delimiter">'</span><span class="content">:/usr/lib/ruby/gems/1.8</span><span class="delimiter">'</span></span>
<span class="keyword">end</span>
</pre></div>
</div>

<p>Last thing, since we&#39;re working around a lot of things we need to run bundle
install in the production environment to make sure we have all the dependencies
we need for the live site. This unfortunately will need to be done everytime
you manipulate your gem sets:</p>
<div class="CodeRay">
  <div class="code"><pre>[dreamhost]$ RAILS_ENV=production bundle install
</pre></div>
</div>

<p>Open up the DreamHost panel and find the domain your setting up under the
&quot;Manage Domains&quot; setting. Add Hosting to it. Make sure you are running it under
the user that we just set everything up in with a web directory set to/public.
For example my testing domain would be example.com/public. Check the checkbox
for &quot;Passenger&quot; and then hit the button &quot;Fully host this domain&quot;.</p>

<p>As soon as you receive an email from the friendly DreamHost robot, load your
site up in a web browser and you should be greeted with the stock Rails 3.0.11
site. Note that the &quot;About your application&#39;s environment&quot; link will not work
in the production environment, this is intentional and expected for Rails.</p>

<p>This is where I leave you to develop your site. Good luck!</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2012/02/rubys-xmlrpc-client-and-ssl/">Ruby's XMLRPC::Client and SSL</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on February 14, 2012</time> by Sam Stelfox</aside>
    <article>
      <p>For the past few days I&#39;ve been working on a Ruby project that needed to
interact with a remote XMLRPC API. This isn&#39;tparticularlyunusual but it was
the first time from within a Ruby application. Luckily enough Ruby has a built
in XMLRPC client that handles a lot of the messy bits.</p>

<p>The XMLRPC::Client class itself seems fairly simple. There are only a handful
of methods, five of which are for opening a new connection in a few different
ways, and at least two ways to open each type of connection.</p>

<p>As a starting point this was a simplified chunk of code that I was using to
connect to the remote API:</p>
<div class="CodeRay">
  <div class="code"><pre>require <span class="string"><span class="delimiter">'</span><span class="content">xmlrpc/client</span><span class="delimiter">'</span></span>

<span class="keyword">class</span> <span class="class">APIConnection</span>
  <span class="keyword">def</span> <span class="function">initialize</span>(username, password, host)
    <span class="comment"># Build the arguments for the XMLRPC::Client object</span>
    conn_args = {
      <span class="symbol">:user</span> =&gt; username,
      <span class="symbol">:password</span> =&gt; password,
      <span class="symbol">:host</span> =&gt; host,
      <span class="symbol">:use_ssl</span> =&gt; <span class="predefined-constant">true</span>,
      <span class="symbol">:path</span> =&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">/api</span><span class="delimiter">&quot;</span></span>
    }

    <span class="instance-variable">@connection</span> = <span class="constant">XMLRPC</span>::<span class="constant">Client</span>.new_from_hash(conn_args)
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="function">version</span>
    <span class="instance-variable">@connection</span>.call(<span class="string"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>)
  <span class="keyword">end</span>
<span class="keyword">end</span>
</pre></div>
</div>

<p>The problem I ran into was when connecting to a server using HTTPS. I knew that
this certificate was good however I continued to get the message:</p>

<blockquote>
<p>warning: peer certificate won&#39;t be verified in this SSL session</p>
</blockquote>

<p>Ruby has taken the approach of by default not including any trusted certificate
authorities which I greatly appreciate especially considering that in 2010 and
2011 12 certificate authorities were known to have been hacked including major
ones such as <a href="http://www.informationweek.com/news/security/management/232600406">VeriSign</a>, and <a href="http://www.symantec.com/connect/blogs/diginotar-ssl-breach-update">DigiNotar</a>. Some of which were <a href="http://nakedsecurity.sophos.com/2011/08/29/falsely-issued-google-ssl-certificate-in-the-wild-for-more-than-5-weeks/">proven</a>
to have issued false certificates.</p>

<p>Since XMLRPC::Client doesn&#39;t expose it&#39;s SSL trust settings through it&#39;s
methods I went on a bit of a journey through Google to find an answer. What I
found was overly disturbing, a lot of people don&#39;t seem to understand what SSL
is actually for. The solutions I found from the mostegregiousto least:</p>

<ul>
<li>Disabling OpenSSL certificate checking globally with
OpenSSL::SSL::VERIFY_NONE</li>
<li>Overriding the Net::HTTP certificate checking</li>
<li>Disabling OpenSSL certificate checking locally by extending XMLRPC::Client
and over-riding how it was establishing connections</li>
<li>Using an SSL stripping proxy</li>
</ul>

<p>I couldn&#39;t find a solution out there that didn&#39;t the securityconsciousvoice
in my head scream in despair. I asked on <a href="http://stackoverflow.com/questions/9199660/why-is-ruby-unable-to-verify-an-ssl-certificate">StackOverflow</a> for a good
solution. When I asked I didn&#39;t have a good grasp on how Ruby was handling SSL
certificates at all. The thorough answer from <a href="http://stackoverflow.com/a/9238221/95114">emboss</a>didn&#39;t quite answer
my question but it gave me more than enough to really hunt down what I wanted.</p>

<p>First stop, I needed the certificates that I&#39;ll be using to verify the
connection. Every single certificate authority that issues certificates for
public websites makes the public portion of their certificates available and
this is what we need to verify the connection. To find out which ones you
specifically need you can go to the API server&#39;s address and look at it&#39;s
certificate information by clicking on the site&#39;s lock icon. Every browser is a
little different so you&#39;ll have to find this out on your own. With Chrome (and
perhaps others) you can download each of the certificates in the chain that
you&#39;ll need to verify the server&#39;s certificate.</p>

<p>The server I was connecting to was using a <a href="http://www.rapidssl.com/">RapidSSL</a>certificate, who has
been verified by <a href="http://www.geotrust.com/">GeoTrust</a>. You want to grab their certificates base64
encoded in PEM format. Stick them all in a &quot;ca.crt&quot; file. For these two CAs
you&#39;re file will look a lot like this one:</p>
<div class="CodeRay">
  <div class="code"><pre>-----BEGIN CERTIFICATE-----
MIID1TCCAr2gAwIBAgIDAjbRMA0GCSqGSIb3DQEBBQUAMEIxCzAJBgNVBAYTAlVT
MRYwFAYDVQQKEw1HZW9UcnVzdCBJbmMuMRswGQYDVQQDExJHZW9UcnVzdCBHbG9i
YWwgQ0EwHhcNMTAwMjE5MjI0NTA1WhcNMjAwMjE4MjI0NTA1WjA8MQswCQYDVQQG
EwJVUzEXMBUGA1UEChMOR2VvVHJ1c3QsIEluYy4xFDASBgNVBAMTC1JhcGlkU1NM
IENBMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAx3H4Vsce2cy1rfa0
l6P7oeYLUF9QqjraD/w9KSRDxhApwfxVQHLuverfn7ZB9EhLyG7+T1cSi1v6kt1e
6K3z8Buxe037z/3R5fjj3Of1c3/fAUnPjFbBvTfjW761T4uL8NpPx+PdVUdp3/Jb
ewdPPeWsIcHIHXro5/YPoar1b96oZU8QiZwD84l6pV4BcjPtqelaHnnzh8jfyMX8
N8iamte4dsywPuf95lTq319SQXhZV63xEtZ/vNWfcNMFbPqjfWdY3SZiHTGSDHl5
HI7PynvBZq+odEj7joLCniyZXHstXZu8W1eefDp6E63yoxhbK1kPzVw662gzxigd
gtFQiwIDAQABo4HZMIHWMA4GA1UdDwEB/wQEAwIBBjAdBgNVHQ4EFgQUa2k9ahhC
St2PAmU5/TUkhniRFjAwHwYDVR0jBBgwFoAUwHqYaI2J+6sFZAwRfap9ZbjKzE4w
EgYDVR0TAQH/BAgwBgEB/wIBADA6BgNVHR8EMzAxMC+gLaArhilodHRwOi8vY3Js
Lmdlb3RydXN0LmNvbS9jcmxzL2d0Z2xvYmFsLmNybDA0BggrBgEFBQcBAQQoMCYw
JAYIKwYBBQUHMAGGGGh0dHA6Ly9vY3NwLmdlb3RydXN0LmNvbTANBgkqhkiG9w0B
AQUFAAOCAQEAq7y8Cl0YlOPBscOoTFXWvrSY8e48HM3P8yQkXJYDJ1j8Nq6iL4/x
/torAsMzvcjdSCIrYA+lAxD9d/jQ7ZZnT/3qRyBwVNypDFV+4ZYlitm12ldKvo2O
SUNjpWxOJ4cl61tt/qJ/OCjgNqutOaWlYsS3XFgsql0BYKZiZ6PAx2Ij9OdsRu61
04BqIhPSLT90T+qvjF+0OJzbrs6vhB6m9jRRWXnT43XcvNfzc9+S7NIgWW+c+5X4
knYYCnwPLKbK3opie9jzzl9ovY8+wXS7FXI6FoOpC+ZNmZzYV+yoAVHHb1c0XqtK
LEL2TxyJeN4mTvVvk0wVaydWTQBUbHq3tw==
-----END CERTIFICATE-----
-----BEGIN CERTIFICATE-----
MIIDVDCCAjygAwIBAgIDAjRWMA0GCSqGSIb3DQEBBQUAMEIxCzAJBgNVBAYTAlVT
MRYwFAYDVQQKEw1HZW9UcnVzdCBJbmMuMRswGQYDVQQDExJHZW9UcnVzdCBHbG9i
YWwgQ0EwHhcNMDIwNTIxMDQwMDAwWhcNMjIwNTIxMDQwMDAwWjBCMQswCQYDVQQG
EwJVUzEWMBQGA1UEChMNR2VvVHJ1c3QgSW5jLjEbMBkGA1UEAxMSR2VvVHJ1c3Qg
R2xvYmFsIENBMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA2swYYzD9
9BcjGlZ+W988bDjkcbd4kdS8odhM+KhDtgPpTSEHCIjaWC9mOSm9BXiLnTjoBbdq
fnGk5sRgprDvgOSJKA+eJdbtg/OtppHHmMlCGDUUna2YRpIuT8rxh0PBFpVXLVDv
iS2Aelet8u5fa9IAjbkU+BQVNdnARqN7csiRv8lVK83Qlz6cJmTM386DGXHKTubU
1XupGc1V3sjs0l44U+VcT4wt/lAjNvxm5suOpDkZALeVAjmRCw7+OC7RHQWa9k0+
bw8HHa8sHo9gOeL6NlMTOdReJivbPagUvTLrGAMoUgRx5aszPeE4uwc2hGKceeoW
MPRfwCvocWvk+QIDAQABo1MwUTAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBTA
ephojYn7qwVkDBF9qn1luMrMTjAfBgNVHSMEGDAWgBTAephojYn7qwVkDBF9qn1l
uMrMTjANBgkqhkiG9w0BAQUFAAOCAQEANeMpauUvXVSOKVCUn5kaFOSPeCpilKIn
Z57QzxpeR+nBsqTP3UEaBU6bS+5Kb1VSsyShNwrrZHYqLizz/Tt1kL/6cdjHPTfS
tQWVYrmm3ok9Nns4d0iXrKYgjy6myQzCsplFAMfOEVEiIuCl6rYVSAlk6l5PdPcF
PseKUgzbFbS9bZvlxrFUaKnjaZC2mqUPuLk/IH2uSrW4nOQdtqvmlKXBx4Ot2/Un
hw4EbNX/3aBd7YdStysVAq45pmp06drE57xNNB6pXE0zX5IJL4hmXXeXxx12E6nV
5fEWCRE11azbJHFwLJhWC9kXtNHjUStedejV0NxPNO3CBWaAocvmMw==
-----END CERTIFICATE-----
</pre></div>
</div>

<p>Ugly right? That&#39;s what ruby needs though. But how do we get XMLRPC::Client to
actually use that information without hacking it all to pieces? Net::HTTP has a
few methods that allow you to set the appropriate connection settings and
XMLRPC::Client uses Net::HTTP. If XMLRPC::Client allowed to you specify this
directly somehow I would&#39;ve been a lot happier.</p>

<p>Here&#39;s that code snippet again, this time forcing certificate verification with
the ca.crt file. This code assumes that the ca.crt file lives in the same
directory as the connection script:</p>
<div class="CodeRay">
  <div class="code"><pre>require <span class="string"><span class="delimiter">'</span><span class="content">xmlrpc/client</span><span class="delimiter">'</span></span>

<span class="keyword">class</span> <span class="class">APIConnection</span>
  <span class="keyword">def</span> <span class="function">initialize</span>(username, password, host)
    <span class="comment"># Build the arguments for the XMLRPC::Client object</span>
    conn_args = {
      <span class="symbol">:user</span> =&gt; username,
      <span class="symbol">:password</span> =&gt; password,
      <span class="symbol">:host</span> =&gt; host,
      <span class="symbol">:use_ssl</span> =&gt; <span class="predefined-constant">true</span>,
      <span class="symbol">:path</span> =&gt; <span class="string"><span class="delimiter">&quot;</span><span class="content">/api</span><span class="delimiter">&quot;</span></span>
    }

    <span class="instance-variable">@connection</span> = <span class="constant">XMLRPC</span>::<span class="constant">Client</span>.new_from_hash(conn_args)

    <span class="instance-variable">@connection</span>.instance_variable_get(<span class="string"><span class="delimiter">&quot;</span><span class="content">@http</span><span class="delimiter">&quot;</span></span>).verify_mode = <span class="constant">OpenSSL</span>::<span class="constant">SSL</span>::<span class="constant">VERIFY_PEER</span>
    <span class="instance-variable">@connection</span>.instance_variable_get(<span class="string"><span class="delimiter">&quot;</span><span class="content">@http</span><span class="delimiter">&quot;</span></span>).ca_file = <span class="constant">File</span>.join(<span class="constant">File</span>.dirname(<span class="predefined-constant">__FILE__</span>), <span class="string"><span class="delimiter">&quot;</span><span class="content">ca.crt</span><span class="delimiter">&quot;</span></span>)
  <span class="keyword">end</span>

  <span class="keyword">def</span> <span class="function">version</span>
    <span class="instance-variable">@connection</span>.call(<span class="string"><span class="delimiter">&quot;</span><span class="content">version</span><span class="delimiter">&quot;</span></span>)
  <span class="keyword">end</span>
<span class="keyword">end</span>
</pre></div>
</div>

<p>Those last two lines in the initialize method first dive into the connection
we&#39;ve already setup (but before it&#39;s been called), grab the of Net::HTTP and
tells it to force peer verification and to use the certificate file we created
before. No more warning, and we&#39;re actually safe.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2011/05/exploration-of-an-acn-iris-3000/">Exploration of an ACN Iris 3000</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on May 1, 2011</time> by Sam Stelfox</aside>
    <article>
      <p>So I found a dirt cheap video SIP phone (ACN Iris 3000) at a local HAM fest.
After looking around I found the vendor has locked in the phone with their
specific service with an iron grip and had gone out of business. I guess I
should expect that kind of anti-competitive behavior from a business that
Donald Trump has a vested interest in.</p>

<p>I&#39;ve come across one post on a forum that seems to have been crawled and copied
out every where. The poster had cracked it and got it working with an Asterisk
server which is what my ultimate goal for this phone is, however they claim to
have done it by getting root through telnet. The problem being that port 23
(telnet) is not open so this was a dead end.</p>

<p>This is a running document of how I&#39;m doing it, you&#39;ll notice that I&#39;m writing
this as I go.</p>

<h2>Reconnaissance</h2>

<p>First thing&#39;s first a little run down of what I&#39;ve found. I can change the
network address and the way it&#39;s handling networking (either bridged or NAT). I
can not get into the Administrators menu which is where all the juicy bits seem
to be. I&#39;ve found that the factory reset code is 7517517, though that doesn&#39;t
get me anything beyond cleaning up it&#39;s last known phone number.</p>

<p>Through a very thorough nmap scan I&#39;ve found that ports TCP 21, 79, 113, 513,
514, 554, 5060, 7022, and 8080 are all open. There doesn&#39;t appear to be any UDP
ports available which actually surprised me, since SIP over UDP is pretty
common.</p>

<p>7022 and 8080 both immediately caught my eye. 7022 looks like someone moved SSH
(port 22) to a non-standard port, and 8080 is a very common alternate port for
HTTP. Connecting to 7022 via telnet confirmed my suspicions of SSH. I received
this prompt:</p>

<blockquote>
<p>Connected to 10.0.0.85.
Escape character is &#39;<sup>]&#39;.</sup>
SSH-2.0-dropbear_0.45</p>
</blockquote>

<p>Bingo. SSH it is, and an old version of dropbear at that. Unfortunately as the
one poster I found said the password was neither blank nor &#39;root&#39;. I suspect
that they had an older firmware revision and these &#39;bugs&#39; were ironed out in a
later revision. That&#39;s ok though it&#39;ll just take a bit more work.</p>

<p>As for port 8080 it is definitely running a web configuration interface. All it
asks for is a password (which we don&#39;t have). The extension for the login page
(esp) makes me suspect that the Iris device is running a copy of AppWebServer
or something similar and using embedded javascript as the server side
processing. For now that doesn&#39;t provide much but it could be very useful later
on.</p>

<h2>Attack</h2>

<p>So while looking for an exploit for DropBear 0.45 I started up a SSH dictionary
attack and encountered by first real problem. The screen started blinking while
running three or more threads trying to break in, at first I thought it was
kind of funny but then it turned off completely.</p>

<p>Turns out the adapter I have for it is only rated for pushing out 500mA and the
phone itself takes up to 1500mA, apparently I hit that limit and browned-out
the phone. It still seems to work but if I want to take this route I&#39;ll need a
more robust power supply. Looking around I found a 1500mA supply and after
checking the boards for damage I gave it a shot and everything seems to be
working OK.</p>

<p>Unfortunately I wasn&#39;t able to find any viable exploits for that particular
DropBear version as the vulnerabilities that had been found were either DoS
vulnerabilities or were only useful with valid credentials.</p>

<p>The basic dictionary attack failed and I started up a more comprehensive one. I
could easily start brute forcing this but it would take a very long time,
especially if the company realized that a weak password wasn&#39;t cutting it.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2011/02/linux-n-issues-and-kde-multi-monitor-woes/">Linux N Issues & KDE Multi-Monitor Woes</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on February 25, 2011</time> by Sam Stelfox</aside>
    <article>
      <p>So I recently did a fresh install of Fedora 14 with KDE installed (not the KDE
spin mind you) on my ThinkPad. I&#39;m pleasantly surprised with hows it&#39;s working
everything seems to be working out the box very stably. I used it without issue
for a solid month and a half without a single issue.</p>

<p>Earlier this week I started having issues with my wireless card on some
networks, but not at all of them. The most prominent one being my home network.
I&#39;ve had issues with my access point dropping connections before on a wide
array of machines and not actually dropping it (ie: my laptop would see it as
connected but the AP wouldn&#39;t exchange traffic with it). So when I started
seeing this behavior I expected that issue to have cropped up again.</p>

<p>The actual behavior that I was witnessing was this:</p>

<ol>
<li>Connect to wireless network</li>
<li>Use the connection for 5-10 seconds</li>
<li>Pages would start timing out even though the connection was still &#39;active&#39;</li>
</ol>

<p>Disconnecting and reconnecting to the wireless would start the situation all
over again, which quickly became frustrating but I didn&#39;t have time to mess
with it so I just plugged into an ethernet port and went about my business.</p>

<p>The next day I received my the logwatch from my laptop (Yes, my laptop sends
it&#39;s logs to my email) and it mentioned more than 20,000 new entries of an
error I&#39;ve never seen before:</p>
<div class="CodeRay">
  <div class="code"><pre>iwlagn 0000:03:00.0: BA scd_flow 0 does not match txq_id 10
</pre></div>
</div>

<p>After poking around a bit online I found that the issue is with a recent kernel
update (I&#39;m currently running 2.6.35.11-83) changing the behavior of some
sanity checks to wireless connections that support &#39;N&#39;. Turns out my wireless
card and all the networks I was having issues with support &#39;N&#39;. Good to know.</p>

<p>It was easy enough to solve that issue, the kernel module just needed an option
passed to it that I believe just disables &#39;N&#39;. This is all well and good but I
haven&#39;t had to manually pass options to a kernel module for a couple of
releases now (I think the last was Fedora 10). Since then the file
<em>/etc/modules.conf</em> has been deprecated in favor of placing files in
<em>/etc/modules.d/</em>. There are some files that come stock in there but none are
passing parameters to modules and the naming scheme doesn&#39;t seem to conform to
anything.</p>

<p>I was unsure if there was something specific I had to name the file or if it
needed to be in one of the existing files. I ended up creating the
file<em>/etc/modprobe.d/iwlagn.conf</em> and putting the following in it:</p>
<div class="CodeRay">
  <div class="code"><pre>options iwlagn 11n_disable=1
# This one might be needed instead
#options iwlagn 11n_disable50=1
</pre></div>
</div>

<p>After I rebooted the problem vanished like it was never there. If you notice
there is a second option in there that is commented out. I found some people
where the first option didn&#39;t work but replacing it with that second option
did, so if one doesn&#39;t work for you try the second option.</p>

<p>The second issue that I encountered was just this morning. I&#39;m working at a
remote site today that I&#39;m not at very often, and am using my laptop as my
desktop workhorse. Usually when I&#39;m at a remote site, I steal an office that
isn&#39;t in use and claim it as my own, and today was no different. There was a
screen in this office that had its power plugged it but it&#39;s VGA cable was just
sitting there. I figured &#39;why not?&#39; so I plugged it in and KDE happily
announced that it detected a new display and offered to take me to the settings
interface that would allow me to configure it.</p>

<p>&quot;Awesome!&quot; I thought, multiple desktops has always been one of those things I
had to tweak and search around for and it looks like KDE is making some serious
strides in their support for it. When I turned it on I wasn&#39;t really paying
attention to the settings and my laptop display ended up on the wrong side of
the screen and my primary desktop on the LCD. Not exactly what I wanted but
it&#39;s cool that it was that easy to setup.</p>

<p>I went back into the configuration options switched things around, but no
matter what I did, the &#39;primary desktop&#39; was always on the external monitor.
What&#39;s more is that there isn&#39;t any option for selecting the primary display!
That <em>usedto</em> be there...</p>

<p>I hunted around before getting frustrated and searching around online. Sure
enough other people were annoyed by this regression but the solution was very
easy (though it appears you have to do it everytime).</p>

<p>To set the primary monitor to my laptop screen (LCDS1) I just opened a shell
and put this in:</p>
<div class="CodeRay">
  <div class="code"><pre>xrandr --output LCDS1 --primary
</pre></div>
</div>

<p>Poof! Everything is all set and I&#39;m happy once again. I hope that the KDE
developers put back the primary display selection in the settings but for now
it&#39;s easy enough. Hopefully this will help other people on the net.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2011/02/ipv6-enabled-webservers/">IPv6 Enabled WebServers</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on February 17, 2011</time> by Sam Stelfox</aside>
    <article>
      <p>I&#39;ve happily been using <a href="http://www.dreamhost.com/redir.cgi?ad=rewards%7C71008">DreamHost</a> for over 6 years now. They <a href="http://blog.dreamhost.com/2011/02/03/ipv6-now-available-from-dreamhost/">recently
announced</a> that they are IPv6 enabled. All of my webservers are happily on
the IPv6 internet now thanks to them and it was free to boot. In my upcoming
IPv6 trials I now know at the very least I will still be able to update this
blog.</p>

<p>Thanks DreamHost for staying on top of technology like this! You never
disappoint.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2011/02/exploration-of-ipv6-part-0-overview-and-project-goals/">Exploration of IPv6 Part 0: Overview and Project Goals</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on February 17, 2011</time> by Sam Stelfox</aside>
    <article>
      <p>Last week I finally picked up a project that I&#39;ve been putting off for far too
long. IPv6. With all of the Class A IPv4 subnets assigned and the total pool of
available addresses rapidly dwindling it was time to make the move. When I
started hunting down information about IPv6 and using it on my local network I
was inundated with a lot of information about <em>what</em> IPv6 is, <em>why</em> we need it,
and <em>when</em> everyone will need to be on it but very little about how to
implement it.</p>

<p>To this end I&#39;m writing these posts about the how and glossing over the what,
why, and when. For those of you who are interested in that information I
strongly recommend you read the <a href="http://en.wikipedia.org/wiki/Ipv6">Wikipedia article on IPv6</a>. It covers
everything that I&#39;ve found in other blog posts and news releases and a lot more
that isn&#39;t.</p>

<p>On to the specifics. My home network is closer to a small-business network
crossed with an enterprise network. I have multiple subnets devoted to specific
tasks (Public, DMZ, Server, Trusted LAN). I have two wireless networks, the
first one is WPA2 802.1x using my own  PKI for certificates, and the second is
WEP  secured with static addresses MAC restrictions and does not route to the
internet. The latter is for some very old devices I have that don&#39;t support the
secure wireless but still need to talk to a local service.</p>

<p>Ultimately I should not have to sacrifice any of my security to upgrade to IPv6
and I firmly believe in defence in depth. Off the top of my head the only thing
I lose security wise is NAT which a lot of people argue is security through
obscurity and not actually a layer of security but I <a href="/blog/2011/02/the-home-network-and-nat-as-a-security-layer/">personally disagree</a>.
I don&#39;t <u>have</u> to lose NAT as there are NAT66 options out there but to be
honest, we need to start looking at the future and sticking with old and
outdated security models will only end up causing a lot of trouble. I also
don&#39;t want to deal with the thought of 2<sup>16,386</sup> potential addresses out there
(That&#39;s assuming every IPv6 address is hiding a NAT <em>shudder</em>).</p>

<p>My servers are all running either Fedora 14 or CentOS 5.5 as I&#39;m most
comfortable with the Red Hat architecture. Anyone out there using a different
system architecture will have to look elsewhere (sorry). I also have Mac OS X
(10.3 and 10.4) and Windows 7 clients. Lucky for me they all support IPv6
natively, they just need to be configured.</p>

<p>So what do I want to accomplish with this project? I intend to break this down
into stages, each stage will be followed up with a post on this blog with the
details of what I did, how I accomplished it, and any pitfalls I ran into.
These stages will be:</p>

<ol>
<li>Firewall, Initial Connection, and Security Plan</li>
<li>Getting the clients online (Routing, FreeRADIUS, radvd)</li>
<li>Getting the public servers online (Apache, Postfix, Bind)</li>
<li>Getting file &amp; database servers online (MySQL, OpenLDAP, Samba, NFSv4)</li>
<li>Getting support services online (Kerberos, Syslog, Snort)</li>
<li>Pulling the plug on IPv4 (NAT64, DNS64)</li>
<li>One month IPv6 only report</li>
</ol>

<p>Part 2 may also include ISC DHCPd configuration for stateful IPv6 client
configuration. This will be something that I cover all the pros and cons about
in the security plan and will be decided then. At the very end (Parts 6 &amp; 7) I
will have all of my home systems running IPv6 only for one month too see the
state of IPv6 and see what clients still work. Thanks to the magic of NAT64 and
DNS64 I should be able to access everything that is still IPv4 as if it was
IPv6.</p>

<p>Stay tuned. This is going to be a bumpy ride.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2011/02/the-home-network-and-nat-as-a-security-layer/">The Home Network and NAT as a Security Layer</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on February 17, 2011</time> by Sam Stelfox</aside>
    <article>
      <p>One of the hot-topics for IPv6 (which I have been thinking about a lot lately)
is NAT. I normally wouldn&#39;t go into detail about specifics that are obvious to
people in my field but for the sake of this post I will. NAT or Network Address
Translation, is a way for a large number of computers to share a single public
IP address.</p>

<p>The router that is handling the NAT will keep track of connections coming in
and out of it and re-write the destination IP to an internal address to keep
the traffic flowing.</p>

<p>NAT was necessary with IPv4 because IPv4 only had 4,294,967,296 addresses on
the internet and quite a few those were unroutable or reserved. With a world
population of 7 billion only half the population of the planet could have a
single device online at a time. IPv6 solves this issue by increasing the number
of public routable address to 3.410<sup>38.</sup> That means that each person alive
could have 4.9x10<sup>28</sup> addresses online at any given time.</p>

<p>So what does this mean for NAT? Clearly we don&#39;t need it any more right? There
is no way I&#39;ll ever use 4.9x10<sup>28</sup> addresses. I&#39;m willing to bet Google doesn&#39;t
own that many machines. Well this is where the debate starts. NAT was never
designed to be used as a security tool and it has even had some security
ramifications because of it.</p>

<p>The weakness of NAT is also it&#39;s primary strength. What do I mean by that? You
can&#39;t attack a computer if you can&#39;t talk to it. In my opinion, this alone has
protected innumerable regular home users from all kinds of terrible things
online. A standard COTS router that comes with most internet connections will
stop port-scans and automated attack tools at the door.</p>

<p>Sounds good right? So why would people be opposed to it? Simple. It complicates
things. There are a limited number of simultaneous connections that can go
through a single NAT device. This hard limit of 65,536 connections (in reality
this number is an order of magnitude less - 32,768) isn&#39;t changed between IPv4
and IPv6 and there really isn&#39;t a good reason to change it. Sounds like a lot
but trust me it gets used up quickly.</p>

<p>There is also identity reasons, behind a NAT could be 100 people or 1 and to
the rest of the world it will all look the same. If someone breaks into a home
network there isn&#39;t any way to differentiate that cracker from a normal user to
the outside world. This privacy also gives home users plausible deniability for
anything that happens on their network.</p>

<p>But those arguments against have very little to do with security. So what is
all this hype about NAT being a form of security through obscurity? The
argument I come across whenever I ask neigh-sayers about NAT, is that if a user
gets infected then the network can still be enumerated behind the NAT as if all
the computers were on the Internet. This argument has one fatal flaw. It is
depending on a user to get infected. A firewall has this exact same
&quot;vulnerability&quot; so would they argue that a firewall is not a layer of security?
I thought not.</p>

<p>NAT has it&#39;s problems, but claiming it is not a security layer is just plain
wrong. IPv6 is here to stay and we should really start looking at the security
implications of everything involving it. New security models need to be created
and lots of of research needs to be done in this area still. In the mean time I
suspect a lot of malware and viruses will start making use of IPv6 and how
relatively unknown it really is.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2010/06/a-little-surprise-nestled-among-software/">A Little Surprise Nestled Among Software</a></h1>
    <aside class="post-date">Published <time datetime=''>during lunch on June 30, 2010</time> by Sam Stelfox</aside>
    <article>
      <p>So yesterday my morning started out by my organization&#39;s WAN administrator
pointing out some weird https traffic coming from one of our building&#39;s
subnets. I looked and sure enough there was a steadily growing stream of https
traffic coming from there. There was a few offices in that building and several
labs that weren&#39;t being used for the summer. Definitely not enough people to be
downloading the 10Mb/s and growing stream of information.</p>

<p>My first thought was virus outbreak. Using the net flows generated by the
building&#39;s head switch I watched as dozens of computers created https
connections to an IP address block owned by a German telecom. Another red flag.
The entire lab seemed to have  it.</p>

<p>There were no PTR records to indicate any kind of legitimate service  running
on the IPs they were connecting to. Great. That lab had just been ghosted with
an image so the master must have it. Sure enough the master was making the same
connections. I blocked all https traffic on that subnet and went about digging
deeper into the infection.</p>

<p>This is where I&#39;m going to go on a bit of a tangent rant. Windows UAC. The labs
have all had Windows 7 Enterprise deployed to them and for security reasons we
left UAC on. It&#39;s annoying but for the most part it&#39;s a good security addition
to Windows, with the exception of use cases beyond how the developers use their
machines...</p>

<p>I&#39;m far more comfortable doing everything on a computer from a keyboard, even
in Windows. It&#39;s quite rare for me to use the mouse unless I&#39;m playing a game,
doing image manipulation or browsing the web. So when I open a command prompt
from and administrator account and run a command that gets stopped by UAC I
expect the same prompt I would for any program that I tried to run using
Window&#39;s GUI or a Windows equivalent of the venerable sudo utility.</p>

<p>You have to start the command prompt with Administrator privileges which
involves navigating through a context menu in a context menu in a context menu
(the right click menu, in the accessories folder menu, in the programs
menu...). Alternatively you can make it so the command prompt always starts
with Administrator privileges, but I don&#39;t always need them and don&#39;t want them
when I don&#39;t need them.</p>

<p>If this was limited to the command prompt I wouldn&#39;t be as bothered, but it
does the same damn thing from the run prompt. Rather than popping up a dialog
box to confirm an action Windows will immediately deny the ability to run the
program and you&#39;re left navigating menus (or in the case of the group policy
editor, traversing Window&#39;s folder structure to find the executable so you can
right click on the damn thing).</p>

<p>Moving on... a quick run of netstat showed the connection attempts to the
foreign servers stuck in a SYN_SENT mode. Good, it wasn&#39;t talking to anyone any
more and the subnet&#39;s traffic graph reflected that. I ran &quot;netstat -b&quot; to find
out what program was creating the connection. &quot;Akamai&quot;.</p>

<p>I know that sounded familiar. I vaguely remembered it having to do with DNS and
connecting user&#39;s to the closest server to deliver content but that didn&#39;t
involve a client and definitely wasn&#39;t as noisy or as obnoxious as this thing.
So where was it? Well no one was logged into any of the computers while this
was happening so it was running before login so probably snuck itself in as a
service.</p>

<p>Usually I&#39;d just jump straight to the registry to try and find this kind of
thing but I already had the computer management window open so I took a quick
peek at the service listing. Right nr the top &quot;Akamai NetSession Interface&quot; was
set to start on boot. Bingo, but this looked some what legitimate. We didn&#39;t
willingly install this, but it had all the signs of professionally made
software and wasn&#39;t trying to hide itself beyond not being listed as an
installed program.</p>

<p>I shutdown all the computers on the subnet and went looking for answers.
Apparently Akamai has started a service that allows companies to cache content
used by their programs on user&#39;s local machines.</p>

<p>We didn&#39;t want this software, it&#39;s using a lot of traffic, and nowhere were we
told that it would also be installed or what the ramifications would be.
Regardless of what the company wants to call this, it&#39;s malware as far as I&#39;m
concerned even if it the software wasn&#39;t designed with a malicious intent it
was consuming large amounts of resources that we didn&#39;t willingly give it.</p>

<p>All the software on the lab machines was there for a reason, and it wasn&#39;t
obvious which of the pieces of software it came with. Without knowing where it
came from, I know that simply removing it from the computers wouldn&#39;t be enough
to stop it from coming back. I couldn&#39;t block the traffic as it was using
standards compliant https connections.</p>

<p>Disabling the service seemed to do the trick so I wrote a quick Administrative
Template for GPO that I could deploy across our domain to permanently disable
the service on any machine that was unfortunate enough to get this nasty thing.
If your familiar with GPO&#39;s and Administrative Templates here is the source of
mine that I used to manage this damn service:</p>
<div class="CodeRay">
  <div class="code"><pre>CLASS MACHINE
CATEGORY !!SystemOnly
  POLICY !!PolicyName
    KEYNAME &quot;SYSTEM\CurrentControlSet\Services\Akamai&quot;
    PART !!PartName DROPDOWNLIST REQUIRED
      VALUENAME &quot;Start&quot;
      ITEMLIST
        NAME &quot;Automatic&quot; VALUE NUMERIC 1
        NAME &quot;Manual&quot; VALUE NUMERIC 3
        NAME &quot;Disabled&quot; VALUE NUMERIC 4 DEFAULT
      END ITEMLIST
    END PART
  END POLICY
END CATEGORY

[strings]
SystemOnly=&quot;System&quot;
PolicyName=&quot;Akamai NetSession Interface&quot;
PartName=&quot;Akamai NetSession Interface Service Status&quot;&lt;/code&gt;
</pre></div>
</div>

<p>After enabling the policy and a couple of reboots later and the traffic was
gone. I personally despise any company that installs anything other than what
you want. It&#39;s just bad practice. If you have to hide it, your users probably
don&#39;t want it. Don&#39;t piss off your user base, that&#39;s just bad for business.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2010/06/inspeckt-and-user-input/">Inspeckt and User Input</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on June 18, 2010</time> by Sam Stelfox</aside>
    <article>
      <p>I started working on a rather large PHP based project that needed to take input
from user&#39;s of the website clients (Both form submission and URL based
navigation). These are without question the largest attack surface and most
easily exploited location for vulnerabilities to be introduced into a web
application.</p>

<p>For reasons outside of the topic of this post I decided to not use a pre-made
framework such as Zend to build the application. This left me in a tricky
situation as it meant I&#39;d have to come up with a solution to validate that
input. I went searching for a standalone library to handle this validation for
me. Something that had already been tested and examined by the wonderful open
source community (Can you tell where my loyalties lie?).</p>

<p>I finally get pointed in the direction of <a href="http://code.google.com/p/inspekt/">Inspekt</a>. From the Google Code
page:</p>

<blockquote>
<p>Inspekt acts as a sort of &#39;firewall&#39; API between user input and the rest  of
the application.  It takes PHP superglobal arrays, encapsulates  their data
in an &quot;cage&quot; object, and destroys the original superglobal.   Data can then
be retrieved from the input data object using a variety of  accessor methods
that apply filtering, or the data can be checked  against validation methods.
Raw data can only be accessed via a  &#39;getRaw()&#39; method, forcing the developer
to show clear intent.</p>
</blockquote>

<p>Inspekt conveniently comes with several predefined validators (called tests)
including email, zip code, alphanumeric only, credit card numbers, IP
addresses, hostnames, even custom regular expressions. Filter extend this into
a whole new area, returning only the type of information you want and stripping
everything out of the variable.</p>

<p>The best part is that it is written in a way that you don&#39;t have to use it
exclusively with POST and GET requests. You can create a &#39;cage&#39; around any
variable or array or just put filters and tests on them. It never gets rid of
the raw input either if you ever need that again. For anyone out there that
needs to validate input from anywhere, I&#39;d strongly recommend taking a look at
Inspekt.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2010/06/nice-update/">Nice Update</a></h1>
    <aside class="post-date">Published <time datetime=''>during lunch on June 18, 2010</time> by Sam Stelfox</aside>
    <article>
      <p>I know I don&#39;t update this blog as often as I&#39;d like and I have had a lot going
on in my project realms to put up here. That sadly is not what this short
little post is about. Normally, I really don&#39;t care about updates to WordPress.
I perform them diligently to prevent breaches into my sites, however they don&#39;t
really come with any other benefits.</p>

<p>This time however I was greeted with a clean refreshing theme. I&#39;ve got to give
it to the WordPress UI designers on this one. It is simple and that&#39;s all that
I need.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2010/03/pfsense-and-gaming/">pfSense and Gaming</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on March 24, 2010</time> by Sam Stelfox</aside>
    <article>
      <p>Previously while reviewing open source firewall distributions (which I never
finished), I mentioned some gaming issues. I found a solution that seems to fix
all the issues I had with gaming but unfortunately creates a few new issues
that I didn&#39;t arise. The issue lies with how pfSense performs NAT&#39;ing.</p>

<p>The ports that a particular client opens under some cases can be easily
predicted and in turn exploited. To prevent this pfSense randomizes the
external port that traffic is coming from. This is perfectly fine for any
application that follows networking standards. However it seems that games such
as Call of Duty and Company of Heroes passes the port they open inside their
network protocol which is what the game servers then use to connect back to
them rather than looking at the actual frames that arrive from the client. This
means that the server will be trying to connect back on the wrong port as
pfSense has changed it.</p>

<p>I can see some impossibly small security benefits for the game programmers to
do this. I&#39;m guessing more likely than not this was a failing of the network
library they use where they don&#39;t have access to the information in the frames
of the packets so they wrote a work around for it, and in turn violate basic
network programming best practices.</p>

<p>So what&#39;s the solution? I strongly recommend that anyone reading this read the
complete article as it is possible to prevent yourself from being able to use
your network connection behind pfSense. If any setting doesn&#39;t look quite like
I describe it your probably using a different version and should consult with
the good people in the IRC channels or in their forums.</p>

<p>Here are the steps to get it to work:</p>

<ol>
<li>Open up Firewall -&gt; NAT</li>
<li>There should be three tabs, &#39;Port Forward&#39;, &#39;1:1&#39;, and &#39;Outbound&#39;</li>
<li>Click on the &#39;Outbound&#39; tab</li>
<li>There should be two radio buttons, by default &quot;Automatic outbound NAT rule
generation (IPsec passthrough)&quot; is selected. Choose &quot;Manual Outbound NAT
rule generation (Advanced Outbound NAT (AON))&quot;</li>
<li>Verify that there is a mapping with the following settings:

<ul>
<li>Interface: WAN</li>
<li>Source: Your internal (LAN) subnet</li>
<li>Source Port: *</li>
<li>Destination: *</li>
<li>Destination Port: *</li>
<li>NAT Address: *</li>
<li>NAT Port: *</li>
<li>Static Port: YES</li>
</ul></li>
<li>If you have more than one subnet you&#39;ll need to do this for each one.</li>
<li>Save and Apply the settings</li>
</ol>

<p>That should be it, there has only been two issues that I&#39;ve found, one I&#39;m not
really sure if it&#39;s related. About the same time as when I made this change
UPnP broke. I&#39;m not sure why but it&#39;s something that seems to break quite a bit
with pfSense and I can see this being related to NAT&#39;ing.</p>

<p>The second issue is traffic in between subnets. While it seems to mostly work,
there have been a few oddities such as a computer on one subnet is able to talk
to a computer on a different subnet as long as it initiates the connection. If
the other computer trys to initiate the connection then it will just time out.
It definitely wasn&#39;t related to firewall rules (I set an allow all on both
interfaces and turned off the firewall on both computers). Switching back to
auto-nat&#39;ing resolved the issue.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2010/02/project-hermes-broad-overview/">Project Hermes: Broad Overview</a></h1>
    <aside class="post-date">Published <time datetime=''>during lunch on February 4, 2010</time> by Sam Stelfox</aside>
    <article>
      <p>For the past few months, the little free time that I haven&#39;t spent with friends
or playing with my personal servers has been put towards working out the
details of a rather ambitious plan for my car. The goal? Set my car up as a
mobile internet relay for emergency use. I&#39;ve named this project Hermes. My
naming scheme for all of my projects is based off mythological figures, folk
lores and beasts. It&#39;s a nice broad name set and I can usually associate the
goal of the project with a well known (or not) story. Hermes, messenger of the
gods, patron of boundaries and those that cross them. Hermes often helped
travelers have a safe and easy journey. Perfect.</p>

<p>Now on to some details, what do I want out of this project? What are my
requirements? I want to be able to quickly establish reliable mobile short
range and long range communication which could be brought into an area where
other more common forms of communication have failed. This means having a broad
range of mobile wireless transmitting and receiving stations built into my car
and ready to be turned on at a moments notice.</p>

<p>Natural disasters cause a lot of chaos and disorganization. Priority should
always be the welfare of those affected including getting water, food, medical
supplies and shelter to those without. To accomplish this organization and
communication needs to be in place to facilitate people communicating these
needs. That is one reason why I&#39;m doing this, the second being that it&#39;s just
plain cool.</p>

<p>The most prevalent form of communication in use today is the Internet. Even our
phones have started using the Internet as a backbone for their infrastructure.
However, finding an internet connection around an event such as hurricane
Katrina is impossible due to the sheer volume of damage. What&#39;s the solution?
There is a means of communication which seems to be overlooked more than not by
most people; HAM radio.</p>

<p>HAM or Amateur radio allows for extremely long range communication (in certain
cases to the other side of the world). Amateur radio operates in many
frequencies all of which you are required to have a license to transmit on.
Licenses are fairly easy to acquire.</p>

<p>I learned the material the test covers in about three hours and paid $30 to get
my Technician license. Amateur radio is usually used as the core means to
communicate during national events due to the lack of infrastructure and long
range that is provided by such a setup. Perfect for this project.</p>

<p>As a short range communication, two commercial access points with custom
firmware should do the trick. One for broadcasting and one for connecting to
additional access points. I want to be able to connect to additional access
points to provide an internet connection to the car&#39;s future internal network,
and through my car to become a hub for packet radio communications over Amateur
radio.</p>

<p>This won&#39;t provide a lot of bandwidth (about 9600bps) which after over head and
protocol communications works out to about 750 characters a second of
communications. That may seem slow but thats a hell of a lot faster than trying
to communicate the same message via voice.</p>

<p>In the event that cell service is available outside of the affected area but
still within range of ham radio, a cell phone with a data connection and a
bluetooth link can be the source of internet rather than leeching off a
stranger&#39;s wifi.</p>

<p>To handle the routing of data, packet radio modem, bluetooth and wireless link,
I&#39;m going to need some kind of dedicated computer. Adding all of these devices
to my car causes a problem. Power. Remote communications back to the hub can be
accomplished using a handheld ham radio and a laptop computer.</p>

<p>Since I can&#39;t rely on the electrical grid during a natural disaster this means
I&#39;ll need a way to charge their batteries from my base station, which is
another major power drain. I could leave my car on to run the alternator and
power the devices that way but I would quickly run out of gas and my car&#39;s
battery wouldn&#39;t hold up for extended problems, leaving my stranded. My
solution to this is a second electrical grid in my car.</p>

<p>A few deep-cycle marine batteries in the trunk (where I&#39;ve decided all of this
equipment is going to end up) and some high efficiency solar panels on the
roof, combined with an AC charger for when I do have the luxury of plugging in
should be enough to power a communications hub for an extended period of time.</p>

<p>So that&#39;s where I&#39;m at. I&#39;ve tentatively started pricing out solar panels and
in-car ham radios for the project. Stay tuned! This is going to be an
interesting ride...</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2010/02/open-source-firewall-reviews-virtualization/">Open Source Firewall Reviews: Virtualization</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on February 4, 2010</time> by Sam Stelfox</aside>
    <article>
      <p>So I hit a snag while attempting to review the open source firewalls on my
list. I still fully intend to get around it but the two spare boxes I had
kicking around to do the testing on both decided that they didn&#39;t like their
cd-rom drives. An excessive amount of required overtime at my job left me not
very willing to get PXE installations of the various firewall distributions
working. The only alternative I was left with was virtualization.</p>

<p>I&#39;ve been playing around with virtualization quite a bit and have been having a
lot of fun doing it. I&#39;ve been focused on freely available server class
virtualization. I trust linux. I have a lot of experience configuring it just
to my liking and can harden a linux machine to an almost obsessive level.</p>

<p>While I have heard a lot of good things about VMWare and they do provide both a
linux version and a free &#39;Viewer&#39; the server level stuff is not available for
free so I didn&#39;t consider them. This has the downside that the various firewall
distributions tend to provide VMWare appliances pre-configured. I went with
KVM. This choice is something that will need to be left for another blog post.</p>

<p>m0n0wall was not an option right off the bat. I couldn&#39;t even get the ISO to
boot to do the installation. pfSense worked like a charm, no fuss at all. I
still have yet to look at how the others are at dealing with being virtualized.
Stay tuned.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2009/12/open-source-firewall-reviews-intro-and-pfsense/">Open Source Firewall Reviews: Intro & pfSense</a></h1>
    <aside class="post-date">Published <time datetime=''>after his first cup of coffee on December 16, 2009</time> by Sam Stelfox</aside>
    <article>
      <p>Every now and then I like to refresh parts of my home network. New technology
comes out, new versions of software come out and new exploits and attacks come
out. This time around I felt it was about time that I look at the various
firewall distributions that have come out in the past couple of years. I&#39;m
going to perform various reviews over the course of the next few weeks time
(and memory) permitting.</p>

<p>I have a few slightly more obscure requirements for my firewall, some of which
very few reviewers touch on. These being support for 802.1q VLAN tagging, a
built in traffic shaper, a tftp server and options to broadcast it as a PXE
boot server in the DHCP options, a captive portal on an arbitrary interface,
and last but not least updates that don&#39;t require a full system rebuild.</p>

<p>The more common features on my requirements are port forwarding, stateful
firewall with per interface rules, remote syslog logging, DHCP server, DMZ, and
VPN access (perferably PPTP and OpenVPN).</p>

<p>For a long time I&#39;ve been an avid supporter of <a href="http://pfsense.org/">pfSense</a>. For those of you
not interested in following the link, pfSense is a BSD firewall/router based on
a very strong distribution called m0n0wall. pfSense is in a nutshell a
frankenstein of some of the best pieces of the open source BSDs out there all
wrapped in a bunch of PHP based scripts.</p>

<p>As much as I love pfSense there have been a few issues that I&#39;ve grown to live
with. The first being a large number of NAT issues. I&#39;m not really sure how to
classify this but it is very apparent if you play any multi-player online games
(and exponentially more apparent if you have more than one person tying to play
online at the same time). I&#39;m going to use Company of Heroes and Call of Duty:
Modern Warfare 2 as examples for this.</p>

<p>Right off the bat connecting online in Modern Warfare 2, it will display your
&quot;NAT Status&quot; as either open or closed. When one person is connected it is
usually &quot;Open&quot;, when two people are connected one or both will display
&quot;Closed&quot;. Now this isn&#39;t a terribly big issue for MW2 as even with a closed NAT
you can still play the game perfectly fine. The trick is that you won&#39;t be able
to join any games (or even get into a lobby) with someone that is on the same
network as you. So much for working together.</p>

<p>With Company of Heroes things get considerably worse. Even with only one person
trying to play the game, whenever hosting or joining an online game about 50%
of the individual players you try and connect to or that try to connect to you
will fail with a &quot;NAT negotiation error&quot;. This makes playing or hosting
anything more than a 1v1 a royal pain, and more than a 2v2 nigh impossible.</p>

<p>Using a commercial off-the-shell router (in this case an old D-Link 524 I had
laying around) these issues go away completely. At the time of this writing I
am using version 1.2.3-RELEASE (built on Sun Dec 6 23:38:21 EST 2009). The NAT
issues are known and you can find many people with the same issues complaining
in their forums. The answer is almost always use static NAT mapping, but this
only works for one player. It does seem to solve both issues though (as long as
only one person being able to play is acceptable).</p>

<p>The next issue I&#39;ve run across seems to have something to do with the state
table. Now this is a tricky issue because it might be some dirty trick that
Comcast is playing on me and I haven&#39;t tested any other firewall distribution
yet to see where the problem lies.</p>

<p>Right off the bat, pfSense has a maximum state table size of 10,000. This is
WAY more than enough for any home or small business networks. With five people
behind it, I&#39;ve only seen the state table jump as high as 1,500 and that was
with all of us running torrents. The problem seems to be that anymore than 900
entries in the state table cause severe degredation in performance. How severe?
With a state table of 958, it took 43 seconds for text to be echoed back to me
over an SSH connection. That&#39;s impossibly bad latency. This issue is quickly
resolved by blowing away the state table or rebooting the firewall, but will
quickly crop back up when the computers start re-establishing the connections.
The built in traffic shaper only seems to make this problem worse not better.
(As an aside I&#39;m running pfSense on 1.6Ghz box with 512 Mb of ram, this is far
more than the minimum specs of 100Mhz and 128Mb of ram.)</p>

<p>Also while pfSense officially supports having a captive portal on a interface,
I&#39;ve only been able to get this working for a short period of time and that was
back in version 1.21. So beware anyone wanting to use pfSense for a hotspot.
The only reason I really wanted a captive portal was so that I could broadcast
a second wireless AP that the public could connect to anytime and they would be
able to see a kind notice asking them not to abuse the bandwidth I&#39;m freely
sharing.</p>

<p>So with these issues why have I stayed with pfSense for so long? It is a
fantastic, stable system when you don&#39;t need to worry about torrents or gaming.
There are quite a few packages that can be one click installed through the web
interface. It provides good stats about the status of the system in a clean and
easy to navigate interface.</p>

<p>pfSense has been doing a wonderful job of meeting all of my requirements with
the exception of the captive portal but that wasn&#39;t <u>really</u> for me anyway, the
gaming issues, and of course the state table. For anybody out there looking for
a solid well rounded firewall don&#39;t let my issues deter you. There is a version
2 in the works and is currently available that might solve all of my issues,
although it&#39;s alpha software right now and I didn&#39;t really want to have to
troubleshoot my home network all the time due to buggy software when I&#39;m trying
to relax.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2009/11/image-crawler-meets-rm-f-star/">Image Crawler Meets rm -f *</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on November 4, 2009</time> by Sam Stelfox</aside>
    <article>
      <p>So for giggles I wrote a simple web crawler that archived any image it found on
a site that rapidly updated. My plan was to take all of the images resize them
to a fraction of what they were and make a collage progression of the images
posted over a 24 hours period. If that was successful I was going to try and
sort the image by the highest peak on a gray scale histogram of the image.</p>

<p>I let my crawler go and stopped it after a 24 hour period. I ls&#39;d the directory
the images were being saved in to see how many I got and my ssh session locked
up... Or so I thought. I hit Ctrl - C and nothing happened... So I closed my
window and opened a new one. Did the same ls and the same thing happened. At
this point I was really confused, did my system get compromised?  Maybe a
trojan ls was put on my system that was broken somehow?</p>

<p>The last thought put me into a panic, I raced to a system that held incremental
backups of this entire system and ran an md5sum on /bin/ls on it and on every
ls that I could find in the backup. There hadn&#39;t been any change. At this point
I was fairly certain that wasn&#39;t the case so I moved on...</p>

<p>Maybe there was a filename that hit some weird glitch in ls&#39;s programming
causing it too lock up. If this was the case how should I go about fixing it? I
started thinking about how it would be a nice contribution to the community if
I could figure out the error and report it, but I decided to take the lazy way
out.</p>

<p>I cd&#39;d to the directory and ran an rm -f * and was greeted with this:</p>

<blockquote>
<p>/bin/rm: Argument list too long.</p>
</blockquote>

<p>Wait what? All I get was this irritating and slightly elusive error message. So
the * was being expanded, and making the list too long? To be sure I started
hunting in the man pages. <code>man rm</code> recommended me to <code>info coreutils &#39;rm
invocation&#39;</code>. I read through and couldn&#39;t find any limitations or warnings that
might relate to the problem. The only thing I could find in there was a line
that said:</p>

<blockquote>
<p>GNU <code>rm&#39;, like every program that uses the</code>getopt&#39; function to parse its
arguments...</p>
</blockquote>

<p>Alrighty moving on... so getopt is parsing it&#39;s options... man and info pages
on getopt don&#39;t really reveal anything... So to Google!</p>

<p>After a bit of googling I found the answer, getopt&#39;s argument limit is 1024.
So... how many files did I have? I wanted to give ls one more try... I typed it
in and sure enough console froze... or did it? I walked away and did other
things. When I came back I had a large list of files, longer than my console
buffer... Ok-day, lets try this again &#39;ls -l | wc -l&#39;. After about five minutes
it came back again with just the number.</p>

<blockquote>
<p>177654</p>
</blockquote>

<p>Whoa... I wasn&#39;t expecting that... So how do I get around it... &#39;find . | xargs
rm -f&#39; and.... WOO Victory! The directory is clean and happy again... Now i&#39;ll
just have to figure out how to cut down the number of files, or at the very
least organize them into more managable chunks...</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2009/02/impressive-setup-dot-dot-dot/">Impressive Setup...</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on February 26, 2009</time> by Sam Stelfox</aside>
    <article>
      <p>So I joined a project named VOOM (Very Open Object Model). It&#39;s a group of PHP
developers from around the world that all came together through the magic of
the PHP General Mailing List.</p>

<p>The group got together to build a set of common classes such as data validators
that developers could just drop into there code, much like PEAR. One of the
goals is a common standard covering code testing, coverage, format,
documentation and without the dependancies that are riddled throughout things
like PEAR. The project is not intended to be a framework or anything else like
that. Just high quality useful code available to the public.</p>

<p>The thing that is so impressive to me is first off how quickly the group not
only got together and organized but how quickly a full development environment
went up and became usable. We currently have an IRC channel, subversion,
automated testing, wiki, coding templates.</p>

<p>Most of that was done by one person in the group, Nathan Rixham. I&#39;ve never
worked in any setup that... complete. Due too lack of time and creative
inspiration I still haven&#39;t though I&#39;m really looking forward to it.</p>

    </article>
  </div>

  <div class='post'>
    <h1><a href="/blog/2009/01/the-war-between-the-text-editors-and-the-ides/">The War Between the Text Editors and the IDEs</a></h1>
    <aside class="post-date">Published <time datetime=''>instead of an afternoon nap on January 28, 2009</time> by Sam Stelfox</aside>
    <article>
      <p>Long has been the battle of programming in a text editor and IDEs. Both sides
have made good points and slung mud at the other. What all these zealots fail
to realize is that there are merits to both sides. This is true with almost
every war going on and while to each person the other side might seem
ridiculous that doesn&#39;t make the other side wrong. But I digress.</p>

<p>This topic recently surfaced on a private mailing list that me and about thirty
of my friends share. The topic didn&#39;t start as anything to do with development
at all but rather around the cheap netbooks and there effect on the economy,
moved into the time it takes to setup a computer after a full install. He
upgraded his OS because the software that he runs needed new libraries that
would break his old system. After upgrading he found weird compatibility issues
with the new libraries and his system.</p>

<p>All the time he spent setting up his computer was lost development time on his
various freelance projects. This is when it came around to development and
development environments.</p>

<blockquote>
<p>It is obvious to anyone who works with computers that a great deal of time
can be spent on installing, configuring, and maintaining (upgrading)
software. Since no real work is accomplished by this, such time can be
thought of overhead time or as part of the &quot;cost&quot; of doing business in the
computer field.</p>
</blockquote>

<p>Back in the old days I programmed using a plain text editor and a command line
compiler, perhaps together with a make-like tool. There was no fancy IDE with
zillions of dependencies on complex graphical systems, no huge libraries, no
complex web browsers with multiple plug-ins, etc, etc. Most of my time was
spent actually writing programs. Huh.</p>

<p>I&#39;ve used IDEs and I&#39;ve used text editors. Personally I prefer text editors a
lot more, but I definitely see the merits. Since most of my development is
around PHP, a built in compiler doesn&#39;t do me much good. Subversion support
between IDEs vary and with every one you have to learn a different user
interface. On the other hand they allow you to quickly keep track of large
number of files. There are other features that IDEs have but this is the only
feature I can think of that is exclusive to IDEs that isn&#39;t in a plain text
editor.</p>

<p>Those familiar with vim or emacs (yes another war and for the record I&#39;m on the
vim side), will be aware that they have syntax highlighting that would be the
other feature that the IDE side tends to argue is exclusive to them. Which is
sort of true since vim and emacs kind of blend both sides.</p>

<p>IDEs are bloated and complex with lots of features and buttons which takes a
lot of time to learn. Text editors are simple all they do is edit text. vim and
emacs both started out as simple text editors and they still behave exactly as
they did but they have a lot of features that are common in IDEs. You can even
compile from within them and at least in vim if the the compiler throws an
error vim can jump straight to the line the error is on.</p>

<p>I haven&#39;t even begun to cover this war but I&#39;m fairly tired of typing. What my
verdict? Why not get the best of both worlds and just use vim or emacs?</p>

    </article>
  </div>

    </div>
  </body>
</html>
